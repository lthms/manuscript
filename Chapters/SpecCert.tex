%!TEX root = ../main.tex
\chapter{A Theory of HSE Mechanisms}
\label{chapter:speccert}

\endquote{``\emph{The purpose of abstraction is not to be vague, but to create a
    new semantic level in which one can be absolutely precise}''

  \hfill\footnotesize --- Edsger Dijkstra}

\vspace{1cm}%
\noindent
%
Our first contribution is a theory of \ac{hse} mechanisms, which takes into
account that
%
\begin{inparaenum}[(1)]
\item hardware architectures often allow for implementing several \ac{hse}
  mechanisms, and
\item hardware features involved in \ac{hse} mechanisms are not safe by default,
  hence the role played by trusted software components to configure them.
\end{inparaenum}

The rest of this Chapter proceeds as follows.
%
We model the hardware architecture as a labeled transition system whose
sequences of transitions, also called traces, characterize every possible
execution of software components (Section~\ref{sec:speccert:hardware}).
%
This model acts as a foundation for our \ac{hse} mechanisms theory
(Section~\ref{sec:speccert:hse}).
%
We then define what correctness means in the context of \ac{hse} mechanisms
(Section~\ref{sec:speccert:security}).
%
Our motivation to separate the model of the hardware architecture and \ac{hse}
mechanism definitions is to enable the reuse of the same hardware model to
verify the correctness of several \ac{hse} mechanisms.

For the reader familiar with Coq, we present an implementation of our formalism
in Appendix~\ref{appendix:speccert}.
%
This development comprises machine-checked proofs of the theoretical results
that we present throughout this Chapter.

\section{Hardware Model}
\label{sec:speccert:hardware}

We model a hardware architecture, which can execute different software
components, as a \ac{lts}.

\paragraph{States.}
%
The set of states of the \ac{lts} models the possible configurations of the
hardware components.
%
This configuration changes over time with respect to the hardware specifications
and comprises any relevant data such as register values, inner memory contents,
etc.
%
These state transformations occur during the system's transitions.

\paragraph{Transitions.}
%
We distinguish between two classes of transitions: the software transitions
which are direct and foreseeable side effects of the execution of a \ac{cpu}
instruction and the hardware transitions which are not.
%
Following the terminology of David Basin \emph{et
  al.}\,\cite{basin2013enforceable}, software transitions are ``controllable'',
while hardware transitions are only ``observable''.

We illustrate this definition with the x86 instruction \texttt{mov
  (\%ecx),\%eax}\,\footnote{Written in AT\&T syntax here.}.
%
With respect to the semantics of this instruction, a x86 \ac{cpu}:
%
\begin{inparaenum}[(1)]
\item reads the content of the register \texttt{ecx},
%
\item interprets this value as an address and reads the main memory at this
  address,
%
\item writes this content into the register \texttt{eax},
%
\item updates the register \texttt{eip} with the address of the next instruction
  to execute.
\end{inparaenum}
%
The execution of this instruction by a \ac{cpu} may result in several sequences
of transitions.
%
First, the four execution steps described above translate into four software
transitions.
%
Between each of these transitions, a hardware transition can occur.
%
For instance, one hardware component can initiate a \ac{dma}.
%
Also, if the content of \texttt{ecx} is not a valid address, the \ac{cpu} raises
an interrupt.
%
In this scenario, only one software transition occurs ---when the \ac{cpu} reads
the content of \texttt{ecx}--- then the next transition models the interrupt.

\begin{definition}[Hardware Model]
  \label{def:speccert:model}
  A hardware model $\Sigma$ is a tuple
  $\langle H, L_S, L_H, \rightarrow \rangle$, where
  %
  \begin{itemize}
  \item $H$ is the set of configurations of the hardware architecture
  %
  \item $L_S$ is the set of labels to identify software transitions
  %
  \item $L_H$ is the set of labels to identify hardware transitions
  %
  \item $\rightarrow$ is the transition relation of the system
  \end{itemize}

  The transition relation $\rightarrow$ is a predicate on
  $H \times (L_S~\uplus~L_H) \times H$.
  %
  Afterwards, we simply write $L$ for $L_S \uplus L_H$.
  %
  A transition labelled with $l$ from $h$ to $h'$ is denoted by
  %
  \[
    \transition{h}{l}{h'}
  \]
  %
  and we write $\mathcal{T}(\Sigma)$ for the set of triples which satisfy the
  transition relation, that is
  \[
    \mathcal{T}(\Sigma) \triangleq \{\ (h, l, h')\ |\ \transition{h}{l}{h'}\ \}
  \]

  \TODO{c'est quoi le sigle "union" avec un plus à l'intérieur?}
\end{definition}

\paragraph{Traces.}
A trace is a non-empty sequence of transitions of~$\Sigma$, such that for two
consecutive transitions, the resulting state of the first one is the initial
state of the next one.

% \TODO{Tu ne donnes qu'une définition informelle (en anglais) des traces. Tu
% pourrais donner la formule correspondante. Idem pour init et trans}
% \thomasrk[inline]{Bien que je comprenne l'argument, je ne pense
% personnellement pas que ça apportenait vraiment quelque chose.}

\begin{definition}[Traces]
  \label{def:speccert:trace}
  We write $\pathesLTS{Ez}$ for the set of traces of a hardware model $\Sigma$,
  and we consider the following functions:
  %
  \begin{itemize}
  \item $\func{init} : \pathesLTS{Ez} \rightarrow H$ maps a trace to its initial
    state
  \item
    $\func{trans} : \pathesLTS{Ez} \rightarrow \powerset(\mathcal{T}(\Sigma))$
    maps a trace to the set of transitions which occurred during the trace
  \end{itemize}
\end{definition}

As we detailed in Subsection~\ref{subsec:sota:security}, security policies are
modelled as predicates on sets of traces, that is $\powerset (\pathesLTS{Ez})$.
%
Mainstream hardware architectures are not ``safe'' by default, and required
additional software configuration to enforce security properties.
%
For instance, it is legitimate, from a x86 specifications perspective, to enter
ring 3 mode with a page table which allows for modifying kernel code and data.
%
This is why we ultimately seek to model \ac{hse} mechanisms as traces subsets,
to discard traces legitimate from a hardware specification perspective, yet
dangerous from a security perspective.

\section{HSE Mechanisms}
\label{sec:speccert:hse}

We now propose a theory of \ac{hse} mechanisms, where a \ac{hse} mechanism is
primarily characterized by a set of trusted software components, a set of
requirements over hardware states and a set of requirements over software
transitions.
%
On the one hand, the purpose of the requirements over states is to identify the
hardware configurations which constrain the execution of untrusted software
components with respect to a targeted security policy.
%
On the other hand, the purpose of the requirements over software transitions is
to prevent untrusted software components to reach a hardware configuration
wherein the requirements over state are not satisfied.
%
Requirements over software transitions should only constrain the execution of
trusted software components, which implement the \ac{hse} mechanism.
%
We consider an adversary model where attackers control untrusted software
components, and therefore we do not consider any hypotheses on their behavior.

These two classes of requirements allow us to determine a subset of compliant
traces, that is traces where trusted software components have correctly
implemented a \ac{hse} mechanism by obeying software requirements.
%
% \TODO{Peut être rappeller que "correctly implement the HSE" veut dire
% respecter les contraintes sur les états et les transititions software. C'est
% un peu trop implicite.}
%
To verify this \ac{hse} mechanism is correct with respect to a targeted security
policy means proving the set of compliant traces of this mechanism satisfies the
predicate which models the policy.

\paragraph{HSE Mechanisms.}
%
In the context of \ac{hse} mechanisms, trusted and untrusted software components
alike use the same interface to interact with the underlying hardware
components: the \ac{cpu} instructions set.
%
To reason about HSE mechanisms, it is necessary to be able to determine which
software component is executed at a given time.
%
In practice, a subset of states of the hardware architecture is dedicated to
each software component.
%
For instance, x86 processors protection rings are commonly used to execute
several software components.
%
Ring 0 is dedicated to the operating system, whereas the applications are
executed when the \ac{cpu} is in ring 3, with a particular page table setup.

\begin{definition}[Hardware-Software Mapping]
  \label{def:speccert:hardsoft}
  Given \( S \) a set of software components, a hardware-software mapping
  $\func{con\-text} : H \rightarrow S$ is a function which takes a hardware
  state and returns the software component currently executed.
\end{definition}

This definition is of key importance, because it implies strong hypotheses on
how a software stack is executed.
%
First, we assume only one software component is executed at a given time by the
hardware architecture, in order to simplify our definitions.
%
We believe dealing with multi-core architectures is possible with the cost of
additional efforts, \emph{e.g.} by defining a set of identifiers to select a
particular core.
%
It remains to be proven as we have not tackled this challenge during this
thesis.
%
Besides, there are approaches which allow for executing two software components
using the same ``hardware context'', \emph{e.g.} JavaScript programs of two tabs
inside a browser are arguably two distinct software components.
%
However, from the hardware architecture perspective, these three components are
indistinguishable, and enforcing a security policy in such a context is achieved
by means of software measures, \emph{e.g.} program interpretation or software
fault isolation\,\cite{morrisett2012rocksalt}.

We say a software transition is trusted (respectively untrusted) when it is
generated from a state associated to a trusted (respectively untrusted) software
component.
%
A hardware-software mapping is mandatory to define requirements over software
transitions that are consistent with respect to our adversary model, \emph{i.e.}
which only constrain trusted software components.
% GH: Cela devrait être expliqué un peu plus en détail et plus tôt. Il suffirait
% alors ici de le rappeler (comme expliqué en section xx, ces contraintes ne
% concernent que les transition trustés.}

\begin{definition}[HSE Mechanism]
  \label{def:speccert:hse}
  A \ac{hse} mechanism $\Delta$ is a tuple
  $\langle S, T, \func{context}, \func{hardware\_req}, \func{software\_req}
  \rangle$, such that
  %
  \begin{itemize}
  \item $S$ is the set of software components executed by the hardware
    architecture.
  %
  \item $T \subseteq S$ is the set of trusted software components which
    implement the \ac{hse} mechanism and form its \ac{tcb}.
  %
  \item $\func{context}$ is a hardware-software mapping to determine which
    software component is currently executed by the \ac{cpu}.
  %
  \item $\func{hardware\_req}$ is a predicate on $H$ to distinguish between safe
    hardware configurations and potentially vulnerable ones.
  %
  \item $\func{software\_req}$ is a predicate on $H \times L_S$ to distinguish
    between software transitions that trusted software components can safely
    use, and potentially harmful ones they need to avoid.
  \end{itemize}
\end{definition}

We illustrate this definition with the flash memory lockdown mechanism described
in Section~\ref{subsec:usecase:firm:sec}.
%
As a reminder, such mechanism enforces the integrity of the \ac{bios} code
within the flash memory and is implemented by the \ac{pch}.
%
As pictured in Figure~\ref{fig:speccert:flash}, the \ac{pch} acts as a proxy
between the \ac{cpu} and a collection of peripherals, including the flash
memory.
%
The \ac{hse} mechanism proceeds as follows:
%
\begin{enumerate}
\item By default, the flash memory is locked and its content cannot be modified.
  %
  By setting the correct bit of a dedicated register of the \ac{pch}
  (\texttt{BIOS\_CNTL}), a software component requests to unlock the flash
  memory.
%
\item When a software component (\emph{e.g.} system software) unlocks the flash
  memory, the \ac{pch} triggers a \ac{smi}.
%
\item This forces the \ac{cpu} to enter \ac{smm}.
  %
  By doing so, the \ac{cpu} stops the execution of the software component which
  has unlocked the flash memory and starts the execution of the \ac{bios}.
%
\item In order to protect the integrity of the flash memory content, the
  \ac{bios} is expected to lock the flash memory again, before resuming the
  execution of the system software with the \texttt{rsm} assembly instruction.
\end{enumerate}

Legacy \acp{bios} were probably using this mechanism in order to implement an
ad-hoc communication channel between the \ac{bios} and the system software
component, \emph{e.g.} to initiate a \ac{bios} update.
%
The \ac{uefi} standard introduces dedicated protocols to enable communication
between the \ac{bios} and the system software component, and our understanding
is that in most implementations the \ac{bios} action, in response to a \ac{smi}
triggered by the unlocking of the flash memory, is limited to lock it again and
resume.

\begin{figure}
  \centering
  \begin{tikzpicture}
    \node [draw, inner sep=12pt, text badly centered] (CPU) {CPU};%
    \node [draw, below=15pt of CPU, inner sep=25pt, text badly centered] (PCH)
    {PCH};%
    \draw (CPU) -- (PCH);%

    \node [draw, inner sep=5pt, below=10pt of PCH, text width=45pt,
    xshift=-55pt, text badly centered] (Flash) {Flash Memory};%
    \draw ([xshift=-10pt]PCH.south) |- (Flash.east);%

    \node [draw, text=white, dashed, inner sep=10pt, below=10pt of PCH, text
    width=25pt, xshift=55pt, text badly centered] (TPM) {TPM};%
    \draw [dashed] ([xshift=10pt]PCH.south) |- (TPM.west);%

    \node [draw, text=white, dashed, inner sep=10pt, right=20pt of PCH, text
    width=45pt, text badly centered] (USB) {USB Controller};%
    \draw [dashed] (PCH) -- (USB);%

    \node [draw, text=white, dashed, inner sep=10pt, left=20pt of PCH, text
    width=45pt, text badly centered] (PCI) {PCI Controller};%
    \draw [dashed] (PCH) -- (PCI);%
  \end{tikzpicture}

  \caption{From the CPU to the flash memory}
  \label{fig:speccert:flash}
\end{figure}

\begin{example}[Model of Flash Memory Lockdown Mechanism]
  \label{example:speccert:flashdef}
  %
  The set of trusted software components is limited to the \ac{bios}, that is
  \( T = \{ \mathtt{bios} \} \).
  %
  This means the rest of the software stack (\emph{e.g.} the operating system
  and its applications) are untrusted and therefore assumed to be under the
  control of attackers.
  %
  The hardware-software \( \func{context} \) maps \acp{cpu} in \ac{smm} with the
  execution of the \ac{bios}, that is
  %
  \[
    \begin{array}{rcll}
      \func{context}(h) & = & \mathtt{bios} & \text{if } h \text{ characterizes
                                              a \ac{cpu} in \ac{smm}} \\
      \func{context}(h) & \in & S \backslash \{ \mathtt{bios} \} & \text{otherwise}
    \end{array}
  \]
  %
  % \TODO{La phrase n'est pas suffisamment préciser. En outre, j'ai mis du temps
  % à
  % me rappeler que context ne doit pas être pris ici comme un mot commun mais
  % un nom de fonction!. Il faudrait dire que par défaut contexte(h)=non trusté
  % sauf lorsque le CPU est en SMM, c'est à dire lorsqu'une SMI se produit et
  % avant que le bios exécute une instruction rsm}
  %
  A safe hardware state ($\func{hardware\_req}$) is either a state wherein the
  \ac{bios} is executed, or a state wherein the flash memory is locked.
  %
  It is expected that the \ac{bios} locks the flash memory before using the
  \texttt{rsm} instruction ($\func{software\_req}$).
\end{example}

\paragraph{HSE Laws.}
%
As it is, our theory of \ac{hse} mechanisms is too permissive.
%
For a \ac{hse} mechanism to be consistent, it must also obey two requirements,
together called the \ac{hse} laws.
%
The first law says that the $\func{software\_req}$ predicate always holds true
for transitions generated by untrusted software components.
%
That is, the first law enforces that a \ac{hse} mechanism definition does not
make any assumption regarding untrusted software components.
%
The second law says that the requirements over the hardware state specified by
$\func{hardware\_req}$ are invariant with respect to $\func{software\_req}$.
%
As long as the trusted software components which implement the \ac{hse}
mechanism only generate software transitions which satisfy the
$\func{software\_req}$ predicate, the $\func{hardware\_req}$ predicate holds
true.
%
This means the software transitions at the untrusted software components
disposal cannot put the system into an unsafe state.

\begin{definition}[\ac{hse} Laws]
  \label{def:speccert:laws}
  A \ac{hse} mechanism $\Delta$ has to satisfy the following properties:
  \begin{enumerate}
  %
  \item Untrusted software transitions satisfy $\func{software\_req}$:
    $\forall (h, l, h') \in \mathcal{T}(\Sigma)$, $\forall x \not\in T$,
    %
    \[
      l \in L_S \wedge \func{context}(h) = x \Rightarrow \func{software\_req}(h,
      l)
    \]
  %
  \item $\func{hardware\_req}$ is an invariant with respect to
    $\func{software\_req}$: $\forall (h, l, h') \in \mathcal{T}(\Sigma)$,
    \[
      \func{hardware\_req}(h) \wedge (l \in L_S \Rightarrow
      \func{software\_req}(h,l)) \Rightarrow \func{hardware\_req}(h')
    \]
  \end{enumerate}
\end{definition}

On the one hand, a \ac{hse} mechanism definition which does not satisfy the
first law is incorrectly making assumption about ``untrusted'' software
components.
%
This makes these components part of the \ac{tcb} \emph{de facto}, even though
they do not belong to $\mathcal{T}$.
%
Formally defining a \ac{hse} mechanism may be the occasion to uncover such
implicit assumptions.
%
On the other hand, a \ac{hse} mechanism which does not satisfy the second law
has to be carefully reviewed.
%
As it stands, it lets the hardware architecture reach a state wherein the
hardware configuration does not satisfy the requirements over states, despite
the correct implementation of the mechanism by the trusted software components.
%
In such a condition, the hardware architecture may stop to constrain the
execution of untrusted software components with respect to the targeted security
policy.
%
This could mean that constrains over trusted software components execution are
incomplete, or that requirements over hardware states are too restrictive.
%
If it is not possible to loosen the requirements over hardware states without
threatening the security policy enforcement or to find additional restrictions
over trusted software execution, then the \ac{hse} mechanism probably does not
serve its purpose.
% \TODO{Cela veut surrement dire que les contraintes sur l'exécution du code
% trusté sont incomplètes ou que le la restriction sur l'état du hardware est au
% contraire trop restrictive. S'il n'est pas possible de trouver une contrainte
% sur l'état du hardware moins restrictive permettant d'assurer la propriété de
% sécurité ou de restreindre le code trusté pour vérifier cette seconde loi, il
% y a de forte chance que le HSE ne permette pas d'assurer la propriété de
% sécurité visée.... }

\begin{example}[Flash Memory Lockdown Inconsistency]
  We can convince ourselves that the informal definition description we have
  discussed in the Example~\ref{example:speccert:flashdef} obeys the first
  \ac{hse} law, but \emph{does not} obey the second one.
  %
  \paragraph{Untrusted software transitions satisfy $\func{software\_req}$.}
  %
  The only software restriction we have formulated concerns the use of the
  \texttt{rsm} instruction by the \ac{bios}.
  %
  The rest of the software stack can leverage the complete x86 instructions set
  with no restriction.
  %
  In particular, an attacker is free to unlock the flash memory thanks to the
  \texttt{BIOS\_CNTL} register.

  \paragraph{$\func{hardware\_req}$ is not an invariant with respect to
    $\func{software\_req}$.}
  %
  A \ac{cpu} is either in \ac{smm} or not in \ac{smm}.
  %
  If it is in \ac{smm}, the only way to leave \ac{smm} is to execute the
  \texttt{rsm} instruction, which qualifies as a software transition.
  %
  If the \ac{cpu} is in \ac{smm}, the \func{software\_req} hold true for this
  software transition when the flash memory is locked.
  %
  As a consequence, a \ac{bios} which correctly implements this \ac{hse}
  mechanism locks the flash memory prior to leaving the \ac{smm}.
  %
  However, if the \ac{cpu} is not in \ac{smm}, and tries to open the flash
  memory, two things happen sequentially.
  %
  First, the flash memory is effectively opened.
  %
  This has to be modelled by a software transition.
  %
  Then, the \ac{pch} triggers a \ac{smi}, leading the \ac{cpu} to enter
  \ac{smm}.
  %
  A \ac{smi} has to be modelled as a hardware transition.
  %
  Between the modification of the \texttt{BIOS\_CNTL} register and the treatment
  of the \ac{smi} by the \ac{cpu}, the \func{hardware\_req} predicate is not
  satisfied.

  It is because the flash memory lockdown as described here does not satisfy the
  first law that the race condition uncovered by Corey Kallenberg \emph{et
    al.}\,\cite{kallenberg2015racecondition} is possible.
  %
  On the contrary, the \texttt{SMM\_BWP} register semantics ---detailed in
  Subsection~\ref{subsec:usecase:hse:speed}--- allows for defining a HSE
  mechanism which satisfies both laws, because the register ties together the
  state of the \acp{cpu} and the flash memory state.
\end{example}

\paragraph{Trace Compliance.}
%
Whether trusted software components are correctly implementing a given \ac{hse}
mechanism is a safety property: trusted software components shall \emph{never}
generate a software transition which does not satisfy the requirements of the
\ac{hse} mechanism.
%
Because the purpose of these requirements over software transitions is to
prevent untrusted software components to reach a hardware configuration wherein
the requirements over states are not satisfied, so it is required that the
initial state of the trace satisfies the requirements over states.
%
A trace whose initial state satisfies the requirements over states and where
trusted software components do correctly implement a \ac{hse} mechanism is said
to comply with this mechanism.
%
\begin{definition}[Compliant Traces]
  We write $\mathcal{C}(\Delta)$ for the set of the traces which comply with
  $\Delta$.
  %
  Given $\rho \in \pathesLTS{Ez}$, then $\rho \in \mathcal{C}(\Delta)$ iff
  \[
    \func{hardware\_req}(\func{init}(\rho)) \wedge \forall (h,l,h') \in
    \func{trans}(\rho)\text{, }l \in L_S \Rightarrow \func{software\_req}(h, l)
  \]
\end{definition}

\begin{example}[Memory Flash Lockdown Compliance]
  We consider the trace to start at the end of the boot sequence, when the
  \ac{bios} gives the control flow to the system software component it has
  selected.
  %
  At the time, it is expected that the \texttt{BIOS\_CNTL} register of the
  \ac{pch} has been correctly set; in particular, the \texttt{SMM\_BWP} bit
  should be set, to avoid the Speed Racer
  attack\,\cite{kallenberg2015racecondition}.
  %
  If the \ac{bios} fails to do so, then the related trace is not compliant.
\end{example}

\begin{lemma}[HSE Invariant Enforcement]
  \label{lemma:speccert:hseinv}
  As intended, \func{hardware\_req} is an invariant of traces which complies
  with $\Delta$, that is
  %
  \[
    \forall \rho \in \mathcal{C}(\Delta), \forall (h, l, h') \in
    \func{trans}(\rho), \func{hardware\_req}(h) \wedge \func{hardware\_req}(h')
  \]

  \begin{proof}
    By definition of $\mathcal{C}(\Delta)$, we know the initial state of the
    trace satisfies \func{hardware\_req}, and thanks to the second HSE Law, we
    can conclude the state after the first transition also satisfies
    \func{hardware\_req}.
    %
    We generalize to the trace by induction.
    %
    \hfill \( \square \)
  \end{proof}
\end{lemma}

As a consequence, a \ac{hse} mechanism allows for satisfying a given set of
requirements over hardware configurations throughout the execution of a software
stack, as long as a set of trusted software components correctly implement the
mechanism.

\section{HSE Mechanism Correctness.}
\label{sec:speccert:security}

It is important to keep in mind that preserving a set of requirements over
hardware configurations is only a mean to an end.
%
The true purpose of a \ac{hse} mechanism is to constrain the execution of
untrusted software components with respect to a targeted security policy.

It is possible to define a \ac{hse} mechanism which satisfies the \ac{hse} Laws,
yet failed to constrain the execution of untrusted software components with
respect to a targeted security policy.
%
The SMRAM cache poisoning attack described in
Subsection~\ref{subsec:usecase:hse:smram} is a good illustration of that
eventuality\,\cite{duflot2009smram,wojtczuk2009smram}.
%
The isolation of the \ac{bios} at runtime is enforced by only two hardware
mechanisms: the \ac{smm} of the \ac{cpu} and the \texttt{SMRAMC} register of the
memory controller.
%
By correctly configuring the memory controller \emph{via} the \texttt{SMRAMC}
register, the \ac{bios} can activate the protection of a dedicated memory region
called the SMRAM.
%
In such a case, only a \ac{cpu} in \ac{smm} can read or write to the SMRAM.
%
As it stands, the \ac{hse} mechanism described here satisfies both laws.
%
However, between the \ac{cpu} and the memory controller lies the cache, as
pictured in Figure~\ref{fig:speccert:smram}.
%
If the cache does not take into account the SMRAM ---as it was the case in 2009,
before the SMRAM cache poisoning attack (discussed in
Subsection~\,\cite{subsec:usecase:hse:smram}) was disclosed--- it can be used to
circumvent the protection enforced by the memory controller: the integrity of
the SMRAM is enforced, but the \ac{cpu} does not read its content when it needs
it.

\begin{figure}
  \centering
  \begin{tikzpicture}
    \node [draw, inner sep=15pt] (Core) {Core};%
    \node [draw, inner sep=7pt, below=5pt of Core] (Cache) {Cache};%
    % \node [draw, inner sep=10pt, dashed, fit=(Core) (Cache)] (CPU) {};%

    \node [draw, below=10pt of Cache, inner sep=20pt, text width=50pt, text
    badly centered] (MC) {Memory Controller};%

    \draw (Core) -- (Cache);%
    \draw (Cache) -- (MC);%

    \node [draw, right=10pt of MC, minimum height=100pt, inner sep=10pt] (DRAM)
    {DRAM};%

    \draw (DRAM) -- (MC);%

    \draw [dashed] ([yshift=15pt]DRAM.south west) -- ([yshift=15pt]DRAM.south
    east);%
    \draw [dashed] ([yshift=25pt]DRAM.south west) to node [below, yshift=1pt]
    {\small SMRAM} ([yshift=25pt]DRAM.south east);%
  \end{tikzpicture}

  \caption{From the \ac{cpu}'s core to the SMRAM}
  \label{fig:speccert:smram}
\end{figure}

We detail in Subsection~\ref{subsec:sota:security} how various classes of
security policies ---safety and liveness properties, and hyperproperties--- can
be modeled against a transition system.

\begin{definition}[Security Policy]
  A security policy \( P \) is either a predicate on sets of traces, a predicate
  on traces or a predicate on transitions.
\end{definition}

\begin{definition}[Correct HSE Mechanism]
  A \ac{hse} mechanism $\Delta$ is correct with respect to a security policy $P$
  (denoted by $\Delta \models P$) if and only if the set of compliant traces of
  $\Delta$ satisfies $P$, that is
  %
  \[
    \Delta \models P \triangleq
    \begin{cases}
      P(\mathcal{C}(\Delta)) & \text{if } P \text{ is a predicate on sets of
        traces} \\
      \forall \rho \in \mathcal{C}(\Delta), P(\rho) & \text{if } P \text{ is a
        predicate on traces} \\
      \forall \rho \in \mathcal{C}(\Delta), \forall \mathit{tr} \in
      \func{trans}(\rho), P(\mathit{tr}) & \text{if }P \text{ is a predicate on
        transitions}
    \end{cases}
  \]
\end{definition}

Verifying that a \ac{hse} mechanism is correct with respect to a security policy
can be difficult.
%
In the particular case of safety properties, the reasoning is facilitate because
they are characterized by predicates on transitions.
%
The following theorem takes advantage of this fact.

\begin{theorem}[Correct HSE Mechanism for Predicate on Transitions]
  \label{theorem:speccert:correcthse}
  Given a security policy $P$ defined as a predicate on transitions, then
  %
  \[
    \begin{array}{l}
      \forall (h, l, h') \in \mathcal{T}(\Sigma), \\
      \qquad (\func{hardware\_req}(h) \wedge
      (l \in L_{S} \Rightarrow \func{software\_req}(h, l)))
      \Rightarrow P(h, l, h')
    \end{array}
  \]
  %
  is a sufficient condition for
  %
  \[
    \Delta \models P
  \]

  \begin{proof}
    By definition, a HSE mechanisn \( \Delta \) is correct with respect to a
    security policy characterized by a predicate on transitions \( P \) if the
    transitions of its compliant traces satisfy \( P \).
    %
    With Lemma~\ref{lemma:speccert:hseinv}, we know that initial states of a
    transition of compliant traces satisfy $\func{hardware\_req}$.
    %
    We also know by definition of compliant traces that their transitions
    satisfy \func{software\_req}.
    %
    Therefore, if we can prove that transition which satisfy both
    \func{hardware\_req} and \func{software\_req} also satisfy \( P \), then we
    can conclude that transitions of compliant traces satisfy \( P \).
    %
    \hfill \( \square \)
  \end{proof}
\end{theorem}

\section{Conclusion}

In this Chapter, we have presented our theory of \ac{hse} mechanisms, in the
form of requirements over a hardware model.
%
This approach makes it possible to reuse the same model to define and verify
several \ac{hse} mechanisms, provided that the model is comprehensive enough in
terms of hardware features.
%
We believe this is an essential property, especially because in practice, these
multiple mechanisms will be implemented concurrently, and may interfere with
each other.

Throughout this Chapter, we have tried to illustrate our definitions with
real-world examples, as our effort has been originally motivated by the
disclosure of several vulnerabilities targeting multiple x86 \ac{hse} mechanisms
for the past few
years\,\cite{wojtczuk2009smram,duflot2009smram,rutkowska2008remap,domas2015sinkhole,kallenberg2015racecondition}.
%
All being told, our approach can be summarized to a three-step methodology for
specifying and verifying \ac{hse} mechanisms against hardware architecture
models, that is
%
\begin{inparaenum}[(1)]
\item specifying the software requirements that must be satisfied by the trusted
  software components which implement the \ac{hse} mechanism,
%
\item specifying the targeted security policy the \ac{hse} mechanism supposedly
  enforces, and
%
\item verifying that the \ac{hse} mechanism is correct with respect to the
  targeted security policy.
\end{inparaenum}
%
We believe this methodology would benefit both hardware designers and software
developers.
%
In the next Chapter, we apply our proposal to a real world example: the \ac{hse}
mechanism implemented by the \ac{bios} to remain isolated from the rest of the
software stack after the end of the boot sequence
(Section~\ref{sec:usecase:hse}).
