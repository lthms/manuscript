\chapter{Hardware and BIOS Background}
\label{chapter:usecase}

Our motivation to formally specify and verify architectural attacks comes from
our experience with the x86 hardware architecture.
%
Over the past decade, the security of the lower levels of abstraction (hardware,
firmware, system software) has grown in importance, and several critical
vulnerabilities which fall in our definition of architectural attacks have been
disclosed.
%
While our contributions are intended to be applicable to other hardware
architectures, for purposes of evaluating our work, we have adopted the systemic
approach to apply them to a x86 real example.
%
We have chosen to focus on the HSE mechanism implemented by the BIOS at runtime
to stay isolated from the rest of the software stack, including the system
software.
%
Because the BIOS is the most privileged piece of software executed by the
hardware architecture, this HSE mechanism is of key importance.
%
Despite this fact, it has been defeated several times, and therefore, it
illustrates perfectly our motivations.
%
However, it is important to emphasize that other mainstream architectures
(\emph{e.g.}  ARM) work on similar basis and suffer similar issues.

The rest of this Chapter proceeds as follows.
%
We describe how a typical x86 hardware architecture is organized, and the
consequences of this organization in terms of security
(Section~\ref{sec:usecase:architecture}).
%
We then focus on the key role played by the \ac{bios}
(Section~\ref{sec:usecase:firmware}).
%
Once the role of the \ac{bios} has been established, we detail HSE mechanisms it
implements, and several architectural attacks which have defeated these HSE
mechanisms in the past (Section~\ref{sec:usecase:hse}).

\section{Hardware Architecture Overview}
\label{sec:usecase:architecture}

% TODO: Unify the figures, because right now, they have different name for the
% same thing. Use the vocabulary introduced in Introduction.

Describing hardware architectures in depth is challenging, because they tend to
be made of many inter-connected components of various nature.
%
From this perspective, the x86 hardware architecture is a textbook case, and
this is probably best illustrated by the scale of its documentation.
%
At the time of writing this thesis\,\footnote{Spring 2018.}, the \emph{Intel 64
  and IA-32 Architectures Software Developerâ€™s Manual} is 4842 pages long.
%
Executed on the computer used to write the present thesis, the GNU/Linux
command-line application \texttt{lshw} lists about 30 hardware components, which
come with their own documentations, often in the form of large datasheets.

A x86 computing platform is built upon two key components: \acp{cpu} and memory
(\ref{subsec:usecase:cpumem}).
%
The \ac{cpu} communicates with peripherals to interact with the outside world
(\emph{e.g.} another computing platform, a user) (\ref{subsec:usecase:perif}).

\subsection{Processors and Memory}
\label{subsec:usecase:cpumem}

A computer platform goal is to execute programs to perform arbitrary tasks.
%
To that end, it relies on one or more \ac{cpu}.
%
A \ac{cpu} takes so-called ``instructions'' as input, and manipulates its
internal states and data stored in a memory, as output
%
A program is a sequence of instructions, often stored in the same memory as the
data it manipulates.
%
Overall, a \ac{cpu} basically repeats the following task, over and over:

\begin{enumerate}
\item Read the content of its (internal) \emph{program counter} register, and
  interpret it as the address of the next instruction.
%
\item Fetch the content of this address from memory.
%
\item Decode the instruction, that is identified the desired operation to
  perform
%
\item Act accordingly, by modifying its internal state, and interacting with the
  memory.
%
\item Update the content of its \emph{program counter} register according to the
  semantics of the instruction it has executed. Most of the time, it increases
  it to fetch the next instruction, but it can also set it to an arbitrary value
  (\emph{e.g.} with jump instructions).
\end{enumerate}

From the \ac{cpu} perspective, the memory is abstracted into a contiguous array
of storage cells, identified by an address.
%
A \ac{cpu} can interact with the memory by reading at or writing to a given
address.
%
In reality, a hardware architecture contains several memories of various nature.
%
The \ac{dram} remains the most important, and is often called the \emph{system
  memory}, but it is not the only memory present in a hardware architecture.
%
Peripherals expose memories too; the latter are used as communication channels
between them and the \acp{cpu}.
%
That is, to ``receives a message'' from a peripheral, a \ac{cpu} reads the
content of the memory it exposed, while it can ``send a message'' by writing to
the same memory.

% Interacting with the \ac{dram} remains slow, in regard to the speed of a
% \ac{cpu}
%%
% To improve performance, Intel \acp{cpu} come with several (often three) levels
% of caches, from the smaller and quicker, to the bigger and slower.
%%
% For cache-friendly programs, the gain in performance can be huge.
%%
% This gain is paid in important increase of complexity.
%%
% Enforcing coherence between the different levels of cache and the \ac{dram} is
% not trivial.

\paragraph{}
%
Historically, x86 \acp{cpu} were using two distinct memory spaces to communicate
either with the \ac{dram} or with the peripherals, along with two families of
instructions.
%
Nowadays, the memories exposed by the peripherals are mapped within the same
address space, and accessed with the same instructions.
%
That is, when a \ac{cpu} read at or write to an address, the access is
transparently dispatched either to the \ac{dram} or to a peripheral.
%
The first component to intervene in the decision process is the Memory
Controller (formally known as the \emph{northbridge}, and now integrated to the
\ac{cpu} Die).
%
The Memory Controller is connected to the \ac{dram} and to peripherals which
require small access time, such as a graphic card or a ethernet controller.
%
If a given memory access does not target one of its peripherals or the
\ac{dram}, the Memory Controller forwards the memory access to the Platform
Controller Hub (PCH) (formally known as the \emph{southbridge}).
%
The PCH acts as a proxy for the remaining peripherals.

The memory map, that is the correspondence between the addresses used by the
\ac{cpu} and the storage cells scattered among the hardware architecture, is
dynamically configurable.
%
As such, determining which hardware component will receive a given memory access
is far from being trivial.
%
From a security perspective, the consequences are important.
%
If an untrusted software component is able to modify the \ac{cpu} memory map in
an unanticipated manner, it may be able to tamper with the execution of a
trusted software component.

\subsection{Peripherals}
\label{subsec:usecase:perif}


It is worth mentioning that, since 2008, Intel embeds the Management Engine, a
processor \emph{inside} the memory controller.
%
The Management Engine executes a complete software stack, is capable of
interacting to the \ac{dram} as well as other hardware components.
%
Intel leverages the Management Engine to provide out-of-band management
solution, which means it can interact with the rest of the world without the
cooperation of the main \ac{cpu}.
%
Although the Management Engine supposedly operates in a transparent manner from
the \ac{cpu} perspective, we emphasize that a Management Engine vulnerability, a
scenario which is not without precedent, potentially defeats any security
measures implemented at the \ac{cpu} level.

The security threat posed by the Management Engine is not an isolated case.

\subsection{Hidden Hardware Architecture Complexity}

One drawback of Figure~\ref{fig:usecase:computing-platform-1} is to hide the
complexity of the \emph{Hardware} layer.
%
Far from a homogeneous block, a typical hardware architecture comprises dozens
of hardware components whose nature and purpose are very different.
%
It is not possible to reason about HSE mechanisms without taking this reality
into account.

Figure~\ref{fig:usecase:computing-platform-2} partially highlights this, by
making explicit several hardware components involved in memory accesses: the
cache, the memory controller, a DRAM controller or potentially a graphic card.
%
Most of them run dedicated software stacks, concurrently with the ``main''
software stack pictured in Figure~\ref{fig:usecase:computing-platform-1}.
%
Although these concurrent software stacks are not the main subject of this
thesis, they are worth mentioning, as they can have dramatic consequences from a
security perspective.
%
We cite two example to motivate this claim.
%
First, L. Duflot \emph{et al.} have been able to take control of a network card,
because the piece of software responsible for processing network packets was
vulnerable.
%
This novel ---at the time--- kind of attacks poses several challenges, from a
security perspective.
%
Indeed, it is very hard, if not impossible, for the ``main'' software stack to
know whether the network card has been compromised or not.
%
The second example we want to detail is the Intel Management Engine, an
autonomous system which lives inside x86 processors since 2008.
%
The Management Engine is used by Intel to provide business services, such as
out-of-band administration management or trusted computing technologies
emulation.
%
To enable these features, the Management Engine requires very important
privileges, and is \emph{de facto} the most privileged execution environment of
a x86 computing platform.
%
Recent vulnerabilities have shown this is not without consequences when the
Management Engine's software stack is compromised.

Apart from these potential software implementation issue within hidden software
stacks, Figure~\ref{fig:usecase:computing-platform-2} highlights the complexity
of a typical hardware architecture.
%
This complexity easily explains the architectural attacks that have been
disclosed during the past decade.

\subsection{Importance of Software Isolation}

Software components mostly manipulate data stored in ``memory'', and they see
this memory as a continuous array.
%
In reality, it is scattered among many different, sometimes redundant locations.
%
This is partly because the x86 architecture heavily relies on \emph{memory
  mapping} mechanisms.
%
For each memory access, several hardware components might be involved: the MMU,
the cache, the memory controller, the DRAM controller, the peripherals, and so
on.

The code of the software components which form the software stack are also
stored within the memory, as pictured by
Figure~\ref{fig:usecase:computing-platform-3}.
%
When the \ac{cpu} wants to execute the next instruction of a given software
components code, it fetches it from memory.
%
For the result of this memory fetch to be what the software developer is
expecting, the memory layout has to be carefully configured.
%
This is harder than one might expect.
%
This makes \emph{isolation} a key security property.
%
In the context of this thesis, we say one component $A$ is said isolated from a
second component $B$ when $B$ cannot tamper with $A$'s functioning otherwise
than through its interface.
%
Thus, an operating system should be isolated from end users applications, to
prevent the latter to grant themselves abusive rights.
%
The opposite is not necessarily true, and it is even a common practice for
operating system to tamper with applications code (\emph{e.g.} address space
layout randomization, dynamic libraries).

Isolation should not been confused with code integrity, as it might be possible
for an attacker to tamper with the execution of a given software component
without modifying its code in memory.
%
To that end, they might for instance rely on a memory mapping mechanism.


\section{BIOS}
\label{sec:usecase:firmware}

To illustrate these threats, we focus on the \emph{Firmware} layer of the
computing platform.
%
We first explain the role played by the computer firmware at runtime, after the
boot sequence.
%
We then describe which HSE mechanisms it implements to stay isolated from the
rest of the software stack.
%
Finally, we show how these HSE mechanisms have been defeated by attackers over
time.

\subsection{BIOS Purposes}

In the context of this thesis, we call \emph{Firmware} a piece of software
provided by a hardware vendor and indispensable to ensure the computer correctly
works.
%
Many hardware components comes with their dedicated firmware, \emph{e.g.} the
graphic card, the network card, etc.
%
In addition, hardware vendors provide a particular form firmware tied to the
hardware architecture as a whole, better known as the \ac{bios}.
% or the \emph{Unified Extensible Firmware Interface} (UEFI).

The main objective of the \ac{bios} is to carry on the initialization of the
hardware architecture.
%
This initialization process is commonly called the boot sequence.
%
One the boot sequence is completed, the \ac{bios} selects a system software,
like an operating system.
%
To do so, it loads the system software code into memory, then starts its
execution.
%
Once this is done, the system software controls the main \ac{cpu}, and the rest
of the hardware architecture.

The \ac{bios} often exposes a set of so-called runtime services, but nothing
obliges the system software to use them.
%
For this reason, people tend to think \ac{bios} role ends with the boot
sequence.
%
This is not true.
%
Indeed, the \ac{bios} continues to actively participate to the well functioning
of a computer, even after it gives the control flow to the system software.
%
Its main task is to take care of hardware events specific to the particular
hardware architecture it is tied to.
%
Sometimes, it also emulates a hardware feature, in a transparent manner from the
point of view of the system software.  \thomasrk[inline]{Do we have an example?}
%
Last, but not least, it manages its own update.
%
That is, the system software is not able to modify the \ac{bios} code, as stored
in the SPI Flash, by itself.
%
Instead, it can only submit an update to the \ac{bios}, and the latter alone
decides if this update can be applied.
%
This prevent the dangerous scenario where an attacker is able to take control of
the system software, and then modify the \ac{bios}.

Translated in terms of security properties, this means two things:
%
\begin{inparaenum}[(1)]
\item the \ac{bios} shall be properly isolated from the other software
  components, and
  %
\item the SPI Flash which contains the \ac{bios} code shall be
  integrity-protected, so that only the \ac{bios} can modify it.
\end{inparaenum}
%
This should not be a surprise for the attentive readers: these two security
properties are enforced by two HSE mechanisms implemented by the \ac{bios}.

\subsection{BIOS Isolation}

The \ac{bios} isolation at runtime is enforced thanks to the \ac{smm} of x86
\ac{cpu}.
%
Intel describes it as follows (the emphasis is ours, and does not exist in the
original document):

\begin{quote}
  \ac{smm} is a special-purpose operating mode provided for handling system-wide
  functions like power management, system hardware control, or proprietary
  OEM-designed code.
  %
  It is intended for use only by system firmware, not b applications software or
  general-purpose systems software.
  %
  \textbf{The main benefit of \ac{smm} is that it offers a distinct and easily
    isolated processor environment that operates transparently to the operating
    system or executive and software applications.}
\end{quote}

To handle several level of privileges, Intel \ac{cpu} provides several execution
modes.
%
An execution mode can be roughly assimilated to a set of hardware capabilities.
%
Hence, in a given execution mode, a \ac{cpu} may refuse to execute certain
assembly instructions.
%
As a consequence, the software component executed will not be able to leverage
the side-effects involved by the execution of these instructions, \emph{e.g.}
access to specific hardware registers (like the one related to paging).
%
The execution modes are not ''linear''.
%
On the contrary, they can be seen as a composition of several hardware features:
ring levels, virtualization technology, and finally \ac{smm}.
%
This means you can be in ring~0, while in hypervisor mode, while in \ac{smm},
for instance.

\paragraph{System Management Mode}
%
The main objective of the \ac{smm}, as stated by the Intel Developer Manual, is
to provide an `isolated processor environment'', dedicated to ``system
firmware'', and that should ``operate transparently to the operating system''.
%
To provide these features, \ac{smm} relies on two things: the SMRAM and the
\ac{smi}.

The SMRAM is a special memory region within the DRAM, dedicated to the \ac{smm}.
%
It is supposed to contain the \ac{bios} code, and its private data;
%
as a consequence, it should not be accessible to a \ac{cpu} which is not in
\ac{smm}.
%
The exact location and size of the SMRAM is architecture dependent.
%
To locate it, the \ac{cpu} has a register named \texttt{SMBASE}, to be
configured by the \ac{bios} during the boot sequence.
%
As its name implies, the \texttt{SMBASE} value should point to the base of the
SMRAM.
%
It is then up to the \ac{bios} developer to appropriately write its so-called
\ac{smm} code (that is, the code supposedly executed in \ac{smm} at runtime)
knowing the limitation of the SMRAM of the targeted architecture.

The \ac{smi} is a hardware interrupt which makes the \ac{cpu} enters \ac{smm}.
%
More precisely, when a \ac{cpu} receives a \ac{smi}, it saves its current state
(\emph{e.g.} registers, execution mode, etc.), either in the SMRAM or, for most
recent versions, in dedicated register of the \ac{cpu}.
%
Once this preliminary step is done, the \ac{cpu} reconfigures itself;
%
in particular, it sets its program counter register, that is, the register which
indicates from which address to fetch the next instruction it shall execute, to
$\texttt{SMBASE} + 0x8000$\thomasrk{Ã€ vÃ©rifier.}.
%
From this point, the \ac{cpu} is in \ac{smm} and starts to execute what should
be the \ac{smm} code.
%
Once the \ac{smm} code has performed the task it has been requested for, the
\texttt{rsm} instruction can be used.
%
The instruction, which can be used only in \ac{smm}, tells the \ac{cpu} to
restore its previous state.
%
This way, the execution of the pieces of software previously halted by the
\ac{smi} can resume.
%
From the system point of view, it is like if nothing has happened.

\section{Examples of x86 Architectural Attacks}
\label{sec:usecase:hse}

The combination of the SMRAM and the \ac{smi} explains why the \ac{smm} is often
introduced as the ``most privileged execution mode'' of a x86 \ac{cpu}.
%
In a nutshell, the \ac{smm} code can do all the thing the system software does,
including arbitrary memory locations which belongs to that system software, but
the system software cannot modify the SMRAM content.
%
In addition, the \ac{smi} is not a maskable interrupt, so the system software
cannot prevent the execution of the \ac{smm} code.
%
In other words, both the integrity of the SMRAM and the availability of the
\ac{smi} are the foundation of the \ac{smm} security.
%
Because they have been both defeated at repeated occasions, this makes the
\ac{smm} particularly interesting to illustrate the concept of architectural
attacks.

\paragraph{SMRAM Cache Poisoning Attack}
%
From the beginning, the integrity of the SMRAM has been enforced by the Memory
Controller of the x86 architecture, whether it is a dedicated hardware component
(northbridge), or more recently a part of the \ac{cpu}.
%
The Memory Controller main purpose it to act as a proxy for the \ac{cpu} memory
accesses.
%
It receives the \ac{cpu} memory accesses, and dispatches them among the
different hardware components which expose memory.

The Memory Controller exposes a configuration register called the
\texttt{SMRAMC}, whose purpose is to configure the access control configuration
of the SMRAM.
%
At the beginning of the boot sequence, the SMRAM is said to be opened, which
means it can be access by the \ac{cpu} whether it is in \ac{smm} or not.
%
This allows the \ac{bios} to load the \ac{smm} code inside the SMRAM, as the
\ac{cpu} is not itself in \ac{smm} at the beginning of the boot sequence.
%
Once the loading is done, the \ac{bios} can ``close'' the SMRAM, meaning only a
\ac{cpu} in \ac{smm} can access to the SMRAM.
%
It can also lock the SMRAMC, to prevent further piece of software (say, a
malicious or exploited system software) to open the SMRAM in order to tamper
with its content.

Between 1986\thomasrk{Verify the date}, when the \ac{smm} has first been
introduced, and 2009, it was believed that the \texttt{SMRAMC} register enough
was sufficient to ensure the integrity of the SMRAM.
%
Loic Duflot \emph{et al.}\,\cite{duflot2009smram} and Rafal Wojtczuk \emph{et
  al.}\,\cite{wojtczuk2009smram} have independently shown this belief was
misplaced, thanks to the so-called \emph{SMRAM Cache Poisoning Attack}.
%
In addition to the evocative name, Figure~\ref{todofig} highlights the
vulnerability concept.
%
To increase performance, the \ac{cpu} uses a cache of its memory accesses.
%
That is, when it reads memory, it stores the result of this access within a
cache.
%
Then, when it has to read at the same location again, it gets the result from
the cache directly, whose access time is way lower than regular DRAM.
%
A similar scheme applies to write accesses.

As a consequence, regarding a \ac{cpu} configuration, copies of the SMRAM
content may be found in the cache.
%
These copies were not protected by the Memory Controller, meaning the system
software could tamper with them, even while not in \ac{smm}.
%
This attack is a perfect illustration of an architectural attack:
%
both the Memory Controller and the Cache work as expected.
%
The first one prevent an authorized access by a \ac{cpu} not in \ac{smm};
%
The second one keeps copies of successful accesses to decrease latency due to
memory accesses.
%
However, once put together, they paves the road toward a successful tampering of
the SMRAM by a system software.

The solution implemented by Intel to prevent further exploitation of this
vulnerability was to modify the behavior of the Cache, when the memory accesses
target the SMRAM;
%
and because the SMRAM size and location remain specific to each architecture,
this means it requires an additional step of configuration to tell the cache
where the SMRAM is.

What is interesting about the SMRAM Cache Poisoning is that another x86
vulnerability\,\cite{domas2015sinkhole} has been since disclosed.
%
It also allows to trick a \ac{cpu} in \ac{smm} to execute arbitrary
instructions, but leaves the content of the SMRAM in DRAM untouched.
%
In this case, it leverages the fact that the configuration registers of the
\ac{apic}, a component of the \ac{cpu}, can be mapped in memory.
%
An attacker can use them to mask the real content of the SMRAM, even to a
\ac{cpu} in \ac{smm}.
%
Again, the complexity implied by the composition of several hardware components
can be used in a harmful way.


\paragraph{}
%
The isolation provided by the \ac{smm} is not an end in itself.
%
In fact, it has become the basis upon which other HSE mechanisms have been
implemented.
%
One good example is the HSE mechanism responsible for the SPI Flash access
control.
%
In this example, the trusted software component is the \ac{smm} code.
%
The rest of the software stack, including the system software, is considered
untrusted.
%
The targeted security property is the integrity of the SPI Flash.
%
More precisely, only the \ac{smm} code should be capable of overwriting the
content of the SPI Flash, which contains the \ac{bios} code.
%
To enforce this security property, the HSE mechanism relies on the
\texttt{FNCTL} \thomasrk{Trouver le bon nom et mettre une ref.} register,
exposed by the Platform Controller Hub.
%
Once configured correctly, the SPI Flash is considered ``locked'', meaning it is
not possible even for the \ac{smm} code to issue a successful write access which
targets its content.
%
The SPI Flash can be unlocked, but when the system software tries, the PCH fires
a \ac{smi}.
%
As a consequence, the \ac{cpu} saves its current state, and starts executing the
\ac{smm} code.

What comes next depends on the \ac{smm} code, and how it is implemented.
%
It is executed in a situation where the SPI Flash is unlocked, so it can
perform, if it makes sense, the write access intended by the system software on
its behalf.
%
On typical workflow is for the system software to load the \ac{bios} update in
memory, and for the \ac{smm} code to verify whether this update is correctly
signed by the vendor.
%
In any case, it is the responsibility of the \ac{smm} code to lock again the SPI
Flash before it uses the \texttt{rsm} instruction to leave \ac{smm}.
%
Similarly to the \texttt{SMRAMC} register and the isolation it promises, the
\texttt{FNCTL} register has been defeated at least twice.

\paragraph{SENTER Sandman}
%
In 2015, Xeno Kovah \emph{et al.} have shown it was possible to leverage the
Intel TXT technology to circumvent the SPI Flash write
protection\,\cite{kovah2015senter}.
%
By default, a system software has to trust the \ac{bios}.
%
Nowadays, most \ac{bios} implementations are made of millions of lines of code,
which are provided by many different industrial partners of the vendor.
%
As a consequence, the attack surface is consequent.
%
Intel TXT is a recent feature of some x86 \ac{cpu}, whose aim is to reduce the
\ac{tcb} of a system software, by removing most of the \ac{bios} from it.
%
With Intel TXT, a hypervisor can start its execution in an isolated execution
environment.
%
From this perspective, it was coherent for TXT to mask incoming \ac{smi}, this
indeed reduce the size of the \ac{tcb}, by excluding the \ac{smm} code.
%
Unfortunately, in this case, it has the important consequence of leaving the SPI
Flash content unprotected.

\paragraph{Speed Racer}
%
There is at least another attack that defeated the \texttt{FNCTL} register
purpose.
%
In 2015, Corey Kallenberg \emph{et al.} have shown that the scenario detailed
previously, where unlocking the SPI Flash fires a \ac{smi} which forces the
\ac{cpu} to execute the \ac{smm} code, suffers from a race condition in presence
of a second \ac{cpu}\,\cite{kallenberg2015racecondition}.
%
When a \ac{smi} is fired, all the x86 \ac{cpu} of the platform will eventually
enter in \ac{smm}.
%
On the contrary, the SPI Flash is unlocked as soon as the \texttt{FNCTL}
register is modified.
%
To prevent this race condition, Intel has added a new feature to its PCH, and
exposed by the \texttt{FNCTL} register.
%
Once activated, this new feature ensures the SPI Flash stays locked as long as
one \ac{cpu} is not in \ac{smm}.

\section{Conclusion}
\label{sec:usecase:conclusion}

Due to the complexity of computing platform, in particular from a hardware point
of view, implementing a correct HSE mechanism is challenging.
%
We chose to focus on HSE mechanisms implemented by the firmware, because it has
been well studied and there are several illustrative example of architectural
attacks.
%
In particular, in this chapter, we explained how three of them work.
