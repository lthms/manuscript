\documentclass[oneside,a4paper]{memoir}
\setsecnumdepth{subsection}

\usepackage[chapter]{minted}
\usemintedstyle{bw}

% ABOUT THIS FILE
% ---------------
%
% The goal of this document is to prepare the next (and final?) version of the
% chapter 3.

\usepackage{bigcenter}
\usepackage{geometry}
\usepackage{paralist}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bussproofs}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{inconsolata}

\usepackage[dvipsnames]{xcolor}
\usepackage{xargs}
\usepackage{todonotes}
\newcommandx{\thomasrk}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}

\usepackage{mdframed} % or, "mdframed"
\usepackage[amsthm,framed]{ntheorem}
\newcommand{\powerset}{\raisebox{.15\baselineskip}{\Large\ensuremath{\wp}}}

\definecolor{statementline}{HTML}{b7e2d6}

\theoremstyle{break}
\theorembodyfont{\fontshape\rmdefault\selectfont}

\mdfdefinestyle{quoted}{
hidealllines=true,
leftmargin=-15pt,
rightmargin=-15pt,
leftline=true,
innertopmargin=10pt,
innerbottommargin=10pt,
innerrightmargin=15pt,
linewidth=5pt,
linecolor=gray!40,
backgroundcolor=gray!3,
usetwoside=false,
skipabove=\topsep,
skipbelow=\topsep}

\mdfdefinestyle{definition}{
style=quoted,
linecolor=Violet!20,
backgroundcolor=Violet!2}

\mdfdefinestyle{statement}{
style=quoted,
linecolor=PineGreen!30,
backgroundcolor=PineGreen!2}

\newmdtheoremenv[style=definition]{definition}{Definition}[chapter]
\newmdtheoremenv{notation}{Notation}[chapter]
\newmdtheoremenv[style=quoted]{example}{Example}[chapter]
\newmdtheoremenv[style=statement]{corollary}{Corollary}[chapter]
\newmdtheoremenv[style=statement]{lemma}{Lemma}[chapter]
\newmdtheoremenv[style=statement]{theorem}{Theorem}[chapter]

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, positioning, arrows, intersections, fit,
  matrix, shapes, shapes.symbols}

\usepackage{acro}
\input{abbrev}

\begin{document}
\chapter{State of the Art of Formal Verification}

%
% The rest of this Chapter proceeds as follow.
%%
% First, we give an opinionated introduction to the formal verification of
% hardware and software components with respect to security properties, with
% respect to our objectives (Section~\ref{?}).
%%
% Then, we give a review of several industrial and academic projects which
% implements these approaches (Section~\ref{?}).
%%
% Finally,

Formal verification consists in proving the correctness of a system ---the
\emph{Implementation}--- with respect to certain properties.
%
To that end, a verifier
%
\begin{inparaenum}[(1)]
\item defines a formal description of the system ---the \emph{Specification}---,
  %
\item exhibits a proof that a formal description of the system satisfies a
  statement (defined in an arbitrary logic) which encodes the property with
  respect to which the correctness shall be proven, and
  %
\item exhibits a proof of correspondence between the implementation and the
  specification.
\end{inparaenum}
%
In this context, the terms ``implementation'' and ``specification'' refer to a
subjective relation between two layers of abstraction: the specification is more
abstract than its implementation, and formal verification proofs can be
organized in an arbitrary number of abstraction layers
%
The definition of a specification shall ease the construction of the proof of
correctness, while the correspondence proof allows for extending the properties
of the specification to the implementation.
%
The instantiation of the terms ``formal description'', ``correspondence proof'',
``properties'' or ``correctness proof'' may considerably vary from one system to
another.
%
Similarly, the nature of the proofs and their construction greatly depend on the
tools used by the verifier.
%
For our part, we want to construct correctness proofs of a hardware architecture
specification, with respect to security properties, and using the Coq theorem
prover (as explained in Chapter~\ref{chap:introduction}).
%
The rest of this Chapter is organized with this objective in mind

First, we describe popular formalisms used to define formal descriptions of
hardware specifications (Section~\ref{sec:sota:formalisms}).
%
Then, we focus on the encoding of security properties as logic statements
(Section~\ref{sec:sota:security}).
%
Finally, we give an overview of related works
(Section~\ref{sec:sota:relatedwork}).
% and we conclude this Chapter by positioning our contributions in that respect
% (Section~\ref{...}).

\section{Transition Systems}
\label{sec:sota:formalisms}

\subsection{Definition}

The formal verification of discrete systems, such as computing systems, commonly
rely on some sort of \emph{transition systems} to describe the behavior of the
target.
%
More precisely, the system is characterized by a set of \emph{states} and by a
set of \emph{atomic} state-transformation, called \emph{transitions}.
%
Transitions occur when the system interacts with its environment (\emph{e.g.} a
hardware circuit receives a clock signal, a hardware controller receives a
message from a bus, an operating system handles a syscall).
%
Additionally, \emph{labeled} transition systems distinguish between classes of
transitions \emph{via} the use of labels (\emph{e.g.} one label per syscall).

To the best of our knowledge, the more straightforward definition of a labeled
transition system, as used by Vijayaraghavan \emph{et al.} in their work on
modular verification of multiprocessor hardware
designs\,\cite{vijayaraghavan2015modular}, is a tuple
\( \langle S, L, R \rangle \), such that \( S \) is a set of states, \( L \) is
a set of labels, and \( R \subseteq S \times L \times S \) is the transition
relation.

\begin{example}[Airlock System]
  Figure~\ref{fig:sota:airlock-lts} illustrates an instantiation of this
  definition for a simple airlock system.
  %
  An airlock system is a device made of two doors, and an intermediary chamber.
  %
  To get across a airlock system, a user requests the opening of the first door,
  enters the chamber, waits for the system to close the first door and open the
  second door, and exits the chamber.

  \begin{itemize}
  \item A door of the system can be either \( \mathtt{open} \) or
    \( \mathtt{close} \).
    %
    The set of states of the airlock system reflects the combinatronics of the
    doors states.
  \item A transition is characterized by the opening (\( \mathtt{Open}_i\), with
    \( i \in \{1, 2\} \)) and closing (\( \mathtt{Close}_i \), with
    \( i \in \{1, 2\} \)) of a door of the system.
    %
  \item The system does not allow the simultaneous opening of both doors, as
    stated by the definition of \( R \) which does not contains a transition
    which leads to the state \( (\mathtt{open}, \mathtt{open}) \).
  \end{itemize}
\end{example}

\begin{figure}
  \begin{center}
    % the mathematical definition
    \begin{minipage}[c]{0.55\linewidth}
      \[
        \begin{array}{rcl}
          S & \triangleq & \{ \mathtt{open}, \mathtt{close} \}^2 \\
          L & \triangleq & \{ \mathtt{Open}_1, \mathtt{Close}_1, \mathtt{Open}_2,
                           \mathtt{Close}_2 \} \\
          R & \triangleq & \{ (\mathtt{close}, \mathtt{close}), \mathtt{Open_1},
                           (\mathtt{open}, \mathtt{close}), \\
            & & \ (\mathtt{close}, \mathtt{close}), \mathtt{Open_2},
                (\mathtt{close}, \mathtt{open}), \\
            & & \ (\mathtt{open}, \mathtt{close}), \mathtt{Close_1},
                (\mathtt{close}, \mathtt{close}), \\
            & & \ (\mathtt{close}, \mathtt{open}), \mathtt{Close_2},
                (\mathtt{close}, \mathtt{close}) \}
        \end{array}
      \]
    \end{minipage}
    \hfill
    % a tikzpicture to illustrate the resulting automata
    \begin{minipage}[c]{0.40\linewidth}
      \begin{center}
        \begin{tikzpicture}
          \node [draw, circle split, text width=30pt, text badly centered] (cc)
          {\( \mathtt{close} \) \nodepart{lower} \( \mathtt{close} \)};%
          \node [right=of cc] (x) {};%
          \node [draw, circle split, above=of x, text width=30pt, text badly
          centered] (oc) {\( \mathtt{open} \) \nodepart{lower}
            \( \mathtt{close} \)};%
          \node [draw, circle split, below=of x, text width=30pt, text badly
          centered] (co) {\( \mathtt{close} \) \nodepart{lower}
            \( \mathtt{open} \)};%
          \node [draw, circle split, right=of x, text width=30pt, text badly
          centered] (oo) {\( \mathtt{open} \) \nodepart{lower}
            \( \mathtt{open} \)};%

          \draw [-latex] (cc) edge [bend left] node [xshift=-5pt, left]
          {\( \mathtt{Open}_1 \)} (oc);%
          \draw [-latex] (oc) edge [bend left] node [xshift=5pt, right]
          {\( \mathtt{Close}_1 \)} (cc);%

          \draw [-latex] (cc) edge [bend left] node [xshift=5pt, right]
          {\( \mathtt{Open}_2 \)} (co);%
          \draw [-latex] (co) edge [bend left] node [xshift=-5pt, left]
          {\( \mathtt{Close}_2 \)} (cc);%

        \end{tikzpicture}
      \end{center}
    \end{minipage}

    \caption{An simple airlock system modeled as a labeled transition system}
    \label{fig:sota:airlock-lts}
  \end{center}
\end{figure}

There are many modeling structures one can use to characterize transition
systems, with each variant better suited to tackle a particular class of
systems.
%
For instance, the Kripke structure\,\cite{kripke1971semantical} is a notorious
variation of (labeled) transition systems used in model
checking\,\cite{clarke1999model}, while Petri net\,\cite{peterson1981petri},
process algebra\,\cite{bergstra1984process} or interface
automata\,\cite{de2001interface} are better suited to model concurrent systems.

\subsection{Introduction to Deductive Reasoning}

Theorem prover rely on formal systems in which formulas (also called
propositions) of a formal language represent statements which can either be true
or false.
%
Each formal system (\emph{e.g.} higher-order logic\,\cite{leivant1994hol})
relies on a set of axioms, that are formulas known to be true, and inference
rules which allows for deriving new formulas.

The statement that a proposition \( P \) is true is commonly denoted by
\( \vdash P \).
%
A proposition \( P \) may also be true on the condition that propositions
\( Q_0, Q_1, ... Q_n \) is also true.
%
This statement is denoted by \( Q_0, Q_1, ... Q_n \vdash P \).
%
A statement is proven true when it is part of the base of axioms or we use
inference rules to derive already proven statements.
%
By doing so, we construct a \emph{proof}.
%
For example, a notorious inference rule is the \emph{Modus ponens}, which states
that if a proposition \( P \) is true, and the proposition \( P \Rightarrow Q \)
is also true, then the proposition \( Q \) is true, that is
%
\[
  P\text{, }(P \Rightarrow Q) \vdash Q
\]
%
Using the \emph{Modus ponens}, it becomes possible to construct a proof of
\( \vdash Q \) from a proof of \( \vdash P \) and a proof of
\( \vdash P \Rightarrow Q \).
%
Figure~\ref{fig:sota:inference} gives a l list of common inference rules.
%
Conditional statements, once proven, become new inference rules to be used to
construct proofs.

Formally constructing a proof can quickly become cumbersome as propositions
become more complex.
%
They can be described in the form of carefully worded sentences.
%
Another popular approach is to write them as so-called proof trees.
%
Each node of the tree is a proof obligation.
%
The children of a given proof obligation or proofs which allows for concluding
about the node goal, by using an inference rule of the system.
%
By convention, a node goal and its children are separated by a line labeled with
the name of the inference rule.
%
The leafs of the trees are the statement known to be true, either because they
are part the system axioms or because they have already been proven before.
%
Therefore, a proof which only consists in applying the \emph{Modus ponen} can be
represented as follows:
%
\begin{prooftree}
  \AxiomC{\( P \)} \AxiomC{\( P \Rightarrow Q \)} \RightLabel{\small {\scshape
      Modus Ponens}} \BinaryInfC{\( Q \)}
\end{prooftree}

\begin{figure}
  \begin{center}
    \begin{tabular}{ll}
      {\scshape Modus ponens} & \( P \Rightarrow Q\text{, }P \vdash Q \) \\
      {\scshape Modus tollens} &
                                 \( P \Rightarrow Q\text{, }\neg Q \vdash \neg P \) \\
      {\scshape Conjunction:} & \( P\text{, }Q \vdash P \wedge Q \) \\
      {\scshape Addition:} & \( P \vdash P \vee Q \)
    \end{tabular}
  \end{center}

  \caption{Examples of common inference rules}
  \label{fig:sota:inference}
\end{figure}

Verifying the correctness of a proof can be challenging.
%
The promise of theorem provers is to handle this tasks, supposedly in a more
reliable way than humans.
%
Therefore, the quality of a theorem prover is measured by its capacity to reject
ill-formed proofs.
%
To avoid this pitfall, modern theorem provers are built as ``certified'' layers
around a certification as small and simple as possible.
%
The idea is that, as long as the kernel does not contain a bug, advanced
features implemented inside a certified layer cannot introduce inconsistency in
the proof-checking process.
%
This greatly diminishes the risk to have inconsistencies in the proof checker,
although this happened in the
past\,\cite{claret2015falso,griffioen1998comparison}.

\subsection{Specifying Security Policies}
\label{sec:sota:security}

The verification a system is \emph{always} relative to certain properties (in
our case, the correct enforcement of a security policy).
%
The definition of a specification of the system to allow for formally reasoning
about its behavior is a key step of the verification process.
%
The formalization of the targeted property is as important, if not more.
%
Indeed, the challenge posed by a potential gap between an implementation and its
specification can be abated by an appropriate correspondence proof.
%
As for the targeted properties, a gap between its characterization using a
particular logic and its semantics should not be understated.
%
For instance, Mathy Vanhoef \emph{et al.} disclosed a critical vulnerability
(KRACK) targeting the WPA2 protocol\,\cite{vanhoef2017key}, despite previous
formal verification results (\emph{e.g.} \cite{he2004analysis}).
%
The reason remains simple: KRACK does not violate the security properties proven
in the formal analysis of the protocol, only these security properties were not
strong enough.

The theory of properties of a transition system is now well understood, with an
intuitive classification of properties, such that:
%
\begin{itemize}
\item \emph{Safety properties}\,\cite{lamport1977proving,lamport1985logical}
  characterize that nothing ``bad'' shall \emph{never} happens.
\item \emph{Liveness properties}\,\cite{lamport1985logical,alpern1985liveness}
  characterize that something ``good'' shall \emph{eventually} happens.
\end{itemize}

We discussed in Subsection~\ref{subsec:usecase:targetedsec} the two classes of
security policies commonly targeted by x86 \ac{hse} mechanisms.
%
An access control policy is a safety property: no unauthorized action by a
subject targeting on object shall never happen.
%
An availability policy is a liveness property: the system shall eventually
satisfy the service

Safety and liveness properties are expressed against the transition systems
\emph{traces}.
%
The most generic definition of a trace of a transition system is a (potentially
infinite) sequence of states generated by successive transitions.
%
Each modeling structure has its own definition of traces, which takes into
account the specificities of the model.
%
For instance, traces labeled transition system will interleave a label between
each state\,\cite{vijayaraghavan2015modular}, to characterize the nature of the
transition which led to the transformation of a state of the sequence with its
successor.
%
Afterwards, we write \( \Sigma(M) \) for the set of traces of a specification
\( M \).

Simplest properties can be defined in terms of sets of
traces\,\cite{schneider2000enforceable,basin2013enforceable}\,\thomasrk{cite
  ``Recognizing Safety and Liveness'' by Alpern}.
%
We assume a specification \( M \) whose set of states is \( S \) and whose
traces only contain states.
%
On the one hand, a safety property \( P \in \powerset(\Sigma(M)) \) is
formalized with an invariant \( \iota \) on trace element (\emph{i.e.} on
\( S \) in the case of the specification \( M \)).
%
\( M \) is correct with respect to \( P \) when
%
\[
  \forall \rho \in \Sigma(M)\text{, } \iota(\rho_0) \wedge \rho_{[1..]} \in P,
\]
%
where \( \rho_0 \) is the first element of the trace, and \( \rho_{[1..]} \) is
the trace obtained by removing the first element of \( \rho \).
%
On the other hand, a liveness property is formalized by a predicate \( \eta \)
on trace element which has to be satisfied at least once.
%
This time, \( M \) is correct with respect to \( P \) when
%
\[
  \rho \in \Sigma(M)\text{, } \eta(\rho_0) \vee \rho_{[1..]} \in P.
\]
%

\begin{example}[Airlock Safety and Liveness Properties]
  A typical \emph{safety} property (nothing `bad'' happens) for an airlock
  system is that at least one door shall be close at any time.
  %
  We formalize this property with the invariant \( \iota \), defined as follows:
  %
  \[
    \iota( d_1, d_2) \triangleq d_1 = \mathtt{close} \vee d_2 = \mathtt{close}
  \]
  %
  The specification of the airlock system is defined with a labeled transition
  system.
  %
  Assuming the airlock device is initialized in a correct state (\emph{e.g.}
  both doors are close), we verify this specification is correct with respect to
  the safety property characterized by \( \iota \) by exhibiting a proof that
  \( \iota \) is an invariant with respect to \( R \), that is
  %
  \[
    \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \iota(d_1, d_2) \Rightarrow
    \iota(d_1', d_2')
  \]
  %
  Such a proof is given in Figure~\ref{fig:sota:proofsafety}.

  In addition, we can also prove that both doors of the airlock will
  \emph{eventually} be close.
  %
  We can characterize this liveness property with the predicate \( \eta \), such
  that
  %
  \[
    \eta(d_1, d_2) \triangleq d_1 = \mathtt{close} \wedge d_2 = \mathtt{close}
  \]
  %
  We verify the specification of the airlock system is correct with respect to
  the liveness property characterized by \( \eta \) by exhibiting a proof that
  for each transition of \( R \), one of the state satisfies \( \eta \), that is
  %
  \[
    \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \eta(d_1, d_2) \vee
    \eta(d_1', d_2')
  \]

\end{example}

\begin{figure}
  \bigcentering%
  {\footnotesize \AxiomC{} \RightLabel{\footnotesize
      \( \vee,\Rightarrow \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{close} = \mathtt{close} \\
        \vee \mathtt{close} = \mathtt{close}) \\
        \Rightarrow (\mathtt{open} = \mathtt{close} \\
        \qquad \vee \mathtt{close} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{close}, \mathtt{close}) \\
        \Rightarrow
        \iota(\mathtt{open}, \mathtt{close})
      \end{array} \)}%
    \AxiomC{}
    \RightLabel{\footnotesize \( \vee,\Rightarrow \){\scshape -Def}}
    \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{close} = \mathtt{close} \\
        \vee \mathtt{close} = \mathtt{close}) \\
        \Rightarrow (\mathtt{close} = \mathtt{close} \\
        \qquad \vee \mathtt{open} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{close}, \mathtt{close}) \\
        \Rightarrow
        \iota(\mathtt{close}, \mathtt{open})
      \end{array} \)}%
    \AxiomC{}
    \RightLabel{\footnotesize \( \vee,\Rightarrow \){\scshape -Def}}
    \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{open} = \mathtt{close} \\
        \vee \mathtt{close} = \mathtt{close}) \\
        \Rightarrow (\mathtt{close} = \mathtt{close} \\
        \qquad \vee \mathtt{close} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{open}, \mathtt{close}) \\
        \Rightarrow
        \iota(\mathtt{close}, \mathtt{close})
      \end{array} \)}%
    \AxiomC{See \( \square \)}
    \RightLabel{\footnotesize \( R \){\scshape -Def}}
    \QuaternaryInfC{\( \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \iota(d_1,
      d_2) \Rightarrow \iota(d_1', d_2') \)}%
    \DisplayProof}

  \vspace{2em}

  {\footnotesize \AxiomC{} \RightLabel{\footnotesize
      \( \vee,\Rightarrow \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{close} = \mathtt{close} \\
        \vee \mathtt{open} = \mathtt{close}) \\
        \Rightarrow (\mathtt{close} = \mathtt{close} \\
        \qquad \vee \mathtt{close} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{close}, \mathtt{open}) \\
        \Rightarrow
        \iota(\mathtt{close}, \mathtt{close})
      \end{array} \)}%
    \UnaryInfC{\( \square \)}
    \DisplayProof}

  \caption{Airlock system proof of correctness with respect to a safety
    property}
  \label{fig:sota:proofsafety}
\end{figure}

Not all security policies can be formalized with a predicate on traces.
%
For instance, \emph{noninterference} \thomasrk{ref} is a confidentiality policy
which requires that so-called public inputs handled by a given system always
produce the same output, regardless of concurrent secret inputs.
%
In this context, considering each trace independently does not make sense.
%
To witness a violation of the security policy requires to compare two traces
together.
%
Such properties are called \emph{hyperproperties}\,\cite{marr2002hypertheading},
and are characterized by sets of sets of traces.
%
Verifying a system with respect to a hyperproperty is harder in the general
case, but certain hyperproperties, called \( k \)-safety properties, can be
reduced to an invariant.
%
For instance, we assume \( M \) handles inputs which can be either secret or
public.
%
Let \( \equiv \) be the binary relation, such that two states \( s \) and
\( r \) satisfies this relation (\( s \equiv r \)) when they characterize two
instances of the system which have handled the same public inputs and produced
the same visible behavior.
%
Similarly to Banerjee \emph{et al.} \thomasrk{Stack-based access control for
  secure information flow} or Barthe \emph{et al.}\,\cite{barthe2011virtcert1},
we can prove \( M \) enforces noninterference if for any public input \( l \) by
constructing a proof that
%
\[
  \forall (s, r) \in S \times S, s \equiv r \Rightarrow (s \xrightarrow{l} s'
  \wedge r \xrightarrow{l} r') \Rightarrow s' \equiv r',
\]
where \( s \xrightarrow{l} s' \) is a transition of the system from a state
\( s \) to a state \( s' \) to handle the input \( l \).

% Linear Temporal Logic?

\paragraph{Adversary}
%
\begin{itemize}
\item Combinatronics of system actions (Pip, VirtCert)
\item Additional rule to model more powerful attacker (Moat, XOM + bus snooping)
\end{itemize}

\subsection{Related Works}

\section{Beyond Transition Systems}

\subsection{Sequential versus Concurrent Systems}

\begin{itemize}
\item Airlock System problem
\item Hoare Logic
\end{itemize}

\subsection{Compositional Modeling}

\subsection{Assume-Guarantee Reasoning}

\subsection{Related Works}

\section{Introduction to Theorem Proving}

A theorem prover is a computer program to write machine-checked proofs in a
particular logic, which is in the general case more expressive than what a model
checkers offers.
%
However, they lack automation for nontrivial problems, as they do not excuse
users from \emph{writing proofs}.
%
The task can be very important in terms of effort for real world systems.

\subsection{By Example: Coq and the Airlock System}

To illustrate how we can leverage the formal system of a theorem prover to
formally verify a transition system, we
%
The Coq theorem prover\,\cite{coq} includes two languages: a rich functional
language to write specifications ({\scshape Gallina}) and a tactic language to
write proofs ({\scshape Ltac}).
  %
We can use {\scshape Gallina} to describe the system in terms of states and
actions to update this state.

\inputminted[firstline=1,lastline=14]{coq}{Listings/Airlock.v}

This reads as follows: a door is either open or close; a airlock system is made
of two doors; we consider four actions which imply an update of the airlock
system's state (opening the first or second door, closing the first or second
door).

{\scshape Gallina} includes a special type, called \texttt{Prop}, to write
logical propositions which can be either true or false.
%
We can define the transition relation of our airlock system using \texttt{Prop.}
%
In practice, this is done by enumerating the cases where the statement is true,
and the remaining cases are considered to be false.

\inputminted[firstline=16,lastline=33]{coq}{Listings/Airlock.v}

This reads as follows: we distinguish between four classes of transitions, one
per actions.
%
On the one hand, a transition which implies to open a door (case one and three)
requires the both doors to be closed.
%
On the other hand, a transition which implies to close a door (case two and
four) requires the door to be closed.

The security property of our airlock system is a safety property: at any time,
at least one door is close.
%
This property is a predicate on the system state, which we can define in
{\scshape Gallina} \emph{via} the \texttt{Prop} type.

\inputminted[firstline=35,lastline=38]{coq}{Listings/Airlock.v}

For the airlock to be secure, this means the \texttt{secure\_airlock} predicate
must hold true before and after each transition.
%
We can express that in the form of a \emph{lemma}, that is a logical statement
for each we exhibit a proof.
%
We write the proof with {\scshape Ltac}, and trust Coq to refuse it in case it
is incorrect.
%
The proof is written in terms of {\scshape Ltac} tactics.
%
Each tactic corresponds to an inference rule.
%
For instance, the \texttt{right} tactic refers to the fact that given two
statements $P$ and $Q$, then if $Q$ is true, then $P \vee Q$ is also
true. Tactics updates the proof obligation (initially the lemma statement), and
the goal of a Coq user is to bring back this proof obligation to something that
has already been proven.

\inputminted[firstline=40,lastline=57]{coq}{Listings/Airlock.v}

This reads as follows: we prove that, given any ``secure state'', that is a
airlock for which the \texttt{secure\_airlock} holds true, any action which
implies a system's state update, the \texttt{secure\_airlock} also holds true
for the system's state after the transition.
%
The proof is conducted by enumeration of possible actions (\texttt{induction}),
and by definition of \texttt{Transition} (\texttt{inversion}).

\thomasrk[inline]{So? Quelle est la conclusion de cette section? Pourquoi va-tu
  choisir dans ton approche de faire du Coq?}

% \section{A Tour of Large Verified Systems}
% \label{sec:sota:relatedwork}

% \subsection{Hardware Systems}

% \paragraph{Intel.}

% \paragraph{ARM.}

% \paragraph{XOM.}

\section{Where this Thesis Stands}

\subsection{Specifying and Verifying Hardware-based Security Enforcement
  Mechanisms}

Formal verification consists in proving the correctness of a system,
characterized by a mathematical model, with respect to certain properties,
defined as logic formula.
%
By definition, \ac{hse} mechanisms fall between two domains that are hardware
design verification and low-level software components verification.

On the one hand, hardware designs verification often focus on properties
transparent to the executed software components (\emph{e.g.} cache
coherency\,\cite{stern1995cachecoherence}, linearizability of SGX
instructions\,\cite{leslie2015sgx}, hardware-based memory
isolation\,\cite{lie2003xom}).
%
Security gap in interactions of multiple platform components are less subject to
formal verification, due to their increasing
complexity\,\cite{potlapally2011hardwaresecurity}.
%
Yet they are responsible for architectural attacks we want to avoid.
%
On the other hand, low-level software components such as
seL4\,\cite{klein2009sel4} or CertiKOS\,\cite{gu2016certikos} use the features
exposed by these components, and are verified against \emph{ad hoc} hardware
models, whose scope is often limited to necessary hardware features.
%
We steer a middle course between these approaches.
%
We would rather characterize sets of requirements over low-level software
components, such that satisfying these requirements is sufficient to ensure the
hardware architecture enforces a certain property.
%
As a first step, we can verify the correctness of these requirements against a
hardware model.
%
The long term goal of this approach is to focus the verification of low-level
software components on proving they satisfy these requirements.
%
As such, our approach relates to previous research works such as
RockSalt\,\cite{morrisett2012rocksalt} (validation of arbitrary programs against
a verified software-based fault isolation\,\cite{wahbe1994sfi} policy) or
Moat\,\cite{sinha2015moat} (verification of SGX
enclave\,\cite{costan2016sgxexplained} programs with respect to
confidentiality).

\subsection{Compositional Verification of Hardware Architecture}

\bibliographystyle{unsrt}%
\bibliography{manuscript}
\end{document}