%!TEX root = ../main.tex
\chapter{Specifying and Verifying a BIOS HSE Mechanism}
\label{chapter:speccert2}

\endquote{``\emph{BIOS as the root of trust. For everything.}''

  \hfill\footnotesize --- Joanna Rutkowska}

\vspace{1cm}\noindent
%
In the previous chapter, we have introduced a formal definition for \ac{hse}
mechanisms, whose purpose is to be the foundation of a three-step methodology to
formally specify and verify \ac{hse} mechanisms.
%
We now apply this methodology to specify and verify the \ac{hse} mechanism
implemented by the \ac{bios} on x86 hardware architecture at runtime and
described in Section~\ref{sec:usecase:hse}.
%
The purpose of this \ac{hse} mechanisms is to provide an isolated execution
environment to the \ac{bios}. It relies on the System Management Mode (SMM) and
the System Management Interrupt (SMI).

First, we formally specify the targeted security policy for this \ac{hse}
mechanism.
%
We take the approach of proposing a generic class of security policies we later
specialize for our use case (Section~\ref{sec:speccert2:usecase}).
%
Then, we define a minimal x86 hardware model we call {\scshape Minx86}, whose
scope is limited to the hardware features required to express our use case
(Section~\ref{sec:speccert2:minx86}).
%
Finally, we give a formal definition of the \ac{hse} mechanism implemented by
the \ac{bios} at runtime, and show that this definition satisfies the two
\ac{hse} laws and is correct with respect to the targeted security policy
previously introduced (Section~\ref{sec:speccert2:verif}).

The model and proofs described in this Chapter have been implemented using Coq.
%
We have released this development as free software in a project called SpecCert\,\footnote{SpecCert can be found at the following
  URL: \url{https://github.com/lthms/speccert}}.
%
As we introduce new definitions and theoretical results, we point to the related
statements in SpecCert, so the interesting reader familiar with Coq can
read our machine-checked proofs. \TODO{The reader... can read fait un peu répétition}

\section{Specifying BIOS Isolation Policy}
\label{sec:speccert2:usecase}

We now focus on a class of security policies we call \emph{isolation policies} \TODO{es-tu vraiment le seul (et le premier) a parler de isolation policy? c'est le "we call" qui me fait tiquer}.
%
Such a policy prevents a software component to tamper with the execution of
lower levels of the software stack. \TODO{Pourquoi s'embarquer dans les histoire de position dans la software stack. J'ai pas l'impression que cette histoire de hierarchie dans une stack est été formellement définie. Je préfererais qu'on parle de code trusté/non trusté.}
%
We consider that a software component tampers with the execution of another when
it is able to make the latter execute an instruction of its choice, that is the
former achieves a code injection against the latter. \TODO{Evite les longues phrases avec "le premier, le second, etc.". A la fin on s'y perd. Il est préférable dans ce cas de nommer les deux composants et d'utiliser leur nom par la suite. Par exemple, soit deux composant A et B... }
\TODO{Outre la remarque précédente, je n'ai pas l'impression que "make the latter execute an instruction of its choice" soit synonyme de "code injection". J'ai l'impression que la définition inclut également du Code Reuse Attack (l'attaquant fait bien exécuter du code de son choix à la cible également dans ce cas, même si les instruction appartiennent à du code légitime de la cible). En outre, si c'est bien de "code injection" dont tu veux parler, dit le dès le début et n'essaie pas de redéfinir ce concept d'une manière alambiqué et au final ambigue.}
%
This is a particular sub-case of the Integrity property
(Definition~\ref{def:usecase:int}) \TODO{Le label de la définition est cassé}, as we focus on instructions fetches
exclusively. \TODO{Pas claire mais je ne suis pas allez chercher ce que la propriété disait..}
%
It is true than, usually, the word ``isolation'' refers to stronger security
properties; for instance, the guests isolation of the idealized hypervisor of
Gilles Barthe \emph{et al.} is a hyperproperty similar to
non-interference\,\cite{barthe2011virtcert1}.
%
However, enforcing such a property is a task mostly tackled by system software. \TODO{Cette partie justificative est un peu casse gueule, je trouve. Déjà, utiliser un mot qui, généralement, à un autre sens dans la plupart des travaux (ce que tu sembles avancer) n'est pas une bonne idée. Il faut peut être changer le nom, dans ce cas. En outre, je ne vois pas pourquoi une propriété plus forte devrait être mise en oeuvre seulement dans des couches supérieures (system software). A mon avis, la propriété dépend du modèle d'attaquant considéré. Il faudrait un peu plus développer ces aspects. Par contre, pas sur qu'on soit si générique dans ce cas...}

First, we give a definition of code injection (\ref{subsec:speccert:tampering}).
%
We leverage it as a foundation for defining isolation policies which apply to
complete software stacks (\ref{subsec:speccert:globalsec}). \TODO{Ce label aussi est cassé}
%
\TODO{Que veux dire "complete software stacks"?}
Finally, we introduce isolation sub-policies, and define the \ac{bios} isolation
policy as an isolation sub-policy (\ref{subsec:speccert:biossec}).

\subsection{Code Injection}
\label{subsec:speccert:tampering}

A memory location within a hardware architecture is a container which is able to
store data used by a software component \emph{e.g.}~a general-purpose register
of a \ac{cpu}, a \ac{dram} memory cell, etc.
%
To formally define a code injection, it is necessary to be able to map an
instruction executed by the \ac{cpu} to the software component which has written
this instruction into its memory location.
%
A hardware model tracks the memory location ownership when the hardware
architecture state maps each memory location with a software component called
its \emph{owner}, and transition relation updates this mapping throughout
traces.
%
A software component becomes the new owner of a memory location when it
overwrites its content during a transition.
%
By extension, we say a software component owns some data when it owns the memory
location in which these data are stored.

With this mapping, it becomes possible to determine the owner of an instruction
fetched by the \ac{cpu} in order to be decoded and executed.

\begin{definition}[Transition-Software Mapping]
  \label{def:speccert2:transsoft}
  A transition-software mapping
  $\func{fetched}_{\Sigma}: H \times L \rightarrow \powerset(S)$ is a function
  which takes an initial hardware state, a transition label and returns the set
  of owners of the fetched instructions during this transition.
\end{definition}

Hence, $s \in \func{fetched}_{\Sigma}(h, l)$ means that an instruction owned by
$s$ was fetched in order to be executed by the \ac{cpu} during a transition
labelled with $l$ from a state $h$.

With a hardware-software mapping and an event-software mapping, we give a formal
definition of a \textit{code injection}.

\begin{definition}[Code Injection]
  \label{def:speccert:tempering}
  A software component $x \in S$ achieves a code injection against another
  software component $y \in S$ during a transition labelled with $l \in L$ from
  a state $h \in H$ to a state $h' \in H$, denoted by
  %
  \[
    h \xrightarrow[x \leadsto y]{l} h'
  \]
  %
  when the \ac{cpu} fetches an instruction owned by $x$ while executing $y$,
  that is
  %
  \[
    h \xrightarrow[x \leadsto y]{l} h' \triangleq x \in
    \func{fetched}_{\Sigma}(h, l) \wedge \func{context}(h) = y
  \]

  We write $h \xrightarrow[x \not\leadsto y]{l} h'$ when $x$ does not achieve a
  code injection against~$y$.  with the execution of~$y$.
\end{definition}

\begin{example}[Application Code Injection]
  When the user of a computer starts a new application, the operating system
  loads the code of this application into the \ac{dram}. Therefore, when the
  \ac{cpu} starts the execution of the application in ring3, it executes
  instructions which are owned by the OS.
\end{example}

\begin{example}[Thinkpwn Code Injection]
  The \ac{bios} of certain Lenovo laptops were subject to a trivial attack
  called Thinkpwn\,\cite{cr4sh2016thinkpwn}.
  %
  Under certain circumstances, the \ac{smm} code was using the content of a
  structure provided by a untrusted source (\emph{e.g.} system software) as a
  function pointer.
  %
  As a consequence, it was possible for a malicious system software to achieve a
  code injection against the \ac{bios}.
  %
  The result was a privilege escalation.
\end{example}

\begin{example}[SMRAM Cache Poisoning]
  The SMRAM cache poisoning attack\,\cite{duflot2009smram,wojtczuk2009smram} can
  be used to perform a code injection attack against the \ac{bios}. For
  instance, Loic Duflot \emph{et al.} have been able to inject the necessary
  instructions inside the cache for the \ac{cpu} so that the \ac{bios} updates
  the \texttt{SMBASE} register.
\end{example}

\subsection{Isolation Policies}
\label{subsec:speccert2:globalsec}

We leverage the code injection definition to propose a generic formalization of
\emph{isolation policies}, to determine if a given software component is
authorized to tamper with the execution of another software component in the
context of a software stack.

\begin{definition}[Isolation Policy]
  \label{def:speccert:global}
  A isolation policy $I$ is a safety property characterized by a tuple
  $\langle S, \rightarrowtail, \func{context} \rangle$, such that
  %
  \begin{itemize}
  \item $S$ is a set of software components executed by the hardware
    architecture'
  \item $\rightarrowtail$ is a binary relation on $S$, such that given
    $(x, y) \in S \times S$, $x \rightarrowtail y$ means $x$ is authorized to
    tamper with the execution of $y$. $\rightarrowtail$ has to be
    %
    \begin{inparaenum}[(1)]
    \item anti-symmetric, and
    %
    %
    \item transitive.
    %
    \end{inparaenum}
    %
    \[
      \begin{array}{lr}
        \forall (x, y) \in S \times S,
        & \\
        \qquad x \rightarrowtail y \wedge y
        \rightarrowtail x \Rightarrow x = y
        & \text{\small (1)} \\
        %
        \forall (x, y, z) \in S \times S \times S,
        & \\
        \qquad x \rightarrowtail y \wedge y
        \rightarrowtail z \Rightarrow x \rightarrowtail z
        & \text{\small (2)}
      \end{array}
    \]
    %
  \item \func{context} is a hardware-software mapping.
  \end{itemize}

  A transition labelled with $l \in L$ from $h \in H$ to $h' \in H$ satisfies I
  when code injections which occur during this transition are authorized by
  $\rightarrowtail$, that is
  %
  \[
    I(h, l, h') \triangleq \forall (x, y) \in S \times S \text{, } h
    \xrightarrow[x \leadsto y]{l} h' \Rightarrow x \rightarrowtail y
  \]
\end{definition}

\begin{corollary}
  If a transition satisfies $I$, then no code injection which is not authorized
  by $\rightarrowtail$ occurs during that transition, that is
  %
  \[
    I(h, l, h') \iff \forall (x, y) \in S \times S \text{, } y \not\ge x
    \Rightarrow h \xrightarrow[y \not\leadsto x]{l} h'
  \]

  \begin{proof}
    This is the contrapositive of Definition~\ref{def:speccert:global}.
  \end{proof}
\end{corollary}

\begin{example}[Software Stack Isolation]
  \label{example:speccert2:isolation}
  Using our definition, we can define a isolation policy for a whole software
  stack which comprises the \ac{bios}, an operating system and several
  applications, that is
  %
  \[
    S \triangleq \{ \mathtt{bios}, \mathtt{os}, \mathtt{app}_1, \dots
    \mathtt{app}_n \}
  \]

  We define the authorization relation $\rightarrowtail$ using three rules:
  %
  \begin{description}
  \item [\(\rightarrowtail\)-refl:] A software component is authorized to tamper
    with its own execution, that is
    %
    \[ \forall x \in S, x \rightarrowtail x \]
    %
  \item [\(\rightarrowtail\)-bios:] The \ac{bios} is authorized to tamper with
    the execution of the rest of the software stack, that is
    %
    \[ \forall x \in S, \mathtt{bios} \rightarrowtail x \]
  \item [\(\rightarrowtail\)-os:] The OS is authorized to tamper with the
    execution of the application it manages, that is
    %
    \[ \forall k \in [0, n], \mathtt{os} \rightarrowtail \mathtt{app}_k \]
  \end{description}

  We prove by case enumeration that $\rightarrowtail$ is anti-symmetric and
  transitive.

  The definition of $\func{context}$ shall obey the following logic: when the
  \ac{cpu} is in \ac{smm}, the \ac{bios} is executed; when the \ac{cpu} is not
  in \ac{smm} and is in ring 0, the system software component is executed; when
  the \ac{cpu} is not in \ac{smm} and is in ring 3, one of the applications
  ---identified by the page tables used by the \ac{cpu}--- is executed.
\end{example}

\subsection{BIOS Isolation Policy}
\label{subsec:speccert:biossec}

A security policy such as the one detailed in
Example~\ref{example:speccert2:isolation} is not enforced by one but many HSE
mechanisms.
%
We can break it down to more specific security policies
%
For instance, w
We use this approach to define the \ac{bios} isolation policy we seek to define
in this Section.

\begin{definition}[BIOS Isolation Sub-policy]
  \label{def:speccert:biospol}
  Given $I$ an isolation policy, we write $I_{\mathtt{bios}}$ for the isolation
  sub-policy, whose purpose is to enforce that only the \ac{bios} can tamper
  with its own execution, that is
  %
  \[
    I_{\mathtt{bios}}(h, l, h') \triangleq \forall x \in S, h \xrightarrow[x
    \leadsto \mathtt{bios}]{l} h' \Rightarrow x = \mathtt{bios}
  \]
\end{definition}

%\begin{example}[BIOS Isolation Sub-policies]
%  \label{example:speccert2:subpolicies}
%
%  % TODO: this first paragraph should go at the end of the chapter.
%  For
%  $U_{\mathtt{apps}} = \{ \mathtt{app}_1, \mathtt{app}_2, \ldots,
%  \mathtt{app}_{n-1} \mathtt{app}_{n} \}$ the set of applications whose
%  executions have to be constrained, the related \ac{tcb} is the set
%  $T_{\mathtt{apps}}~=~\{ \mathtt{bios}, \mathtt{os} \}$.
%  %
%  $I|U_{\mathtt{apps}}$ states that one application can only tamper with its own
%  execution.
%  %
%  The responsibility to constrain the execution of applications cannot fall
%  entirely on system software.
%  %
%  For instance, the \ac{bios} executed while the \ac{cpu} is in \ac{smm} has to
%  be careful not to tamper with the page tables previously configured by the
%  system software component.
%\end{example}

\section{A Minimal x86 Hardware Model}
\label{sec:speccert2:minx86}

$\formatLTS{Minx86}$ is intended to be a minimal model for single core x86-based
machines and we have used publicly available Intel
documents\,\cite{intel2013celeron,intel2009mch,intel2014manual} to define it.
%
The hardware architecture we are modeling with $\formatLTS{Minx86}$ contains a
\ac{cpu}, a cache, a memory controller, a \ac{dram} controller and a VGA
controller\,\footnote{A VGA controller is a hardware device which on we can
  connect a screen. It exposes some memory to the \ac{cpu} for communication
  purposes.} which both expose some memory to the \ac{cpu}.

$\formatLTS{Minx86}$ is meant to illustrate how our formalism can be leveraged
to formally specify and verify a HSE mechanism, and thus is not exhaustive.
%
In its current state of implementation, its scope focuses on the \ac{smm}.

\subsection{Model Scope}
\label{sec:speccert2:scope}

\paragraph{Hardware Features}
%
We consider the \ac{cpu} can be either in System Management Mode (\ac{smm}) or
in an unprivileged mode.
%
We give a brief summary of how the \ac{smm} works.
%
We remind our readers that Section~\ref{subsec:usecase:hse:smm}
%
The \ac{smm} is ``a special-purpose operating mode provided for handling
system-wide functions like power management, system hardware control, or
proprietary OEM-designed code''\,\cite{intel2014manual}.
%
It is the most privileged execution mode of x86 processors.
%
When a \ac{cpu} receives a special hardware interrupt called System Management
Interrupt (SMI), it halts its current execution and reconfigures itself to a
specified state from which it executes the code stored in memory at the address
$\mathtt{SMBASE} + \val{0x8000}$.
%
In practice, the SMBASE value points to the base of a memory region called the
SMRAM.
%
Leaving the \ac{smm} is done by executing a special purpose instruction called
\texttt{rsm} (for \emph{resume}).

The \ac{cpu} relies on a cache to reduce the Input/Output (\IO, that is a read
or write access to the memory) latency.
%
We model one level of cache which stores both data and instructions and we
consider two cache strategies: uncacheable (UC) and writeback (WB).
%
With the UC cache strategy, the cache is not used and all \IOs are forwarded to
the memory controller, whereas with the WB strategy, the cache is used as much
as possible\,\footnote{These cache strategies are explained in
  \cite{intel2014manual}, Volume 3A, Chapter 11, Section 11.3 (page 2316 --
  2317)}.
%
To determine which cache strategy to use, the \ac{cpu} relies on several
configuration registers and mechanisms.
%
One of them is a pair of registers called the \ac{smrr} which can only be
configured when the \ac{cpu} is in \ac{smm}.
%
They are used to tell the \ac{cpu} where the SMRAM is and which cache strategy
to use for \IO targeting the SMRAM when the \ac{cpu} is in \ac{smm}.  When it is
not in \ac{smm}, the \ac{cpu} always uses the UC strategy for \IO targeting the
SMRAM.
%
\ac{smrr} have been introduced as a countermeasure of the SMRAM cache poisoning
attack\,\cite{wojtczuk2009smram,duflot2009smram} which allowed an untrusted code
to tamper with the copy of the SMRAM stored in the cache.
%
The memory controller\,\cite{intel2009mch} receives all the \ac{cpu} \IOs which
are not handled by the cache and dispatches them to the DRAM controller or to
the VGA controller. It exposes a unified view (the memory map) of the system
memory to the \ac{cpu}.
%
The \ac{cpu} manipulates this memory map with a set of addresses called the
physical addresses.
%
The memory controller dedicates a special range of physical addresses to form
the SMRAM.
%
The SMRAM is dedicated to store the code intended to be executed when the
\ac{cpu} is in \ac{smm}.

\paragraph{Tracking Memory Ownership}
%
The \formatLTS{Minx86} definition is parameterized by a hardware-software
mapping \func{context} (Definition~\ref{def:speccert:hardsoft}).
%
The memory locations of \formatLTS{Minx86} are either cache lines or memory
cells exposed by the \ac{dram} controller or the VGA controller.
%
The memory ownership is updated through transitions according to three rules:
%
\begin{enumerate}
\item When a cache line gets a copy of a \ac{dram} or VGA cell content, the
  owner of this cell becomes the new owner of this cache line.
%
\item When the content of this cache line is written back to a memory cell, the
  new owner of this memory cell is the owner of this cache line.
%
\item When the content of a memory location is overwritten during a transition,
  the software currently executed becomes the new owner of this memory location.
%
\end{enumerate}

\begin{definition}[\formatLTS{Minx86}]
  We write $\formatLTS{Minx86}(\func{context})$ for the hardware model which
  tracks memory ownership with respect to the \func{context} hardware-software
  mapping, such that
%
  \[
    \formatLTS{Minx86}(\func{context}) \triangleq \langle H(S), L_S, L_H,
    \xrightarrow[\func{context}]{} \rangle
  \]
  %
  where $S$ is the image of $\func{context}$, that is the set of software
  components which form the software stack.
\end{definition}

\subsection{Hardware States}

$H(S)$ is defined as the Cartesian product of the set of states of the
\ac{cpu}'s core, the \ac{cpu}'s cache, the memory controller and the memories
exposed by both the \ac{dram} controller and the VGA controller.
%
Each of these sets is defined in order to model the hardware features we have
previously described.
%
We use named tuples\,\footnote{See page \pageref{frontmatter:notations}.} to
define them.
%
Thus, $H(S)$ is defined as follows:
%
\[
  H(S) \triangleq \left<\ \func{core}: \texttt{Core},\quad\func{cache}:
  \texttt{Cache}(S),\quad\func{mc}: \texttt{MC},\quad\func{mem}: \texttt{Mem}(S)
  \ \right>
\]

\paragraph{Address Spaces}
%
We define $\texttt{PhysAddr}$ the set of physical addresses the \ac{cpu} uses to
perform \IO and $\texttt{HardAddr}$ the set of hardware addresses exposed by the
\ac{dram} and VGA controllers.
%
To distinguish between \ac{dram} and VGA addresses, we use two different
constructors\,\footnote{See page \pageref{frontmatter:notations}.}.
%
\[
  \begin{array}{rcl}
    \texttt{PhysAddr}
    & \triangleq
    & \textsc{Pa} : [0, \val{max\_addr}] \rightarrow
      \texttt{PhysAddr} \\
      % --------------------------------------------------------------------------
      % no type name
    & % no symbol
    & \\ % no constructor
    % --------------------------------------------------------------------------
    \texttt{HardAddr}
    & \triangleq
    & \textsc{Dram} : [0, \val{max\_addr}] \rightarrow
      \texttt{HardAddr} \\
      % --------------------------------------------------------------------------
      % type name
    & |
    & \textsc{Vga} : [0, \val{max\_addr}] \rightarrow
      \texttt{HardAddr}
  \end{array}
\]
%
The maximal address offset (denoted by $\val{max\_addr}$ here) is specific to
the \ac{cpu} and may vary in time according to its addressing mode (real mode,
long mode, etc.), therefore we left its value as a parameter of our model.
%
By convenience, we give the same maximum address to each of address space.

Finally, we write $\texttt{Val}$ for the set of values that the memory cells
scattered within the memory locations of the hardware architecture can take.

\paragraph{Core}
%
The set of states of the \ac{cpu}'s core is denoted by $\texttt{Core}$. We give
a minimal definition of $\texttt{Core}$, with a clear focus on the \ac{smm}.
%
\[
  \texttt{Core} \triangleq \left<\
    \begin{array}{c}
      \func{in\_smm} : \setshortdef{\val{true},
      \val{false}},\quad\func{pc}: \texttt{PhysAddr},\quad\func{smbase} :
      \texttt{PhysAddr}, \\
      \func{smrr} : \texttt{Smrr},\quad\func{strat} :
      \texttt{PhysAddr} \rightarrow \texttt{CacheStrat}
    \end{array}
  \right>
\]
%
The boolean $\func{in\_smm}$ is a boolean set to $\val{true}$ when the \ac{cpu}
is in \ac{smm} and to $\val{false}$ when it leaves it.
%
The physical address $\func{pc}$ models the program counter, a register used to
store the address of the next instruction to be fetched and executed.
%
The physical address $\func{smbase}$ models the register of the same name.
%
The map $\func{strat}$ abstracts away the numerous mechanisms of the x86
microprocessors to determine which cache strategy to use for a given \IO, where
$\texttt{CacheStrat} \triangleq \setshortdef{\val{UC}, \val{WB}}$ is the set of
the modelled cache strategies.
%
The set of states of the \acp{smrr} is denoted $\texttt{Smrr}$.
%
\[
  \texttt{Smrr} \triangleq \langle~\func{range}:
  \powerset(\texttt{PhysAddr}),\quad\func{strat}: \texttt{CacheStrat}~\rangle
\]
%
The set of physical addresses $\func{range}$ tells the \ac{cpu} the location of
the SMRAM and $\func{strat}$ tells which cache strategy has to be used when the
\ac{cpu} is in \ac{smm}.

% which can be available or already used. A cache line already used is tagged
% with the physical address of its content. For a given physical address, the
% \ac{cpu} computes an index to select a cache line and verify its tag.  hich
% contain, in addition to the copy of the cached memory content, a "dirty bit"
% and a tag. A cache line is marked as dirty when its content is modified which
% indicates if the cache line content has been modified without propagating the
% underlying hardware memories and the .

\paragraph{Cache}
%
Let $\texttt{Index}$ be the set of cache indexes and
$\func{index} : \texttt{PhysAddr} \rightarrow \texttt{Index}$ the function used
by the \ac{cpu} to determine which index to use for a given physical address.
%
They are both parameters of our model.
%
The cache is divided into several cache lines which contain the cached memory
content and several additional information required by the cache strategy
algorithm.
%
The set of states of the cache line is denoted by $\texttt{CacheLine}(S)$.
%
In addition to modeling the hardware specifications, the definition of
$\texttt{CacheLine}(S)$ attaches a software owner to a cache line.
%
\[
  \texttt{CacheLine}(S) \triangleq \langle~\func{dirty} :
  \setshortdef{\val{true}, \val{false}},\quad\func{tag} :
  \texttt{PhysAddr},\quad\func{content}: \texttt{Val},\quad\func{owner}:
  S~\rangle
\]
%
The cache is modelled as a mapping between address indexes and cache lines.
%
\[
  \texttt{Cache}(S) \triangleq \texttt{Index} \rightarrow \texttt{CacheLine}(S)
\]
%
A cache $c$ is well-formed if every cache line is tagged with a physical address
whose index corresponds to the cache line index, that is
%
\[
  \forall \var{i} \in \texttt{Index}, \func{index}(c(i).\func{tag}) = i
\]

\paragraph{Memory Controller}
%
The set of states of the \formatLTS{Minx86} Computing Platforms memory
controller is denoted by $\val{MC}$.
%
\[
  \texttt{MC} \triangleq \langle~\func{d\_open}: \setshortdef{\val{true},
    \val{false}},\quad\func{d\_lock}: \setshortdef{\val{true},
    \val{false}}~\rangle
\]
%
The two booleans $\func{d\_open}$ and $\func{d\_lock}$ model two bits of a
configuration register named \texttt{smramc}.
%
They are used to determine how the memory controller dispatches the \IO which
targets a physical address of the SMRAM.
%
For a memory controller state $\var{mc} \in \texttt{MC}$ to be consistent with
respect to the hardware specifications, it has to verify that
%
\[
  \var{mc}.\func{d\_lock} = \val{true} \Rightarrow \var{mc}.\func{d\_open} =
  \val{false}
\]

We model the SMRAM with two ranges of addresses:
%
\begin{itemize}
\item
  $\texttt{hSmram} \triangleq \setdef{\textsc{Dram}(i)}{\val{smram\_base} \leq i
    \le \val{smram\_end}}$ the SMRAM memory range within the DRAM memory
%
\item
  $\texttt{pSmram} \triangleq \setdef{\textsc{Pa}(i)}{\val{smram\_base} \leq i
    \le \val{smram\_end}}$ the projection of the SMRAM in the address space
  manipulated by the core
\end{itemize}
%
The values of $\val{smram\_base}$ and $\val{smram\_end}$ are specified in the
memory controller specifications and are left as a parameter of our model.
%
It is the software responsability to set the \ac{smrr} accordingly.
%
We assume $\val{smram\_end} - \val{smram\_base} > \val{0x8000}$, that is the
first instruction executed by the core after entering \ac{smm} (that is
$\texttt{SMBASE} + \val{0x8000}$) is inside the SMRAM if the \texttt{SMBASE}
register is correctly configured.

The memory controller translates physical addresses into hardware addresses and
forwards the \IO accordingly.
%
We model this translation with the function
%
\[
  \func{dispatch} : \texttt{MC} \times
  \setshortdef{\val{true},\,\val{false}} \times \texttt{PhysAddr} \rightarrow
  \texttt{HardAddr}
  %
\]
%
\[
  \func{dispatch}(\var{mc}, \var{in\_smm}, \var{pa}) \triangleq
  \begin{cases}
    \textsc{Vga}(i) & \text{if }\var{in\_smm} = \val{false}\text{, }pa \in
    \texttt{pSmram}\text{,} \\
    & \quad\text{ and } \var{mc}.\func{d\_open} = \val{true}  \\
    \textsc{Dram}(i) & \text{otherwise}
  \end{cases}
\]
%
\qquad\qquad\qquad\qquad\qquad\qquad where $pa = \textsc{Pa}(i)$.

We emphasize that the same physical address can be translated into two different
hardware addresses for two memory controller states $m$ and $m'$, hence it is
possible to have
%
\[
  \func{dispatch}(m, b, pa) \neq \func{dispatch}(m', b, pa)
\]

\paragraph{Memories}
%
The physical memories (exposed by the DRAM controller and the VGA controller)
are modelled together with a mapping between the hardware addresses and both the
content and the software component which owns the related memory location.
%
We write $\texttt{Mem}(S)$ for the set of states of the physical memories.
\[
  \texttt{Mem}(S) \triangleq \texttt{HardAddr} \rightarrow
  \langle~\func{content}: \texttt{Val},\quad\func{owner}: S~\rangle
\]

% \paragraph{}% Conclusion of the subsection
% %
% The hardware architecture states are implemented in the
% \emph{SpecCert.x86.Archi\-tecture} module (about 1\,500 lines of code).
% %
% In addition to the state definitions, we have implemented several helper
% functions and predicates.
% %
% For instance,
% %
% \begin{itemize}
% \item
%   $\func{address\_location\_owner} : H(S) \times \texttt{PhysAddr} \rightarrow
%   S$
%   \begin{quote}
%     \small Given a hardware architecture state and a physical address, returns
%     the memory content software owner
%   \end{quote}
% %
% \item $\func{cache\_hit}$, a predicate on $H(S) \times \texttt{PhysAddr}$
%   \begin{quote}
%     \small Given a hardware architecture state and a physical address, holds
%     true if the memory content is in the cache
%   \end{quote}
% %
% \item $\func{cache\_line\_owner} : H(S) \times \texttt{Index} \rightarrow S$
%   \begin{quote}
%     \small Given a hardware architecture state and a cache line index, returns
%     the owner of this cache line
%   \end{quote}
% %
% \item
%   $\func{resolve\_cache\_strategy} : H(S) \times \texttt{PhysAddr} \rightarrow
%   \texttt{CacheStrat}$
%   \begin{quote}
%     \small Given a hardware architecture state and a physical address, returns
%     the cache strategy used by the \ac{cpu} for this address
%   \end{quote}
% %
% \item
%   $\func{translate\_physical\_address} : H(S) \times \texttt{PhysAddr}
%   \rightarrow \texttt{HardAddr}$
%   \begin{quote}
%     \small Given a hardware architecture state and a physical address, returns
%     the result of the memory controller address translation
%   \end{quote}
% \end{itemize}

\subsection{Transition Labels and Transition Relation}

We consider two sets of labels to distinguish between software transitions
(direct, foreseeable consequences of instructions execution, denoted by $L_S$)
and hardware transitions (denoted by $L_H$).
%
As for the transition relation, we define it in terms of pre and postconditions.
%
That is, we define for each transition label
%
\begin{inparaenum}[(1)]
\item a precondition to determine whether the transition can occur from a given
  hardware state, and
    %
\item a postcondition to specify the consequences of the transitions over the
  hardware architecture state.
\end{inparaenum}
%
Let \func{pre} be a predicate on \( L \times H(S) \), and \func{post} be a
predicate on \( L \times H(S) \times H(S) \), then the transition relation of
{\scshape Minx86} is defined as follows:
%
\[
  h \xrightarrow[\func{context}]{l} h' \triangleq \func{pre}(l, h) \wedge
  \func{post}(l, h, h')
\]

% and~\ref{tab:speccert2:hardlab}
\begin{table}[t]
  \centerline{%
    \begin{tabular}{lp{3cm}p{6cm}}
      \hline
      \multicolumn{1}{c}{\scshape Event}
      & \multicolumn{1}{c}{\scshape Parameters}
      & \multicolumn{1}{c}{\scshape Description} \\
      \hline
      \( \func{Write} \)
      & \( \var{pa} \in \texttt{PhysAddr} \) \newline
        \( v \in \texttt{Val} \)
      & A \ac{cpu} \IO to write at physical address \( \var{pa} \) the value \(
        v \) \\
      \hline
      \( \func{Read} \)
      & $\var{pa} \in \texttt{PhysAddr}$
      & A \ac{cpu} \IO to read at physical address \( \var{pa} \). \\
      \hline
      \( \func{SetCacheStrat} \)
      & \( \var{pa} \in \texttt{PhysAddr} \) \newline
        \( \var{strat} \in \texttt{CacheStrat} \)
      & Change the cache strategy for \( \var{pa} \) to \( \var{strat} \) \\
      \hline
      \( \func{UpdateSmrr} \)
      & \( \var{smrr} \in \texttt{Smrr} \)
      & Update the \ac{smrr} content with the new value \( smrr \) \\
      \hline
      \( \func{Rsm} \)
      & \centering ---
      & The \ac{cpu} leaves \ac{smm} \\
      \hline
      \( \func{OpenBitFlip} \)
      & \centering ---
      & Flip the \texttt{d\_open} bit \\
      \hline
      \( \func{LockSmramc} \)
      & \centering ---
      & Set the \texttt{d\_lock} bit \\
      \hline
      \( \func{NextInstruction} \)
      & \( \var{pa} \in \texttt{PhysAddr} \)
      & The program counter register of the \ac{cpu} is set to \( \func{pa} \) \\
      \hline
    \end{tabular}
  }
  \caption{List of labels dedicated to {\scshape Minx86} software transitions
    (\( L_S \))}
  \label{tab:speccert2:softlab}
\end{table}

\paragraph{Software Transitions}
%
Table~\ref{tab:speccert2:softlab} lists the labels dedicated to software
transitions in terms of constructors.
%
We model the \ac{cpu} \IOs with \( \func{Read}(\var{pa}) \) and
\( \func{Write}(\var{pa}) \), the configuration of the memory controller with
\( \func{OpenBitFlip} \) and \( \func{LockSmramc} \), the configuration of the
cache strategy with \( \func{SetCacheStrat}(\var{pa}, \var{strat}) \), the
configuration of the \ac{smrr} with \( \func{UpdateSmrr}(\var{smrr}) \) the exit
of the \ac{smm} with $\func{Rsm}$ and the update of the \ac{cpu} program counter
register with $\func{NextInstruction}(\var{pa})$.
%
As an example, the pre and postconditions of the \func{Write} transitions are
formally defined in Figure~\ref{fig:speccert2:softprepost}.
%
They are presented under the following form:
%
\begin{prooftree}
  \AxiomC{\func{pre}(l, h)}%
  \AxiomC{\func{post}(l, h, h')}%
  \BinaryInfC{\( h \xrightarrow[\func{context}]{l} h' \)}%
\end{prooftree}
%
For the remainder, we give a informal description of the pre and postconditions.
%
The interested readers can always refer to the Coq development in case they want
to review their definitions.

\begin{figure}[p]
  {\small
    \begin{prooftree}
      \AxiomC{%
        \(
        \begin{array}{l}
          h.\func{core}.\func{strat}(\var{pa}) = \val{WB} \\
          \wedge~\func{cache\_hit}(h.\func{cache}, \var{pa}) \\
          \wedge~\var{pa} \not\in h.\func{smrr}.\func{range}
        \end{array}
        \) }%
      \AxiomC{%
        \( h' = h \left\{ \func{cache}(\func{index}(\var{pa})) \leftarrow
          h.\func{cache}(\func{index}(\var{pa}))\left\{
            \begin{array}{c}
              \func{content} \leftarrow v, \\
              \func{dirty} \leftarrow \val{true}
            \end{array}
          \right\} \right\} \) }%
      \BinaryInfC{%
        \( h \xrightarrow[\func{context}]{\func{Write}(\var{pa}, v)} h' \) }
    \end{prooftree}

    \begin{prooftree}
      \AxiomC{%
        \(
        \begin{array}{l}
          h.\func{core}.\func{strat}(\var{pa}) = \val{WB} \\
          \wedge~\neg~\func{cache\_hit}(h.\func{cache}, \var{pa}) \\
          \wedge~\var{pa} \not\in h.\func{smrr}.\func{range}
        \end{array}
        \) }%
      \AxiomC{%
        \(
        \begin{array}{l}
          \text{let } \var{ha} = \func{dispatch}(h.\func{mc}, h.\func{in\_smm},
          \var{pa}) \\
          \text{let } \var{i} = \func{index}(\var{pa}) \\
          h' = h \left\{
          \begin{array}{c}
            \func{mem}(\var{ha})
            \leftarrow \left<
            \begin{array}{c}
              \func{content} = h.\func{cache}(i).\func{content}, \\
              \func{owner} = h.\func{cache}(i).\func{owner} \\
            \end{array}
            \right>, \\
            \func{cache}(i) \leftarrow \left<
            \begin{array}{c}
              \func{content} = v, \func{tag} = \var{pa}, \\
              \func{owner} = \func{context}(h), \func{dirty} = \val{true}
            \end{array}
            \right>
          \end{array}
          \right\}
        \end{array}
        \) }%
      \BinaryInfC{%
        \( h \xrightarrow[\func{context}]{\func{Write}(\var{pa}, v)} h' \) }
    \end{prooftree}

    \begin{prooftree}
      \AxiomC{%
        \(
        \begin{array}{l}
          h.\func{core}.\func{smrr}.\func{strat} = \val{WB} \\
          \wedge~\func{cache\_hit}(h.\func{cache}, \var{pa}) \\
          \wedge~\var{pa} \in h.\func{smrr}.\func{range} \\
          \wedge~h.\func{core}.\func{in\_smm} = \val{true}
        \end{array}
        \) }%
      \AxiomC{%
        \( h' = h \left\{ \func{cache}(\func{index}(\var{pa})) \leftarrow
          h.\func{cache}(\func{index}(\var{pa}))\left\{
            \begin{array}{c}
              \func{content} \leftarrow v, \\
              \func{dirty} \leftarrow \val{true}
            \end{array}
          \right\} \right\} \) }%
      \BinaryInfC{%
        \( h \xrightarrow[\func{context}]{\func{Write}(\var{pa}, v)} h' \) }
    \end{prooftree}

    \begin{prooftree}
      \AxiomC{%
        \(
        \begin{array}{l}
          h.\func{core}.\func{smrr}.\func{strat} = \val{WB} \\
          \wedge~\neg~\func{cache\_hit}(h.\func{cache}, \var{pa}) \\
          \wedge~\var{pa} \in h.\func{smrr}.\func{range} \\
          \wedge~h.\func{core}.\func{in\_smm} = \val{true}
        \end{array}
        \) }%
      \AxiomC{%
        \(
        \begin{array}{l}
          \text{let } \var{ha} = \func{dispatch}(h.\func{mc}, h.\func{in\_smm},
          \var{pa}) \\
          \text{let } \var{i} = \func{index}(\var{pa}) \\
          h' = h \left\{
          \begin{array}{c}
            \func{mem}(\var{ha})
            \leftarrow \left<
            \begin{array}{c}
              \func{content} = h.\func{cache}(i).\func{content}, \\
              \func{owner} = h.\func{cache}(i).\func{owner} \\
            \end{array}
            \right>, \\
            \func{cache}(i) \leftarrow \left<
            \begin{array}{c}
              \func{content} = v, \func{tag} = \var{pa}, \\
              \func{owner} = \func{context}(h), \func{dirty} = \val{true}
            \end{array}
            \right>
          \end{array}
          \right\}
        \end{array}
        \) }%
      \BinaryInfC{%
        \( h \xrightarrow[\func{context}]{\func{Write}(\var{pa}, v)} h' \) }
    \end{prooftree}

    \begin{prooftree}
      \AxiomC{%
        \(
        \begin{array}{l}
          h.\func{core}.\func{strat}(\var{pa}) = \val{UC} \\
          \wedge~\var{pa} \not\in h.\func{smrr}.\func{range}
        \end{array}
        \) }%
      \AxiomC{%
        \(
        \begin{array}{l}
          \text{let } \var{ha} = \func{dispatch}(h.\func{mc}, h.\func{in\_smm},
          \var{pa}) \\
          h' = h \left\{
          \begin{array}{c}
            \func{mem}(\var{ha})
            \leftarrow \left<
            \begin{array}{c}
              \func{content} = v, \\
              \func{owner} = \func{context}(h) \\
            \end{array}
            \right>
          \end{array}
          \right\}
        \end{array}
        \) }%
      \BinaryInfC{%
        \( h \xrightarrow[\func{context}]{\func{Write}(\var{pa}, v)} h' \) }
    \end{prooftree}

    \begin{prooftree}
      \AxiomC{%
        \(
        \begin{array}{l}
          h.\func{core}.\func{smrr}.\func{strat} = \val{UC} \\
          \wedge~\var{pa} \in h.\func{smrr}.\func{range} \\
          \wedge~h.\func{core}.\func{in\_smm} = \val{true}
        \end{array}
        \) }%
      \AxiomC{%
        \(
        \begin{array}{l}
          \text{let } \var{ha} = \func{dispatch}(h.\func{mc}, h.\func{in\_smm},
          \var{pa}) \\
          h' = h \left\{
          \begin{array}{c}
            \func{mem}(\var{ha})
            \leftarrow \left<
            \begin{array}{c}
              \func{content} = v, \\
              \func{owner} = \func{context}(h) \\
            \end{array}
            \right>
          \end{array}
          \right\}
        \end{array}
        \) }%
      \BinaryInfC{%
        \( h \xrightarrow[\func{context}]{\func{Write}(\var{pa}, v)} h' \) }
    \end{prooftree}

    \begin{prooftree}
      \AxiomC{%
        \(
        \begin{array}{l}
          \var{pa} \in h.\func{smrr}.\func{range} \\
          \wedge~h.\func{core}.\func{in\_smm} = \val{false}
        \end{array}
        \) }%
      \AxiomC{%
        \( h' = h \) }%
      \BinaryInfC{%
        \( h \xrightarrow[\func{context}]{\func{Write}(\var{pa}, v)} h' \) }
    \end{prooftree}
  }

  \caption{Pre and postconditions for {\scshape Minx86} \( \func{Write} \)
    transitions}
  \label{fig:speccert2:softprepost}
\end{figure}

A software component can always read and write at any physical address.
%
As a consequence, the precondition for \( \func{Read}(\var{pa}) \) and
\( \func{Write}(\var{pa}) \) always holds true.
%
The postcondition for \( \func{Read}(\var{pa}) \) and
\( \func{Write}(\var{pa}) \) requires the memory content and ownership to be
updated according to the memories and cache state updates.
%
The memory controller enforces a simple access control to protect the
SMRAM content in the DRAM memory by forwarding the related \IO to the VGA
controller when the \ac{cpu} is not in \ac{smm};
%
this is modelled by the \func{dispatch} function.
%
To determine the owner of the memory location which sees its content overriden
during a state transformation, the postcondition uses the hardware-software
mapping passed as a parameter of {\scshape Minx86}.

A software component can always update the cache strategy used for an \IO.
%
The postcondition for \( \func{SetCacheStrat}(pa,strat) \) requires only the
cache strategy setting for this physical address $\var{pa}$ to change.
%
The precondition for \( \func{UpdateSmrr} \) requires the \ac{cpu} to be in
\ac{smm}.
%
The postcondition requires the \ac{smrr} of the \ac{cpu} to be updated with the
correct value, the rest of the hardware architecture state being left unchanged.

A software component can jump to any physical address, that is the precondition
for the label \( \func{NextInstruction}(\var{pa}) \) always holds true.
%
The postcondition for \( \func{NextInstruction}(\var{pa}) \) requires the
program counter register to be updated with \( \var{pa} \).
%
The \( \func{OpenBitFlip} \) precondition requires the \texttt{SMRAMC} register
to be unlocked.
%
The postcondition requires the \texttt{d\_open} bit to be updated. The
$\func{LockSmramc}$ precondition requires the \texttt{d\_lock} bit to be
unset.
%
The postcondition requires the $\texttt{d\_open}$ bit to be unset and the
\texttt{d\_lock} bit to be unset.

\begin{table}[t]
  \bigcentering
  \begin{tabular}{lp{9cm}}
    \hline
    \multicolumn{1}{c}{\scshape Event}
    & \multicolumn{1}{c}{\scshape Description} \\
    \hline
    \(\func{ReceiveSMI}\)
    & A \ac{smi} is raised and the \ac{cpu} enters \ac{smm} \\
    \hline
    \(\func{Fetch}\)
    & A \ac{cpu} \IO to fetch the instruction stored at the physical address
      contained in the program counter register \\
    \hline
  \end{tabular}
  \caption{List of labels dedicated to {\scshape Minx86} hardware transitions
    (\( L_H \))}
  \label{tab:speccert2:hardlab}
\end{table}

\paragraph{Hardware Transitions}
Table~\ref{tab:speccert2:hardlab} lists the labels dedicated to hardware
transitions in terms of constructors.

\begin{figure}
  \centering
  \begin{prooftree}
    \AxiomC{\( h.\func{core}.\func{in\_smm} = \val{false} \)}%
    \AxiomC{\( h' = h \left\{
        \begin{array}{c}
          \func{core}.\func{in\_smm} \leftarrow \val{true}, \\
          \func{core}.\func{pc} \leftarrow h.\func{core}.\func{smbase} + \val{0x8000}
        \end{array}
      \right\} \)}%
    \BinaryInfC{\( h \xrightarrow[\func{context}]{\func{ReceiveSMI}} h' \)}
  \end{prooftree}

  \caption{Pre and postconditions for {\scshape Minx86} \func{ReceiveSMI}
    transitions}
  \label{fig:speccert2:receiveSMI}
\end{figure}

\func{ReceiveSMI} models a System Management Interrupt being raised and handled
by the \ac{cpu}.
%
Its precondition requires the \ac{cpu} not to be in \ac{smm} because \ac{smm} is
non-reentrant.
%
The postcondition of \func{ReceiveSMI} requires the program counter to be set to
$\texttt{SMBASE} + \val{0x8000}$ and the \ac{cpu} is in \ac{smm}.
%
Both the pre and postcondition of \func{ReceiveSMI} are formally defined in
Figure~\ref{fig:speccert2:receiveSMI}.
%
$\func{Fetch}$ models the \IO to fetch the instruction pointed by the program
counter register.
%
As a consequence, the definition of its precondition and postcondition are the
same as $\func{Read}(\var{pa})$ with $\var{pa}$ being the program register
value, that is
%
\[
  h \xrightarrow[\func{context}]{\func{Read}(h.\func{pc})} h' \Rightarrow h
  \xrightarrow[\func{context}]{\func{Fetch}} h'
\]
%
We distinguish between \func{Read} and \func{Fetch} because a software component
does not always decide the value of the program counter register of the Core.
%
For instance, the value of the program counter is updated during a
\func{ReceiveSMI} transition.

\paragraph{Transition-Software Mapping}
%
We define \(\textsc{Minx86}\func{\_fetched}\) a transition-software mapping for
$\formatLTS{Minx86}$ (Definition~\ref{def:speccert2:transsoft}).
%
The \(\textsc{Minx86}\func{\_fetched}\) function maps an initial state of a
transition and the label of this transition with the set of software components
which own an instruction fetched during this transition.
%
In the case of \formatLTS{Minx86}, there is only one event which implies
fetching instructions: \func{Fetch}.
%
Either the instruction is fetched from the cache (in case of cache hit, and with
respect to the \ac{smrr} and \ac{cpu} cache strategy configuration) or from the
hardware components memories (\ac{dram} and VGA).
%
The formal definition of \(\textsc{Minx86}\func{\_fetched}\) is given in
Figure~\ref{fig:speccert2:fetchedformal}.

\begin{figure}
  \centering \small
  \begin{prooftree}
    \AxiomC{\( h.\func{core}.\func{pc} \not\in
      h.\func{core}.\func{smrr}.\func{range} \)}%
    \AxiomC{\( h.\func{core}.\func{strat}(h.\func{core}.\func{pc}) = \val{WB}
      \)}%
    \AxiomC{\( \func{cache\_hit}(h.\func{cache}, h.\func{core}.\func{pc}) \)}%
    \TrinaryInfC{\( \textsc{Minx86}\func{\_fetched}(h, \func{Fetch}) =
      \setshortdef{h.\func{cache}(\func{index}(h.\func{core}.\func{pc})).\func{owner}}
      \)}
  \end{prooftree}

  \begin{prooftree}
    \AxiomC{\( h.\func{core}.\func{pc} \not\in
      h.\func{core}.\func{smrr}.\func{range} \)}%
    \AxiomC{\( \neg~\func{cache\_hit}(h.\func{cache}, h.\func{core}.\func{pc})
      \)}%
    \BinaryInfC{\( \textsc{Minx86}\func{\_fetched}(h, \func{Fetch}) =
      \setshortdef{h.\func{mem}(\func{dispatch}(h.\func{mem},
        h.\func{core}.\func{in\_smm}, \var{pa}))} \)}
  \end{prooftree}

  \begin{prooftree}
    \AxiomC{\(
      \begin{array}{l}
        h.\func{core}.\func{in\_smm} = \val{true} \\
        \wedge~ h.\func{core}.\func{pc} \in
        h.\func{core}.\func{smrr}.\func{range}
      \end{array}
      \)}%
    \AxiomC{\( h.\func{core}.\func{smrr}.\func{strat} = \val{WB} \)}%
    \AxiomC{\( \func{cache\_hit}(h.\func{cache}, h.\func{core}.\func{pc}) \)}%
    \TrinaryInfC{\( \textsc{Minx86}\func{\_fetched}(h, \func{Fetch}) =
      \setshortdef{h.\func{cache}(\func{index}(h.\func{core}.\func{pc})).\func{owner}}
      \)}
  \end{prooftree}

  \begin{prooftree}
    \AxiomC{\( h.\func{core}.\func{pc} \in
      h.\func{core}.\func{smrr}.\func{range} \)}%
    \AxiomC{\( h.\func{core}.\func{in\_smm} = \val{true} \)}%
    \AxiomC{\( \neg~\func{cache\_hit}(h.\func{cache}, h.\func{core}.\func{pc})
      \)}%
    \TrinaryInfC{\( \textsc{Minx86}\func{\_fetched}(h, \func{Fetch}) =
      \setshortdef{h.\func{mem}(\func{dispatch}(h.\func{mem},
        h.\func{core}.\func{in\_smm}, h.\func{core}.\func{pc})).\func{owner}}
      \)}
  \end{prooftree}

  \begin{prooftree}
    \AxiomC{\( h.\func{core}.\func{pc} \in
      h.\func{core}.\func{smrr}.\func{range} \)}%
    \AxiomC{\( h.\func{core}.\func{in\_smm} = \val{false} \)}%
    \BinaryInfC{\( \textsc{Minx86}\func{\_fetched}(h, \func{Fetch}) = \emptyset
      \)}
  \end{prooftree}

  \begin{prooftree}
    \AxiomC{\( l \neq \func{Fetch} \)}%
    \UnaryInfC{\( \textsc{Minx86}\func{\_fetched}(h, l) = \emptyset \)}
  \end{prooftree}

  \caption{Formal definition of \( \textsc{Minx86}\func{\_fetched} \)}
  \label{fig:speccert2:fetchedformal}
\end{figure}

\section{Specifying and Verifying a BIOS HSE Mechanism}
\label{sec:speccert2:verif}

We consider the execution of the software stack described in
Example~\ref{example:speccert2:isolation} after the end of the boot sequence,
when the OS manages the execution of several applications.
%
Our objective is to give a formal definition for the \ac{hse} mechanism
implemented by the \ac{bios} (denoted by \( \Delta_{\mathtt{bios}} \)) to remain
isolated from the rest of the software stack.
%
We have formally define this security policy with $I_{\mathtt{bios}}$
(Definition~\ref{def:speccert:biospol}).
%
\( \Delta_{\mathtt{bios}} \) relies on the \ac{smm} and the \ac{smrr} of x86
\ac{cpu} and the \texttt{SMRAMC} register of the memory controller.

\subsection{Defining a Hardware-Software Mapping}

{\scshape Minx86} is parameterized with a hardware-software mapping
\func{context} (Definition~\ref{def:speccert:hardsoft}).
%
This mapping is necessary for the model to track memory ownership, as
exemplified by the postconditions of \func{Write} transitions in
Figure~\ref{fig:speccert2:softprepost}.
%
The specification of \func{context} in our use case has already been discussed
in Example~\ref{example:speccert2:isolation}, but the {\scshape Minx86} is not
precise enough to give a concrete definition which matches this specification.
%
That is, we cannot distinguish between OS and applications execution.
%
In the context of our use case this is not an issue, because we can distinguish
between the execution of the \ac{bios} and the execution of the rest of the
software stack.
%
Therefore, we axiomatize the definition of \func{context} with two rules:
%
\begin{description}
\item [\func{context}-bios:] If the \ac{cpu} is in \ac{smm}, it executes the
  \ac{bios}
  \[
    h.\func{in\_smm} = \val{true} \Rightarrow \func{context}(h) = \mathtt{bios}
  \]
\item [\func{context}-untrusted:] If the \ac{cpu} is not in \ac{smm}, it
  executes another component of the software stack
  \[
    h.\func{in\_smm} = \val{false} \Rightarrow \func{context}(h) \in
    \setshortdef{\mathtt{os}, \mathtt{app}_1, \dots, \mathtt{app}_n}
  \]
\end{description}

For the sake of readability, we abusively write
\( \func{context}(h) = \mathtt{untrusted} \) when the \ac{cpu} executes a
software component which is not the \ac{bios}.

\subsection{BIOS HSE Definition}

We define $\Delta_{\mathtt{bios}}$ to model the \ac{hse} mechanism applied by
the \ac{bios}, such that
\[
  \Delta_{\mathtt{bios}} = \langle S, \setshortdef{\mathtt{bios}},
  \func{context}, \func{hardware\_req}, \func{bios\_req} \rangle
\]
%
As \func{context} has already been specified, only \func{hardware\_req} and
\func{bios\_req} remain.
%
Once we have properly introduced both, we verify our definition of
\( \Delta_{\mathtt{bios}} \) satisfies the \ac{hse} laws
(Definition~\ref{def:speccert:laws}).

\paragraph{Hardware Requirements}
%
Given \( h \in H(S) \), \( h \) satisfies \func{hardware\_req}, we have
identified six requirements on states.
%
\begin{enumerate}
\item When the \ac{cpu} executes the \ac{smm} code, the program counter register
  value needs to be an address in SMRAM.
  \[
    h.\func{core}.\func{pc} \in \texttt{pSmram}
  \]
  %
\item The \texttt{SMBASE} register was correctly set during the boot sequence to
  point to the base of the SMRAM.
  \[
    h.\func{core}.\func{smbase} = \textsc{Pa}(\val{smram\_base})
  \]
  %
\item All the memory locations within the SMRAM are owned by the \ac{bios}.
  \[
    \forall \var{ha} \in \texttt{hSmram}, h.\func{mem}(\var{ha}).\func{owner} =
    \mathtt{bios}
  \]
  %
\item For a physical address in SMRAM, in case of cache hit, the related cache
  line content must be owned by the \ac{smm} code.
  \[
    \forall \var{pa} \in \texttt{pSmram}, \func{cache\_hit}(h.\func{cache},
    \var{pa}) \Rightarrow h.\func{cache}(\func{index}(\var{pa})).\func{owner} =
    \mathtt{bios}
  \]
  %
\item In order to protect the content of the SMRAM inside the DRAM memory, the
  boot sequence code has locked the SMRAMC controller. This ensures that an OS
  cannot set the \texttt{d\_open} bit any longer and only a \ac{cpu} in \ac{smm}
  can modify the content of the SMRAM.
  \[
    h.\func{mc}.\func{d\_lock} = \val{true}
  \]
  %
\item The range of memory declared with the \ac{smrr} needs to overlap with the
  SMRAM.
  \[
    \texttt{pSmram} \subseteq h.\func{core}.\func{smrr}.\func{range}
  \]
\end{enumerate}

\paragraph{Software Requirements}
%
We now define $\func{bios\_req}$.
%
We only define two restrictions.
%
First, we force the \ac{bios} execution to remain confined within the SMRAM.
%
The reason is simple: the OS can tamper with the memory outside the SMRAM.
%
As a consequence, jumping outside the SMRAM is the best way to fail the security
policy.
%
Secondly, we prevent the \ac{bios} to update the \ac{smrr} registers;
%
the latter should have been properly configured during the boot sequence, and
there is no need to further update them.
%
\[
  \begin{array}{rcl}
    \func{bios\_req}(h, l)
    & \triangleq
    & \func{context}(h) = \val{bios} \\
    % no func name
    & %no triangleq
    & \Rightarrow ((\forall \var{pa} \in \texttt{PhysAddr}, \\
    % no func name
    & %no triangleq
    & \qquad\qquad l = \func{NextInstruction}(\var{pa})
      \Rightarrow \var{pa} \in \texttt{pSmram}) \\
      % no func name
    & %no triangleq
    & \qquad\wedge~(\forall \var{smrr} \in \texttt{Smrr}, l \neq \func{UpdateSmrr}(\var{smrr})))
  \end{array}
\]

\paragraph{HSE Laws}
%
For $\Delta_{\mathtt{bios}}$ to be a \ac{hse} mechanism, we need to prove it
satisfies the two \ac{hse} Laws.

The first law states that the \( \func{bios\_req} \) is always satisfied when a
software component which is not the \ac{bios} is executed by the hardware
architecture.
%
In such a case, it would mean our \ac{hse} mechanism does not rely on hypotheses
which involve untrusted software components.
%
By definition of \func{bios\_req}, \( \func{context}(h) = \mathtt{bios} \) is an
antecedent of the requirements over \func{NextInstruction} and
\func{UpdateSmrr}.

The second law states the state requirements are invariant with respect to the
software requirements.
%
We prove this by case enumeration of \( l \in L_S \uplus L_H \) and
\( h \in H(S) \), we check that each requirement described
previously is preserved by \func{bios\_req}.
%
In practice, these proofs turned out to be the more demanding, especially for
requirements 3 and 4.
%
For \func{Write} and \func{Read} transitions, the following cases have to be
considered:
%
\begin{itemize}
\item Whether the \ac{cpu}'s core is in \ac{smm} or not;
\item Whether the targeted physical address falls into the \ac{smrr} range or
  not;
\item Which cache strategy to use for this transition;
\item In case of cache hit, whether the occupied cache line is tagged ``dirty''
  or not, and whether its tag (a physical address) belongs to the SMRAM or not.
\end{itemize}
%
Once each requirement has been shown to be preserved during a transition, we can
conclude for \func{hardware\_req} as a whole.

\subsection{BIOS HSE Mechanism Correctness}

Our objective is to prove that \( \Delta_{\mathtt{bios}} \) is correct with
respect to \( I_{\mathtt{bios}} \).
%
Because \( I_{\mathtt{bios}} \) is a security policy modelled with a predicate
on transitions, we know thanks to Theorem~\ref{theorem:speccert:correcthse} that
%
\[
  \begin{array}{l}
    \forall (h, l, h') \in \mathcal{T}(\textsc{Minx86}(\func{context})), \\
    \qquad \func{hardware\_req}(h) \\
    \qquad \Rightarrow (l \in L_S \Rightarrow \func{bios\_req}(h, l)) \\
    \qquad \Rightarrow I_{\mathtt{bios}}(h, l, h')
  \end{array}
\]
%
is a sufficient condition for
\( \Delta_{\mathtt{bios}} \models I_{\mathtt{bios}} \).

From the security policy perspective, only the \func{Fetch} label is relevant.
%
Unfolding the definitions previously introduced in this Chapter and its
predecessor leaves us to prove that
%
\[
  \begin{array}{l}
    \forall (h, h') \in H(S) \times H(S) \text{ such that } (h, \func{Fetch}, h')
    \in \mathcal{T}(\textsc{Minx86}(\func{context})), \\
    \qquad \func{hardware\_req}(h) \wedge h.\func{in\_smm} = \val{true}
    \Rightarrow \func{fetched}_{\textsc{Minx86}}(h, \func{Fetch}) =
    \setshortdef{\mathtt{bios}}
  \end{array}
\]
%
Once again, the proof relies on cases enumeration.
%
In particular, the requirement 1 constrains the value of the program counter
register.
%
As a consequence, we know we can rely on the requirements 3 and 4 which
constrains the ownership of memory location related to the SMRAM.

As a side note, we emphasize that these proofs validate the SMRAM cache
poisoning countermeasure.
%
Without the \acp{smrr}, it is not possible to conclude about the correctness of
\( \Delta_{\mathtt{bios}} \) if the hardware model takes the cache into account.
%
We consider two scenarios.
%
On the one hand, the \ac{hse} mechanism definition takes the cache into account
too.
%
In these conditions, it is not possible to prove it satisfies the second law.
%
Indeed, the cache poisoning attack violates the requirement 4.
%
On the other hand, the \ac{hse} mechanism definition does not take the cache
into account.
%
As a consequence, it is possible to prove it satisfies the second law.
%
However, it is not possible to prove it is correct with respect to
$I_{\mathtt{bios}}$.
%
Indeed, we cannot discard the case where a cache line tagged with a physical
address which belongs to the SMRAM is owned by an untrusted software component.
%
In this scenario, we could even exhibit a trace which complies the \ac{hse}
mechanism, but does not satisfies the security policy.

\section{Perspectives on Concurrent HSE Mechanisms}
\label{subsec:speccert2:coop}

We have proven that \( \Delta_{\mathtt{bios}} \models I_{\mathtt{bios}} \), that
is \( \Delta_{\mathtt{bios}} \) is correct with respect to
\( I_{\mathtt{bios}} \).
%
As we discussed in Subsection~\ref{subsec:speccert2:globalsec}, the \ac{bios}
isolation policy fall within a more general isolation policy \( I \) whose scope
is the complete software stack.
%
In practice, \( I \) is enforced \emph{via} several \ac{hse} mechanisms,
including \( \Delta_{\mathtt{bios}} \).
%
As a consequence, these mechanisms have to be implemented concurrently.

We first introduce a \ac{hse} mechanism composition operator \( \sqcap \)
(\ref{subsec:speccert2:compo}).
%
We then illustrate how we can leverage this operator to reason about \( I \)
(\ref{subsec:speccert2:isolationenforcement}).
%
%Finally, we discuss the notion of \ac{hse} mechanisms compatibility
%(\ref{subsec:speccert2:compat}).

\subsection{HSE Mechanisms Composition}
\label{subsec:speccert2:compo}

We model the concurrent implementation of two \ac{hse} mechanisms \( \Delta_1 \)
and \( \Delta_2 \) as a third \ac{hse} mechanism \( \Delta_1 \sqcap \Delta_2 \).
%
For convenience, the \( \sqcap \) operator imposes two restrictions over
\ac{hse} mechanisms: they shall share the same set of software components and
the same hardware-software mapping.
%
It is possible to define a more generic and flexible composition operator, but
it is out of the scope of this Section.

\begin{definition}[Concurrent HSE Mechanisms]
  Given two HSE mechanism \( \Delta_1 \) and \( \Delta_2 \), such that
%
  \[
    \begin{array}{rcl}
      \Delta_1
      & =
      & \langle S, T_1, \func{context}, \func{hardware\_req}_1, \func{software\_req}_1
        \rangle \\
      \Delta_2
      & =
      & \langle S, T_2, \func{context}, \func{hardware\_req}_2, \func{software\_req}_2
        \rangle
    \end{array}
  \]
%
  We write $\Delta_1 \sqcap \Delta_2$ for the \ac{hse} mechanism which combines
  the requirements of both $\Delta_1$ and $\Delta_2$, that is
%
  \[
    \Delta_1 \sqcap \Delta_2 \triangleq \langle S, T_1 \cup T_2, \func{context},
    \func{hardware\_req}_{1\wedge2}, \func{software\_req}_{1\wedge2} \rangle
  \]
%
  where
  \[
    \begin{array}{rcl}
      \func{hardware\_req}_{1\wedge2}(h)
      & \triangleq
      & \func{hardware\_req}_1(h) \wedge \func{hardware\_req}_2(h) \\
      \func{software\_req}_{1\wedge2}(h,l)
      & \triangleq
      & \func{software\_req}_1(h,l) \wedge \func{software\_req}_2(h,l)
    \end{array}
  \]
\end{definition}

\paragraph{Properties}
%
We now discuss two properties of \( \sqcap \) which emphasize that its
definition matches legitimate expectations.
%
Firstly, \( \sqcap \) forms a commutative monoid, and as a consequence is both
associative and commutative.
%
This means the order in which we construct a ``composite'' \ac{hse} mechanism
from a list of sub-mechanisms is not important.
%
Secondly, the set of compliant traces of the composition of two mechanisms is
the intersection of the sets of compliant traces of these mechanisms.
%
In other word, to comply with the composition of two \ac{hse} mechanisms, a
trace has to comply with each mechanism individually.

\begin{lemma}[Commutative Monoid]
  We write $\Delta_\top$ for the \ac{hse} mechanism whose requirements over
  states and software transitions are always satisfied.
  %
  \( \sqcap \) forms a commutative monoid with the set of \ac{hse} mechanisms
  which share both the same set of software components and the same
  hardware-software mapping, whose identity element is \( \Delta_\top \).

  Indeed, \( \sqcap \) satisfies the following properties:

  \begin{description}
  \item [Associativity:]
    \( (\Delta_1 \sqcap \Delta_2) \sqcap \Delta_3 = \Delta_1 \sqcap (\Delta_2
    \sqcap \Delta_3) \)
    %
  \item [Identity Element:] \( \Delta \sqcap \Delta_\top = \Delta \)
    %
  \item [Commutativity:]
    \( \Delta_1 \sqcap \Delta_2 = \Delta_2 \sqcap \Delta_1 \)
  \end{description}

  \begin{proof}
    \( \sqcap \) forms a monoid because it is defined with operators which
    themselves form monoids.
  \end{proof}
\end{lemma}

\begin{lemma}[Compliant Traces, Composition and Intersection]
  \label{lemma:speccert:compinter}
  The set of compliant traces of the intersection of $\Delta_1$ and $\Delta_2$
  is the intersection of the sets of compliant traces of $\Delta_1$ and
  $\Delta_2$, that is
  \[
    \mathcal{C}(\Delta_1 \sqcap \Delta_2) = \mathcal{C}(\Delta_1) \cap
    \mathcal{C}(\Delta_2)
  \]

  \begin{proof}
    The main idea of the proof is to leverage the definition of $\wedge$ and
    $\Rightarrow$ to turn a statement of the form
    %
    \[
      (P \wedge P') \wedge (R \Rightarrow Q \wedge Q')
    \]
    %
    into
    %
    \[
      (P \wedge (R \Rightarrow Q)) \wedge (P' \wedge (R \Rightarrow Q'))
    \]
    %
    and vice versa.
    %
    In our case, $P$ and $P'$ are statements about the initial states of traces
    and \func{hardware\_req}, $R$ is the premise filtering software transitions,
    and $Q$ and $Q'$ are statements about \func{software\_req}.
  \end{proof}
\end{lemma}

\subsection{Software Stack Isolation Policy Enforcement}
\label{subsec:speccert2:isolationenforcement}

Our objective is to prove that by implementing the \ac{hse} mechanism previously
defined and verified, the \ac{bios} participates in enforcing \( I \).
%
We can do that by finding a complementary \ac{hse} mechanism \( \Delta' \) such
that their composition is correct with respect to \( I \), that is
%
\[
  \exists \Delta', \Delta_{\mathtt{bios}} \sqcap \Delta' \models I
\]

We now show that any \ac{hse} mechanism whose purpose is to constrain the
execution of applications with respect to \( I \) verifies this property.
%
We formally specify this additional security policy
%
\[
  I_\mathtt{os}(h, l, h') \triangleq \forall x \in S, h
  \xrightarrow[\mathtt{app}_k \leadsto x]{l} h' \Rightarrow x = \mathtt{app}_k
\]
%
Such a \ac{hse} mechanism is principally implemented by the OS \emph{via} the
memory paging and ring level features of x86.
%
The \ac{bios} is required to cooperate, at least by not modifying with the page
tables set up by the OS.

We can prove that given any \ac{hse} mechanism \( \Delta_{\mathtt{os}} \) which
is correct with respect to \( I_{\mathtt{os}} \), then
\( \Delta_{\mathtt{bios}} \sqcap \Delta_{\mathtt{os}} \) is correct with respect
to \( I \).
%
\[
  \forall \Delta_{\mathtt{os}}, \Delta_{\mathtt{os}} \models I_{\mathtt{os}}
  \Rightarrow \Delta_{\mathtt{bios}} \sqcap \Delta_{\mathtt{os}} \models I
\]

\begin{proof}
  By definition of correct \ac{hse} mechanism, we need to prove that the set of
  traces which comply with $\Delta_{\mathtt{bios}} \sqcap \Delta_{\mathtt{os}}$
  has to satisfy the security policy derived from our isolation policy $I$.
  %
  With Lemma~\ref{lemma:speccert:compinter}, we know that the set of compliant
  traces of $\Delta_{\mathtt{bios}} \sqcap \Delta_{\mathtt{os}}$ is the
  intersection of the sets of compliant traces of $\Delta_{\mathtt{bios}}$ and
  $\Delta_{\mathtt{os}}$.
  %
  We know that the transitions of these traces satisfy respectively
  $I|U_{\mathtt{os}}$ and $I|U_{\mathtt{bios}}$.
  %
  This is enough to conclude, based on the definitions of global and partial
  execution isolation policies.
\end{proof}

The definition of a correct \( \Delta_{\mathtt{os}} \) remains out of the scope
of this manuscript, but we wanted to emphasize that the verification work does
not necessarily ends once \ac{hse} mechanisms are defined and verified
separately.

% TODO: ? Should we?
%\subsection{On HSE Mechanisms Compatibility}
%\label{subsec:speccert2:compat}

\section{Conclusion}
\label{sec:speccert:discuss}

Throughout this Chapter, we have applied our three-steps methodology for
formally specifying and verifying \ac{hse} mechanisms against a hardware
architecture model to a real world example.
%
Our goal was to illustrate our methodology can benefit both hardware designers
and software developers.

First, the hardware architecture model can be used as a formal specification by
software developers.
%
The main benefit of a formal specification is to avoid any ambiguity such as the
one we have found in \cite{intel2009mch} (as published in 2009).
%
One can read at Section 3.8.3.8, page 102 that ``the OPEN bit must be reset
before the LOCK bit is set''.
%
At the same page, in the description of the LOCK bit, one can also read that
``when [LOCK] is set to 1 then [OPEN] is reset to 0''.
%
We had modelled the second statement as the behavior of the memory controller is
not specified if the first statement is true\,\footnote{If we had to actually
  implement the \ac{hse} mechanism, we would have to assume the first was the
  correct one.}  \formatLTS{Minx86} as a formal specification does not suffer
from the same flaw.
%
Secondly, a formal specification of a \ac{hse} mechanism will help software
developers when the time comes to implement it.
%
For instance, the Chapter 34, Volume 3C of \cite{intel2014manual} about \ac{smm}
is about 30 pages long, it gives many details on how the \ac{smm} actually
works, yet no section is actually dedicated to security.
%
On the contrary, our \ac{hse} mechanism definition gathers six requirements on
hardware configurations and two requirements on software executions to enforce a
well-defined security property.
%
Even if the proofs only apply to an abstract model, we believe it is a valuable
improvement.
%
Lastly, the verification process of a \ac{hse} mechanism specification against a
hardware architecture model may help to highlight hidden flaws in the hardware
specifications assumptions.
%
To illustrate that, we have taken the example of the SMRAM cache poisonning
attack\,\cite{wojtczuk2009smram,duflot2009smram}, which has motivated the
introduction of the \ac{smrr}.

From our point of view, the clear separation between the hardware model, the
security properties and the \ac{hse} mechanisms to enforce those properties are
the main advantage of our approach, as two different use cases can be studied
against the same hardware model.
%
However, the scalability of SpecCert remains to be proven.
%
In particular, the complexity of the hardware architecture makes monolithic
model impracticable in practice.
%
The next Part of this thesis focuses on this problematic.

%% In case I need that in the future.
% {\small
% \begin{prooftree}
%   \AxiomC{\( \top \)}%
%   \AxiomC{%
%   \(
%   \begin{array}{l}
%     \text{if }\func{cache\_hit}(h.\func{cache}, pa) \\
%     \text{then }h' = h \{ \func{cache}(\func{index}(\var{pa})) \leftarrow
%           %       h.\func{cache}(\func{index}(\var{pa}))\{ \func{content} \leftarrow
%           %       v,
%           %       \func{dirty} \leftarrow \val{true} \}\}\} \\
%           %       \text{else if }h.\func{cache}(\func{index}(\var{pa})).\func{dirty}
%           %       =
%           %       \val{true} \\
%           %       \text{then }h' = h\left\{
%         \begin{array}{c}
%           \func{mem}(h.\func{cache}(\func{index}(\var{pa})).\func{tag})
%           \leftarrow
%           \left< \begin{array}{c}
%                    \func{content} =
%                    h.\func{cache}(\func{index}(\var{pa})).\func{content}, \\
%                    \func{owner} = h.\func{cache}(\func{index}(\var{pa})).\func{owner}
%                  \end{array}
%           \right>, \\
%           \func{cache}(\func{index}(\var{pa})) \leftarrow
%           \left<
%           \begin{array}{c}
%             \func{content} = v, \func{tag} = \var{pa}, \func{owner} =
%             \func{context}(h), \func{dirty} = \val{true}
%           \end{array}
%           \right>
%         \end{array}\right\} \\
%         \text{else } h' = h \left\{
%         \func{cache}(\func{index}(\var{pa})) \leftarrow
%         \left<
%         \begin{array}{c}
%           \func{content} = v, \func{tag} = \var{pa}, \func{owner} =
%           \func{context}(h), \func{dirty} = \val{true}
%         \end{array}
%         \right>
%         \right\}
%       \end{array}
%       \)}%
%       \BinaryInfC{\( h \xrightarrow[\func{context}]{\func{Write}(\var{pa}, v)}
%       h' \)}
%     \end{prooftree}

%     \begin{prooftree}
%       \AxiomC{\( \top \)}%
%       \AxiomC{%
%       \(
%       \begin{array}{l}
%        \text{if }\func{cache\_hit}(h.\func{cache}, pa) \\
%        \text{then }h' = h \{ \func{cache}(\func{index}(\var{pa})) \leftarrow
%        h.\func{cache}(\func{index}(\var{pa}))\{ \func{content} \leftarrow v,
%        \func{dirty} \leftarrow \val{true} \}\}\} \\
%        \text{else if
%        }h.\func{cache}(\func{index}(\var{pa})).\func{dirty} =
%        \val{true} \\
%        \text{then }h' =
%        h\left\{
%        \begin{array}{c}
%          \func{mem}(h.\func{cache}(\func{index}(\var{pa})).\func{tag})
%          \leftarrow
%          \left< \begin{array}{c}
%                   \func{content} =
%                   h.\func{cache}(\func{index}(\var{pa})).\func{content}, \\
%                   \func{owner} = h.\func{cache}(\func{index}(\var{pa})).\func{owner}
%                 \end{array}
%          \right>, \\
%          \func{cache}(\func{index}(\var{pa})) \leftarrow
%          \left<
%          \begin{array}{c}
%            \func{content} = h.\func{mem}(\var{pa}).\func{content}, \func{tag} =
%            \var{pa}, \\
%            \func{owner} =
%            h.\func{mem}(\var{pa}).\func{owner}, \func{dirty} = \val{false}
%          \end{array}
%          \right>
%        \end{array}\right\} \\
%        \text{else } h' = h \left\{
%        \func{cache}(\func{index}(\var{pa})) \leftarrow
%        \left<
%        \begin{array}{c}
%          \func{content} = h.\func{mem}(\var{pa}).\func{content}, \func{tag} =
%          \var{pa}, \\
%          \func{owner} =
%          h.\func{mem}(\var{pa}).\func{owner}, \func{dirty} = \val{false}
%        \end{array}
%        \right>
%        \right\}
%      \end{array}
%      \)}%
%      \BinaryInfC{\( h \xrightarrow[\func{context}]{\func{Read}(\var{pa})} h'
%      \)}
%    \end{prooftree}
%  }

%    \begin{minipage}[c]{0.40\linewidth}
%      \begin{prooftree}
%        \AxiomC{\( \top \)}%
%        \AxiomC{\( h' = h \{ \func{core}.\func{strat}(\var{pa}) \leftarrow
%        \var{strat} \} \)}%
%        \BinaryInfC{\( h
%        \xrightarrow[\func{context}]{\func{SetCacheStrat}(\var{pa},
%        \var{strat})} h' \)}
%      \end{prooftree}
%    \end{minipage}
%  %
%    \hfill
%  %
%    \begin{minipage}[c]{0.55\linewidth}
%      \begin{prooftree}
%        \AxiomC{\( h.\func{in\_smm} = \val{true} \)}%
%        \AxiomC{\( h' = h \{ \func{core}.\func{smrr} \leftarrow \var{smrr} \}
%        \)}%
%        \BinaryInfC{\( h
%        \xrightarrow[\func{context}]{\func{UpdateSmrr}(\var{smrr})} h' \)}
%      \end{prooftree}
%    \end{minipage}
%
%    \begin{minipage}[c]{0.55\linewidth}
%      \begin{prooftree}
%        \AxiomC{\( h.\func{in\_smm} = \val{true} \)}%
%        \AxiomC{\( h' = h \{ \func{in\_smm} \leftarrow \val{false} \} \)}%
%        \BinaryInfC{\( h \xrightarrow[\func{context}]{\func{Rsm}} h' \)}
%      \end{prooftree}
%    \end{minipage}
