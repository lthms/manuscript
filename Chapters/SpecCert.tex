%!TEX root = ../main.tex
\chapter{Formal Definition of HSE Mechanisms}
\label{chapter:speccert}

\endquote{``\emph{The purpose of abstraction is not to be vague, but to create a
    new semantic level in which one can be absolutely precise}''

  \hfill\footnotesize --- Edsger Dijkstra}

\vspace{1cm}\noindent
%
Our first contribution is a formal definition of \ac{hse} mechanisms, which
takes into account that
%
\begin{inparaenum}[(1)]
\item interfaces exposed by commodity hardware architectures to software
  components are not safe,
\item trusted and untrusted software components use the same interface and
  manipulate the same stateful environment, and
\item several \ac{hse} mechanisms are often implemented simultaneously, to
  enforce different security policies.
\end{inparaenum}
%
\TODO{Dire dans l'intro du 4, et plusieurs endroits, que l'on a surtout utilisé
  l'approche dans le cas d'une propriété de safety}
%
As a consequence,
%
\TODO{je ne vois pas trop le lien de cause à effet. Revoir la transition de
  cette phrase}
%
we have broken down our formal definition into three components: hardware
models, \ac{hse} mechanisms and security policies.
%
\TODO{Attention à l'usage des temps. Dans cette phrase tu utilises le present
  perfect. Ensuite c'est le présent...}
%
In this Chapter and the following, we assume only one software component is
executed at a given time by the hardware architecture, in order to simplify our
definitions.
%
We believe dealing with multi-core architectures is possible with the cost of
additional efforts, although it remains to be proven as we have not tackled this
challenge during this thesis.
%
% \TODO{C'est du bottage en touche peu élégant. Je dirais que c'est une limite
% du modèle tel qu'il est présenté dans cette thèse. Mais on pourrait étendre le
% modèle pour traiter le multi-coeur. Il faut le dire clairement. C'est pas un
% truc hors sujet du chapitre (sauf erreur de ma part, le problème n'est pas
% traité ailleurs dans le manuscrit). }
%
First, we model the hardware architecture as a labeled transition system whose
sequences of transitions, also called traces, characterize every possible
execution of software components (Section~\ref{sec:speccert:hardware}).
%
This model acts as a foundation for our \ac{hse} mechanisms definition
(Section~\ref{sec:speccert:hse}).
%
We finally define what correctness means in the context of \ac{hse} mechanisms
(Section~\ref{sec:speccert:security}).

For the reader familiar with Coq, we present an implementation of our formalism
in Appendix~\ref{appendix:speccert}.
%
This development comprises machine-checked proofs of the theoretical results
that we present throughout this Chapter.

\section{Hardware Model}
\label{sec:speccert:hardware}

We model a hardware architecture, which can execute different software
components, as a \ac{lts}.

\paragraph{States.}
%
The set of states of the \ac{lts} models the possible configurations of the
hardware components.
%
This configuration changes over time with respect to the hardware specifications
and comprises any relevant data such as register values, inner memory contents,
etc.
%
These state transformations occur during the system's transitions.

\paragraph{Transitions.}
%
We distinguish between two classes of transitions: the software transitions
which are direct and foreseeable side effects of the execution of a \ac{cpu}
instruction and the hardware transitions which are not.
%
Following the terminology of David Basin \emph{et
  al.}\,\cite{basin2013enforceable}, software transitions are ``controllable'',
while hardware transitions are only ``observable''.

We illustrate this definition with the x86 instruction \texttt{mov
  (\%ecx),\%eax}\,\footnote{Written in AT\&T syntax here.}.
%
With respect to the semantics of this instruction, a x86 \ac{cpu}:
%
\begin{inparaenum}[(1)]
\item reads the content of the register \texttt{ecx},
%
\item interprets this value as an address and reads the main memory at this
  address,
%
\item writes this content into the register \texttt{eax},
%
\item updates the register \texttt{eip} with the address of the next instruction
  to execute.
\end{inparaenum}
%
The execution of this instruction by a \ac{cpu} may result in several sequences
of transitions.
%
First, the four execution steps described above translate into four software
transitions.
%
Between each of these transitions, a hardware transition can occur.
%
For instance, one hardware component can initiate a \ac{dma}.
%
Also, if the content of \texttt{ecx} is not a valid addres, the \ac{cpu} raises
an interrupt.
%
In this scenario, only one software transition occurs ---when the \ac{cpu} reads
the content of \texttt{ecx}--- then the following transition models the
interrupt.

\begin{definition}[Hardware Model]
  \label{def:speccert:model}
  A hardware model $\Sigma$ is a tuple
  $\langle H, L_S, L_H, \rightarrow \rangle$, where
  %
  \begin{itemize}
  \item $H$ is the set of configurations of the hardware architecture
  %
  \item $L_S$ is the set of labels to identify software transitions
  %
  \item $L_H$ is the set of labels to identify hardware transitions
  %
  \item $\rightarrow$ is the transition relation of the system
  \end{itemize}

  The transition relation $\rightarrow$ is a predicate on
  $H \times (L_S~\uplus~L_H) \times H$.
  %
  Afterwards, we simply write $L$ for $L_S \uplus L_H$.
  %
  A transition labelled with $l$ from $h$ to $h'$ is denoted by
  %
  \[
    \transition{h}{l}{h'}
  \]
  %
  and we write $\mathcal{T}(\Sigma)$ for the set of triples which satisfy the
  transition relation, that is
  \[
    \mathcal{T}(\Sigma) \triangleq \{\ (h, l, h')\ |\ \transition{h}{l}{h'}\ \}
  \]
\end{definition}

\TODO{c'est quoi le sigle "union" avec un plus à l'intérieur?}

\paragraph{Traces.}
A trace is a non-empty sequence of transitions of~$\Sigma$, such that for two
consecutive transitions, the resulting state of the first one is the initial
state of the next one.
%
\TODO{Tu ne donnes qu'une définition informelle (en
  anglais) des traces. Tu pourrais donner la formule correspondante. Idem pour
  init et trans}
\thomasrk[inline]{Bien que je comprenne l'argument, je ne pense personnellement
  pas que ça apportenait vraiment quelque chose.}

\begin{definition}[Traces]
  \label{def:speccert:trace}
  We write $\pathesLTS{Ez}$ for the set of traces of a hardware model $\Sigma$,
  and we consider the following functions:
  %
  \begin{itemize}
  \item $\func{init} : \pathesLTS{Ez} \rightarrow H$ maps a trace to its initial
    state
  \item
    $\func{trans} : \pathesLTS{Ez} \rightarrow \powerset(\mathcal{T}(\Sigma))$
    maps a trace to the set of transitions which occured during the trace
  \end{itemize}
\end{definition}

As we detailed in Subsection~\ref{subsec:sota:security}, security policies are
modelled as predicates on sets of traces, that is $\powerset (\pathesLTS{Ez})$.
%
Mainstream hardware architectures are not ``safe'' by default, and required
additional software configuration to enforce security properties.
%
For instance, it is legitimate, from a x86 specifications perspective, to enter
ring 3 mode with a page table which allows for modifying kernel code and data.
%
This is why we ultimately seek to model \ac{hse} mechanisms as traces subsets,
to discard traces legitimate from a hardware specification perspective, yet
dangerous from a security perspective.

\section{HSE Mechanisms Definition}
\label{sec:speccert:hse}

We now propose a formal definition for \ac{hse} mechanisms, where a \ac{hse}
mechanism is primarily characterized by a set of trusted software components, a
set of requirements over hardware states and a set of requirements over software
transitions.
%
On the one hand, the purpose of the requirements over states is to identify the
hardware configurations which constrain the execution of untrusted software
components with respect to a targeted security policy.
%
On the other hand, the purpose of the requirements over software transitions is
to prevent mistrusted software components to reach a hardware configuration
wherein the requirements over state are not satisfied.
%
Requirements over software transitions should only constrain the execution of
trusted software components, which implement the \ac{hse} mechanism.
%
We consider an adversary model where attackers control mistrusted software
components, and therefore we do not consider any hypotheses on their behavior.

These two classes of requirements allow us to determine a subset of compliant
traces, that is traces where trusted software components have correctly
implemented the \ac{hse} mechanism by obeying software requirements.
%
% \TODO{Peut être rappeller que "correctly implement the HSE" veut dire
% respecter les contraintes sur les états et les transititions software. C'est
% un peu trop implicite.}
%
To verify a \ac{hse} mechanism is correct with respect to a targeted security
policy means proving the set of compliant traces of this mechanism satisfies the
predicate which models the policy.

\paragraph{HSE Mechanisms.}
%
In the context of \ac{hse} mechanisms, trusted and untrusted software components
alike use the same interface to interact with the underlying hardware
components: the \ac{cpu} instructions set.
%
To reason about HSE mechanisms, it is necessary to be able to determine which
software component is executed at a given time.
%
In practice, a subset of states of the hardware architecture is dedicated to
each software component.
%
For instance, the x86 \ac{cpu} has a feature called protection rings where each
ring can be seen as an execution mode dedicated to a class of software
components.
%
The ring 0 is dedicated to the operating system whereas the applications are
executed when the \ac{cpu} is in ring 3, with a particular page table setup.

\begin{definition}[Hardware-Software Mapping]
  \label{def:speccert:hardsoft}
  Given $S$ a set of software components, a hardware-software mapping
  $\func{con\-text} : H \rightarrow S$ is a function which takes a hardware
  state and returns the software component currently executed.
\end{definition}

We say a software transition is trusted (respectively mistrusted) when it is
generated from a state associated to a trusted (respectively mistrusted)
software component.
%
A hardware-software mapping is mandatory to define requirements over software
transitions that are consistent with respect to our adversary model.
%
\TODO{Cela devrait être expliqué un peu plus en détail et plus tôt. Il suffirait
  alors ici de le rappeler (comme expliqué en section xx, ces contraintes ne
  concernent que les transition trustés.}

\begin{definition}[HSE Mechanism]
  \label{def:speccert:hse}
  A \ac{hse} mechanism $\Delta$ is a tuple
  $\langle S, T, \func{context}, \func{hardware\_req}, \func{software\_req}
  \rangle$, such that
  %
  \begin{itemize}
  \item $S$ is the set of software components executed by the hardware
    architecture.
  %
  \item $T \subseteq S$ is the set of trusted software components which
    implement the \ac{hse} mechanism and form its \ac{tcb}.
  %
  \item $\func{context}$ is a hardware-software mapping to determine which
    software component is currently executed by the \ac{cpu}.
  %
  \item $\func{hardware\_req}$ is a predicate on $H$ to distinguish between safe
    hardware configurations and potentially vulnerable ones.
  %
  \item $\func{software\_req}$ is a predicate on $H \times L_S$ to distinguish
    between safe software transitions and potentially harmful ones. \TODO{Je
      rajouterai une phrase pour enfoncer le clou du style "ce prédicat ne
      contraint que les transition trusté"}
  \end{itemize}
\end{definition}

We illustrate this definition with the flash memory lockdown mechanism described
in Section~\ref{subsec:usecase:hse:smm}.
%
As a reminder, such mechanism enforces the integrity of the \ac{bios} code
within the flash memory and is implemented by the \ac{pch}.
%
As pictured in Figure~\ref{fig:speccert:flash}, the \ac{pch} acts as a proxy
between the \ac{cpu} and a collection of peripherals, including the flash
memory.
%
The \ac{hse} mechanism proceeds as follows:
%
\begin{enumerate}
\item By default, the flash memory is locked and its content cannot be modified.
  %
  By setting the correct bit of a dedicated register of the \ac{pch}
  (\texttt{BIOS\_CNTL}), a software component requests to unlock the flash
  memory.
%
\item When a software component (\emph{e.g.} system software) unlocks the flash
  memory, the \ac{pch} triggers a \ac{smi}.
%
\item This forces the \ac{cpu} to enter \ac{smm}.
  %
  By doing so, the \ac{cpu} stops the execution of the software component which
  has unlocked the flash memory and starts the execution of the \ac{bios}.
%
\item In order to protect the integrity of the flash memory content, the
  \ac{bios} is expected to lock the flash memory again, before resuming the
  execution of the system software with the \texttt{rsm} assembly instruction.
\end{enumerate}

Legacy \acp{bios} were probably using this mechanism in order to implement an
ad-hoc communication channel between the \ac{bios} and the system software
component, \emph{e.g.} to initiate a \ac{bios} update.
%
The \ac{uefi} standard introduces dedicated protocols to enable communication
between the \ac{bios} and the system software component, and we believe the
\ac{bios} action, in response to a \ac{smi} triggered by the unlocking of the
flash memory, is limited to lock it again and resume.
%
In both cases, this is really implementation dependent.

\begin{figure}
  \centering
  \begin{tikzpicture}
    \node [draw, inner sep=12pt, text badly centered] (CPU) {CPU};%
    \node [draw, below=15pt of CPU, inner sep=25pt, text badly centered] (PCH)
    {PCH};%
    \draw (CPU) -- (PCH);%

    \node [draw, inner sep=5pt, below=10pt of PCH, text width=45pt,
    xshift=-55pt, text badly centered] (Flash) {Flash Memory};%
    \draw ([xshift=-10pt]PCH.south) |- (Flash.east);%

    \node [draw, text=white, dashed, inner sep=10pt, below=10pt of PCH, text
    width=25pt, xshift=55pt, text badly centered] (TPM) {TPM};%
    \draw [dashed] ([xshift=10pt]PCH.south) |- (TPM.west);%

    \node [draw, text=white, dashed, inner sep=10pt, right=20pt of PCH, text
    width=45pt, text badly centered] (USB) {USB Controller};%
    \draw [dashed] (PCH) -- (USB);%

    \node [draw, text=white, dashed, inner sep=10pt, left=20pt of PCH, text
    width=45pt, text badly centered] (PCI) {PCI Controller};%
    \draw [dashed] (PCH) -- (PCI);%
  \end{tikzpicture}

  \caption{From the CPU to the flash memory}
  \label{fig:speccert:flash}
\end{figure}

\begin{example}[Flash Memory Lockdown Mechanism]
  \label{example:speccert:flashdef}
  %
  The set of trusted software components is limited to the \ac{bios}, that is
  \( T = \{ \mathtt{bios} \} \).
  %
  This means the rest of the software stack (\emph{e.g.} the operating system
  and its applications) are mistrusted and therefore assumed to be under the
  control of attackers.
  %
  The hardware-software mapping binds \acp{cpu} in \ac{smm}
  with the execution of the \ac{bios}, that is
  %
  \[
    \begin{array}{rcll}
      \func{context}(h) & = & \mathtt{bios} & \text{if } h \text{ characterizes
                                              a \ac{cpu} in \ac{smm}} \\
      \func{context}(h) & \in & S \backslash \{ \mathtt{bios} \} & \text{otherwise}
    \end{array}
  \]
  %
  \TODO{La phrase n'est pas suffisamment préciser. En outre, j'ai mis du temps à
    me rappeler que context ne doit pas être pris ici comme un mot commun mais
    un nom de fonction!. Il faudrait dire que par défaut contexte(h)=non trusté
    sauf lorsque le CPU est en SMM, c'est à dire lorsqu'une SMI se produit et
    avant que le bios exécute une instruction rsm}
  %
  A safe hardware state ($\func{hardware\_req}$) is either a state wherein the
  \ac{bios} is executed, or a state wherein the flash memory is locked.
  %
  It is expected that the \ac{bios} locks the flash memory before using the
  \texttt{rsm} instruction ($\func{software\_req}$).
\end{example}

\paragraph{HSE Laws.}
%
As it is, our definition of \ac{hse} mechanisms is too permissive.
%
For a \ac{hse} mechanism to be consistent, it must also obey two axioms,
together called the \ac{hse} laws.
%
The first law says that the $\func{software\_req}$ predicate always holds true
for transitions generated by untrusted software components.
%
That is, the first law enforces that a \ac{hse} mechanism definition does not
make any assumption regarding untrusted software components.
%
The second law says that the requirements over the hardware state specified by
$\func{hardware\_req}$ are invariant with respect to $\func{software\_req}$.
%
As long as the trusted software components which implement the \ac{hse}
mechanisms only generate software transitions which satisfy the
$\func{software\_req}$ predicate, the $\func{hardware\_req}$ predicate holds
true.
%
This means the software transitions at the untrusted software components
disposal cannot put the system into an unsafe state.

\begin{definition}[\ac{hse} Laws]
  \label{def:speccert:laws}
  A \ac{hse} mechanism $\Delta$ has to satisfy the following properties:
  \begin{enumerate}
  %
  \item Untrusted software transitions satisfy $\func{software\_req}$:
    $\forall (h, l, h') \in \mathcal{T}(\Sigma)$, $\forall x \not\in T$,
    %
    \[
      l \in L_S \wedge \func{context}(h) = x \Rightarrow \func{software\_req}(h,
      l)
    \]
  %
  \item $\func{hardware\_req}$ is an invariant with respect to
    $\func{software\_req}$: $\forall (h, l, h') \in \mathcal{T}(\Sigma)$,
    \[
      \func{hardware\_req}(h) \wedge (l \in L_S \Rightarrow
      \func{software\_req}(h,l)) \Rightarrow \func{hardware\_req}(h')
    \]
  \end{enumerate}
\end{definition}

On the one hand, a \ac{hse} mechanism definition which does not satisfy the
first law is incorrectly making assumption about ``untrusted'' software
components.
%
This makes these components part of the \ac{tcb} \emph{de facto}, even though
they do not belong to $\mathcal{T}$.
%
Formally defining a \ac{hse} mechanism may be the occasion to uncover such
implicit assumptions.
%
On the other hand, a \ac{hse} mechanism which does not satisfy the second law
has to be carefully reviewed.
%
As it stands, it does not prevent the hardware architecture to reach a state
wherein the hardware configuration does not satisfy the requirements over
states, despite the correct implementation of the mechanism by the trusted
software components.
%
In such a condition, the hardware architecture may stop to constrain the
execution of untrusted software components with respect to the targeted security
policy. \TODO{Cela veut surrement dire que les contraintes sur l'exécution du
  code trusté sont incomplètes ou que le la restriction sur l'état du hardware
  est au contraire trop restrictive. S'il n'est pas possible de trouver une
  contrainte sur l'état du hardware moins restrictive permettant d'assurer la
  propriété de sécurité ou de restreindre le code trusté pour vérifier cette
  seconde loi, il y a de forte chance que le HSE ne permette pas d'assurer la
  propriété de sécurité visée.... }

\begin{example}[Flash Memory Lockdown Inconsistency]
  We can convince ourselves that the informal definition description we have
  discussed in the Example~\ref{example:speccert:flashdef} obeys the first
  \ac{hse} law, but \emph{does not} obey the second one.
  %
  \paragraph{Untrusted software transitions satisfy $\func{software\_req}$.}
  %
  The only software restriction we have formulated concerns the use of the
  \texttt{rsm} instruction by the \ac{bios}.
  %
  The rest of the software stack can leverage the complete x86 instructions set
  with no restriction.
  %
  In particular, an attacker is free to unlock the flash memory thanks to the
  \texttt{BIOS\_CNTL} register.

  \paragraph{$\func{hardware\_req}$ is not an invariant with respect to
    $\func{software\_req}$.}
  %
  A \ac{cpu} is either in \ac{smm} or not in \ac{smm}.
  %
  If it is in \ac{smm}, the only way to leave \ac{smm} is to execute the
  \texttt{rsm} instruction, which qualifies as a software transition.
  %
  If the \ac{cpu} is in \ac{smm}, the \func{software\_req} hold true for this
  software transition when the flash memory is locked.
  %
  As a consequence, a \ac{bios} which correctly implements this \ac{hse}
  mechanism locks the flash memory prior to leaving the \ac{smm}.
  %
  However, if the \ac{cpu} is not in \ac{smm}, and tries to open the flash
  memory, two things happen sequentially.
  %
  First, the flash memory is effectively opened.
  %
  This has to be modelled by a software transition.
  %
  Then, the \ac{pch} triggers a \ac{smi}, leading the \ac{cpu} to enter
  \ac{smm}.
  %
  A \ac{smi} has to be modelled as a hardware transition.
  %
  Between the modification of the \texttt{BIOS\_CNTL} register and the treatment
  of the \ac{smi} by the \ac{cpu}, the \func{hardware\_req} predicate is not
  satisfied.

  It is because the flash memory lockdown as described here does not satisfy the
  first law that the race condition uncovered by Corey Kallenberg \emph{et
    al.}\,\cite{kallenberg2015racecondition} is possible.
  %
  On the contrary, the \texttt{SMM\_BWP} register semantics allows for defining
  a HSE mechanisms which satisfies both laws, because the register ties together
  the state of the \acp{cpu} and the flash memory state.
\end{example}

\paragraph{Trace Compliance.}
%
Whether trusted software components are correctly implementing a given \ac{hse}
mechanism is a safety property: trusted software components shall \emph{never}
generate a software transition which does not satisfy the requirements of the
\ac{hse} mechanism.
%
Because the purpose of these requirements over software transitions is to
prevent untrusted software components to reach a hardware configuration wherein
the requirements over state are not satisfied, so it is required that the
initial state of the trace satisfies the requirements over state.
%
A trace whose initial state satisfies the requirements over state and where
trusted software components do correctly implement a \ac{hse} mechanism is said
to comply with this mechanism.
%
\begin{definition}[Compliant Traces]
  We write $\mathcal{C}(\Delta)$ for the set of the traces which comply with
  $\Delta$.
  %
  Given $\rho \in \pathesLTS{Ez}$, then $\rho \in \mathcal{C}(\Delta)$ iff
  \[
    \func{hardware\_req}(\func{init}(\rho)) \wedge \forall (h,l,h') \in
    \func{trans}(\rho)\text{, }l \in L_S \Rightarrow \func{software\_req}(h, l)
  \]
\end{definition}

\begin{example}[Memory Flash Lockdown Compliance]
  We consider the trace to start at the end of the boot sequence, when the
  \ac{bios} gives the control flow to the system software component it has
  selected.
  %
  At the time, it is expected that the \texttt{BIOS\_CNTL} register of the
  \ac{pch} has been correctly set; in particular, the \texttt{SMM\_BWP} bit
  should be set, to avoid the Speed Racer
  attack\,\cite{kallenberg2015racecondition}.
  %
  If the \ac{bios} fails to do so, then the related trace is not compliant.
\end{example}

\begin{lemma}[HSE Invariant Enforcement]
  \label{lemma:speccert:hseinv}
  As intended, \func{hardware\_req} is an invariant of traces which complies
  with $\Delta$, that is
  %
  \[
    \forall \rho \in \mathcal{C}(\Delta), \forall (h, l, h') \in
    \func{trans}(\rho), \func{hardware\_req}(h) \wedge \func{hardware\_req}(h')
  \]

  \begin{proof}
    By definition of $\mathcal{C}(\Delta)$, we know the initial state of the
    trace satisfies \func{hardware\_req}, and thanks to the second HSE Law, we
    can conclude the state after the first transition also satisfies
    \func{hardware\_req}.
    %
    We generalize to the trace by induction.
  \end{proof}
\end{lemma}

As a consequence, a \ac{hse} mechanism allows for satisfying a given set of
requirements over hardware configurations throughout the execution of a software
stack, as long as a set of trusted software components correctly implement the
mechanism.

\section{HSE Mechanism Correctness.}
\label{sec:speccert:security}

It is important to keep in mind that preserving a set of requirements over
hardware configurations is only a mean to an end.
%
The true purpose of a \ac{hse} mechanism is to constrain the execution of
untrusted software components with respect to a targeted security policy.

It is possible to define a \ac{hse} mechanism which satisfies the \ac{hse} Laws,
yet failed to constrain the execution of untrusted software components with
respect to a targeted security policy.
%
The SMRAM cache poisoning attack described in
Subsection~\ref{subsec:usecase:hse:smram} is a good illustration of that
eventuality\,\cite{duflot2009smram,wojtczuk2009smram}.
%
The isolation of the \ac{bios} at runtime is enforced by only two hardware
mechanisms: the \ac{smm} of the \ac{cpu} and the \texttt{SMRAMC} register of the
memory controller.
%
By correctly configuring the memory controller \emph{via} the \texttt{SMRAMC}
register, the \ac{bios} can activate the protection of a dedicated memory region
called the SMRAM.
%
In such a case, only a \ac{cpu} in \ac{smm} can read or write to the SMRAM.
%
As it stands, the \ac{hse} mechanism described here satisfies both laws.
%
However, between the \ac{cpu} and the memory controller lies the cache, as
pictured in Figure~\ref{fig:speccert:smram}.
%
If the cache does not take into account the SMRAM ---as it was the case in 2009,
before the introduction of the SMRR--- it can be used to circumvent the
protection enforced by the memory controller: the integrity of the SMRAM is
enforced, but the \ac{cpu} does not read its content when it needs it.

\begin{figure}
  \centering
  \begin{tikzpicture}
    \node [draw, inner sep=15pt] (Core) {Core};%
    \node [draw, inner sep=7pt, below=5pt of Core] (Cache) {Cache};%
    % \node [draw, inner sep=10pt, dashed, fit=(Core) (Cache)] (CPU) {};%

    \node [draw, below=10pt of Cache, inner sep=20pt, text width=50pt, text
    badly centered] (MC) {Memory Controller};%

    \draw (Core) -- (Cache);%
    \draw (Cache) -- (MC);%

    \node [draw, right=10pt of MC, minimum height=100pt, inner sep=10pt] (DRAM)
    {DRAM};%

    \draw (DRAM) -- (MC);%

    \draw [dashed] ([yshift=15pt]DRAM.south west) -- ([yshift=15pt]DRAM.south
    east);%
    \draw [dashed] ([yshift=25pt]DRAM.south west) to node [below, yshift=1pt]
    {\small SMRAM} ([yshift=25pt]DRAM.south east);%
  \end{tikzpicture}

  \caption{From the \ac{cpu}'s core to the SMRAM}
  \label{fig:speccert:smram}
\end{figure}

\begin{definition}[Security Policy]
  A security policy $P$ is either a predicate on sets of traces, a predicate on
  traces or a predicate on transitions.
\end{definition}

\begin{definition}[Correct HSE Mechanism]
  A \ac{hse} mechanism $\Delta$ is correct with respect to a security policy $P$
  (denoted by $\Delta \models P$) if and only if the set of compliant traces of
  $\Delta$ satisfies $P$, that is
  %
  \[
    \Delta \models P \triangleq
    \begin{cases}
      P(\mathcal{C}(\Delta)) & \text{if } P \text{ is a predicate on sets of
        traces} \\
      \forall \rho \in \mathcal{C}(\Delta), P(\rho) & \text{if } P \text{ is a
        predicate on traces} \\
      \forall \rho \in \mathcal{C}(\Delta), \forall \mathit{tr} \in
      \func{trans}(\rho), P(\mathit{tr}) & \text{if }P \text{ is a predicate on
        transitions}
    \end{cases}
  \]
\end{definition}

Verifying that a \ac{hse} mechanism is correct with respect to a security policy
can be difficult, especially when this security policy is a
hyperproperty\,\cite{clarkson2010hyperproperties}.
%
On the contrary, safety properties modelled as predicates on transitions are
easier to reason about, as shown by the following theorem. \TODO{Je trouve que
  c'est un peu s'avancer de dire que ton modèle peut traiter autre chose que des
  prédicats sur les transitions. Tout est construit dans ton approche pour
  traiter efficacement ce cas. Tu ne nous convainc pas que ton approhce
  (prédicat, sur l'état du hard, restriction sur les transition trusté...) est
  adaptée pour traiter d'autre cas...}

\begin{theorem}[Correct HSE Mechanism for Predicate on Transitions]
  \label{theorem:speccert:correcthse}
  Given a security policy $P$ defined as a predicate on transitions, then
  %
  \[
    \begin{array}{l}
      \forall (h, l, h') \in \mathcal{T}(\Sigma), \\
      \qquad \func{hardware\_req}(h) \\
      \qquad \Rightarrow (l \in L_{S} \Rightarrow \func{software\_req}(h, l))\\
      \qquad \Rightarrow P(h, l, h')
    \end{array}
  \]
  %
  is a sufficient condition for
  %
  \[
    \Delta \models P
  \]

  \begin{proof}
    \TODO{Comment faut-il lire la formule logique précédente? 3 implications imbriquées? Du coup, si hardware\_req(h) n'est pas vérifié, la propriété est quand même vérifiée? Ca semble contre-intuitif...}
    With Lemma~\ref{lemma:speccert:hseinv}, we know that every initial state of
    a transition of $\rho$ satisfies $\func{hardware\_req}$.
    %
    As a consequence and by definition of Compliant Traces, we know that every
    transition satisfies the safety property $P$.
    %
    We conclude with the \ac{hse} mechanism correctness.
  \end{proof}
\end{theorem}

\TODO{Contrairement au lemmes précédents, je trouve que la preuve (schéma de
  preuve?) est un peu trop rapide. Je n'arrive pas à suivre et à me convaincre
  que çà marche (mais je suis sans doute trop fatigué).}

\section{Conclusion}

In this Chapter, we present our formal definition of \ac{hse} mechanisms, in the
form of requirements over a hardware model.
%
This approach allows for reusing the same model to define and verify several
\ac{hse} mechanisms.
%
We believe this is an essential property, especially because in practice, these
multiple mechanisms will be implemented concurrently, and may interfere with
each other.

\TODO{Sauf erreur de ma part, ton chapitre 4 ne développe pas du tout cet aspect
  "modulaire" et "réutilisabilié". Donc c'est un peu exagéré de le mettre en
  avant dans la conclusion. Soit il faut nuancer cette conclusion, soit il faut
  développer ces aspects (via un exemple notamment) dans le chapitre.}

Throughout this Chapter, we have tried to illustrate our definitions with
real-world examples, as our effort has been originally motivated by the
disclosure of several vulnerabilities targeting multiple x86 \ac{hse} mechanisms
for the past few
years\,\cite{wojtczuk2009smram,duflot2009smram,rutkowska2008remap,domas2015sinkhole,kallenberg2015racecondition}.
%
All being told, our approach can be summarized to a three-step methodology for
specifying and verifying \ac{hse} mechanisms against hardware architecture
models, that is
%
\begin{inparaenum}[(1)]
\item specifying the software requirements that must be satisfied by the trusted
  software components which implement the \ac{hse} mechanism,
%
\item specifying the targeted security policy the \ac{hse} mechanism supposedly
  enforces, and
%
\item verifying that the \ac{hse} mechanism is correct with respect to the
  targeted security policy.
\end{inparaenum}
%
We believe this methodology would benefit both hardware designers and software
developers.
%
In the next Chapter, we apply our proposal to a real world example: the \ac{hse}
mechanism implemented by the \ac{bios} to remain isolated from the rest of the
software stack after the end of the boot sequence
(Section~\ref{sec:usecase:hse}).
