%!TEX root = ../main.tex
\chapter{State of the Art}
\label{chapter:relatedwork}

\endquote{``\emph{We build our computers the way we build our cities: over time,
    without a plan, on top of ruins.}''

  \hfill\footnotesize --- Ellen Ullman}

% \GH{Se pose ensuite la question de l'adéquation entre ce modèle et
% l'implémentation (code exécutable, code exécuté (ce qui suppose que le
% matériel se comporte comme prévu), circuit logique, VHDL...)  Cette adéquation
% peut-être garantie par extraction automatique du modèle (c'est le cas
% lorsqu'on dispose d'une sémantique formelle du langage source et que le
% compilateur a été prouvé) ou au contraire génération automatique de
% l'implémentation (génération automatique de code dans CoQ), par test (si la
% spec est exécutable), par insertion de pré/post condition, etc. Quels sont les
% termes utilisé par ton bouquin en référence?}
%

\vspace{1cm}%
\noindent
%
The formal verification of a system consists of proving its correctness with
respect to a \emph{specification}\,\cite{gupta1992formal}, that is a description
of properties targeted by the system.
%
To that end, a model of the system is defined to enable rigorous reasoning of
the system behavior by means of formal methods.
%
% We distinguish between \emph{functional} specifications, which describe
% expected behaviors of their implementations, and \emph{non-functional}
% specifications, which notably include security policies.
%
In this thesis, our objective is to give a formal theory of \ac{hse}
mechanisms in the form of requirements that trusted software components have to
satisfy, and to verify that these requirements do effectively provide the
enforcement of targeted security policies.

We steer a middle course between two domains: hardware verification and system
software verification.
%
Generally, hardware verification focus on properties which are transparent to
the executed software (\emph{e.g.} cache
coherency\,\cite{stern1995cachecoherence}, linearizability of SGX
instructions\,\cite{leslie2015linsgx}, or hardware-based memory
isolation\,\cite{lie2003xom}), and system software verification relies on
hardware models which abstract as much as possible of the architecture
complexity.
%
To the extent of our knowledge, the closest related research project  is the work
of Jomaa \emph{et al.}\,\cite{jomaa2016mmu}, who specified what are the
requirement a microkernel must satisfy in order for a \ac{mmu} to enforce memory
isolation at all times.
%
This approach remains an isolated initiative, hence the interactions of the
numerous configurable hardware features is less subject to formal verification.

The rest of this Chapter proceeds as follows.
%
We detail how transition systems have been widely and successfully used in order
to model and verify hardware and software systems, and where does our 
approach 
stand with respect to previous work (Section~\ref{sec:sota:formalisms}).
%
Then, we introduce and justify our interest in compositional verification
approaches, which enable the ``divide and conquer'' strategy to reduce the
burden of verifying large systems, and compare our compositional framework for
Coq with existing solutions (Section~\ref{section:sota:compsec}).

\section{Towards the Formal Verification of HSE Mechanisms}
\label{sec:sota:formalisms}

In a verification problem, the definition of a model allows for unambiguously
describing the set of possible behaviors of the system.
%
The system is characterized by a set of \emph{states} and by a set of state
transformations, called \emph{transitions} (\ref{subsec:sota:ltsdef}).
%
A sequence of transitions of the model, commonly called \emph{trace}, describes
how the system has operated over time, that is which behavior it has exhibited.
%
As a consequence, by reasoning about the set of traces of the model, we reason
about the set of all possible behaviors of the system, \emph{e.g.} to verify
that security policies are enforced at all time (\ref{subsec:sota:security}).
%
To support this reasoning, many approaches and tools have
been proposed. Choosing between one of these tools means making a necessary
compromise between expressiveness, automation, and applicability
(\ref{subsec:sota:tools}).
%
In this thesis, we advocate for defining \ac{hse} mechanisms of a given hardware
architecture against a general-purpose model of this architecture, comprehensive
in terms of hardware components, rather than verifying each \ac{hse} mechanism
against a specific model.
%
Many x86 models have been proposed over years, but to the extent of our
knowledge, none of them aims to describe the x86 architecture as a whole
(\ref{subsec:sota:ltsrelated}).
%
To experiment with our formal theory of \ac{hse} mechanisms, we compromise
and relied on a ad-hoc model, with the aim of identifying desirable properties
for a large-scale model that would optimize the applicability of our approach
(\ref{subsec:sota:ltsconclusion})

\subsection{Modeling a Hardware Architecture}
\label{subsec:sota:ltsdef}

A system is characterized by a set of states (\emph{e.g.} the state of a
processor core typically includes the values of its registers and its execution
mode) and a set of state transformations (\emph{e.g.}  the value of a register
will change when a core executes certain instructions) which occur over times as
the system operates.
%
To formally define these two sets means constructing a model of the system. \GH{"To ... means" me semble bizarre comme formulation. Es-tu sur que ce soit idiomatique? }
%
The literature has a rich collection of formalisms \GH{lequels? Tu pourrais en citer quelques uns à titre d'example, avec des ref pour appuyer "a riche collection of". Ou donner une ref qui parle de la profusion des modèles} which can be leveraged to
that end, each of them being well-suited for dedicated classes of problem.
% \emph{e.g.}  the Kripke structure\,\cite{kripke1971semantical} is a prominent
% definition of transition systems used in model
% checking\,\cite{clarke1999model}.
%
In practice, labeled transition systems\,\cite{loiseaux1995lts} form a prominent
class of transition systems, characterized by the use of labels to distinguish
between transitions.

\begin{definition}[Labeled Transition System]
  A labeled transition system is a tuple \( \langle S, L, R \rangle \), such
  that \( S \) is a set of states, \( L \) is a set of labels, and
  \( R \subseteq S \times L \times S \) is the transition relation, that is
  \( (s, l, s') \in R \) is a transition of the LTS.
\end{definition}

Different names have been used to designate labels and labeled
transitions, \emph{e.g.} input variables\,\cite{cimatti2002nusmv},
operations\,\cite{jackson2012alloy}, rules\,\cite{murphi}, or 
actions\,\cite{barthe2011virtcert1}.
%
Although the name changes, the motivation remains to characterize the nature of
the transition.
%
LTS are well-suited to reason about the interactions of a system with its
environment, \emph{e.g.} hypercalls handled by a
hypervisor\,\cite{barthe2011virtcert1} or \IOs provoked by the execution of
machine instructions\,\cite{lie2003xom}.
%
Similarly to the work of Lie \textit{et al.}\,\cite{lie2003xom}, we use labels to reason about
the interactions between the hardware architecture and the software components
that are executed by this architecture.
%
It allows us to define requirements trusted software components have to satisfy
to implement a given \ac{hse} mechanism.

Throughout this Chapter, we will use the airlock system  as a
running example, since it is both simple ---our examples remain of manageable
size--- and rich ---we can use it to illustrate the definitions we introduce.
%
An airlock system is a device made of two doors, and an intermediary chamber.
%
To get across an airlock system, a user requests the opening of the first door,
enters the chamber, waits for the system to close the first door and open the
second door, and exits the chamber.

\begin{example}[Airlock System]
  \label{example:sota:airlocklts}

  We model our airlock system with a labeled transition system
  \( \langle S, L, R \rangle \), such that:

  \begin{itemize}
  \item A door of the system can be either \( \mathtt{open} \) or
    \( \mathtt{close} \).
    %
    The set of states of the airlock system reflects the Cartesian product of
    the doors states.
    %
    \[
      \begin{array}{rcl}
        S & \triangleq & \{ \mathtt{open}, \mathtt{close} \} \times \{ \mathtt{open},
                         \mathtt{close} \}
      \end{array}
    \]
    %
  \item A transition is characterized by a request to open
    (\( \mathtt{Open}_i\), with \( i \in \{1, 2\} \)) or close
    (\( \mathtt{Close}_i \), with \( i \in \{1, 2\} \)) a door of the system.
    %
    \[
      \begin{array}{rcl}
        L & \triangleq & \{ \mathtt{Open}_1, \mathtt{Close}_1, \mathtt{Open}_2,
                         \mathtt{Close}_2 \}
      \end{array}
    \]
    %
  \item The model does not allow the simultaneous opening of both doors, as
    stated by the definition of \( R \) which does not contain a transition
    which leads to the state \( (\mathtt{open}, \mathtt{open}) \).
    \[
      \begin{array}{rcl}
        R & \triangleq & \{ (\mathtt{close}, \mathtt{close}), \mathtt{Open_1},
                         (\mathtt{open}, \mathtt{close}), \\
          & & \ (\mathtt{close}, \mathtt{close}), \mathtt{Open_2},
              (\mathtt{close}, \mathtt{open}), \\
          & & \ (\mathtt{open}, \mathtt{close}), \mathtt{Close_1},
              (\mathtt{close}, \mathtt{close}), \\
          & & \ (\mathtt{close}, \mathtt{open}), \mathtt{Close_2},
              (\mathtt{close}, \mathtt{close}) \}
      \end{array}
    \]
  \end{itemize}

  The resulting labeled transition system is pictured in
  Figure~\ref{fig:sota:airlock-lts}.
\end{example}

\begin{figure}
  \begin{center}
    % a tikzpicture to illustrate the resulting automata
    \begin{tikzpicture}
      \node [draw, circle split, text width=30pt, text badly centered] (cc)
      {\( \mathtt{close} \) \nodepart{lower} \( \mathtt{close} \)};%
      \node [right=of cc] (x) {};%
      \node [draw, circle split, above=of x, text width=30pt, text badly
      centered] (oc) {\( \mathtt{open} \) \nodepart{lower}
        \( \mathtt{close} \)};%
      \node [draw, circle split, below=of x, text width=30pt, text badly
      centered] (co) {\( \mathtt{close} \) \nodepart{lower}
        \( \mathtt{open} \)};%
      \node [draw, circle split, right=of x, text width=30pt, text badly
      centered] (oo) {\( \mathtt{open} \) \nodepart{lower} \( \mathtt{open}
        \)};%

      \draw [-latex] (cc) edge [bend left] node [xshift=-5pt, left]
      {\( \mathtt{Open}_1 \)} (oc);%
      \draw [-latex] (oc) edge [bend left] node [xshift=5pt, right]
      {\( \mathtt{Close}_1 \)} (cc);%

      \draw [-latex] (cc) edge [bend left] node [xshift=5pt, right]
      {\( \mathtt{Open}_2 \)} (co);%
      \draw [-latex] (co) edge [bend left] node [xshift=-5pt, left]
      {\( \mathtt{Close}_2 \)} (cc);%

    \end{tikzpicture}

    \caption{A simple airlock system modeled as a labeled transition system}
    \label{fig:sota:airlock-lts}
  \end{center}
\end{figure}

%%
% Besides, Petri net\,\cite{peterson1981petri}, process
% algebra\,\cite{bergstra1984process} or interface
% automata\,\cite{de2001interface} are better suited to model concurrent
% systems. \GH{et? Quelle structure vas-tu utiliser dans ton approche?
% Pourquoi?}

Our objective is to verify \ac{hse} mechanisms, therefore we need to be able to
model them.
%
To that end, it is important to consider that
%
\begin{inparaenum}[(1)]
\item \label{needreuse}%
  hardware architectures often allow for implementing several \ac{hse}
  mechanisms, and
  %
\item \label{needreduce}%
  hardware features involved in \ac{hse} mechanisms are not safe by default,
  hence the role played by trusted software components to configure them.
\end{inparaenum}
%
By defining \ac{hse} mechanisms of a given hardware architecture against a
general-purpose model of this architecture, rather than relying on ad-hoc models
dedicated to specific \ac{hse} mechanisms, we believe we reduce the overall
verification effort induced by (\ref{needreuse}), and address the threat posed
by compositional attacks.
%
However, (\ref{needreduce}) means such a general-purpose model of hardware
architectures necessarily embeds behavior which are legitimate with respect to
the hardware architecture functional specification, but violate some targeted
security policies.
%
This is the case, for instance, if the \ac{bios} leaves the SMRAM unlocked at
the end of the boot sequence.

\subsection{Specifying Security Policies}
\label{subsec:sota:security}

The theory of properties of a transition system is now well understood, with an
intuitive classification of properties, such that:
%
\begin{itemize}
\item \emph{Safety properties}\,\cite{lamport1977proving,lamport1985logical}
  characterize that nothing ``bad'' shall \emph{never} happen.
\item \emph{Liveness properties}\,\cite{lamport1985logical,alpern1985liveness}
  characterize that something ``good'' shall \emph{eventually} happen.
\end{itemize}

Two classes of security policies commonly targeted by x86 \ac{hse} mechanisms
are access control and availability policies.
%
An access control policy is a safety property: unauthorized action by a subject
shall never happen.
%
An availability policy is a liveness property: the system shall eventually
satisfy the service.

Safety and liveness properties are expressed against sequences of transitions,
commonly called \emph{traces} in the literature.
%
Each formalism has its own definition of traces, which takes into account its
characteristic.
%
As for the labeled transition systems, their traces interleaves a label between
each state\,\cite{vijayaraghavan2015modular}.

\begin{example}[Airlock System Trace]
  The crossing, by a user, of the airlock system is characterized by the
  following trace:
  \[
    \footnotesize (\mathtt{close}, \mathtt{close})%
    \!\xrightarrow{\mathtt{Open}_1}\!(\mathtt{open}, \mathtt{close})%
    \!\xrightarrow{\mathtt{Close}_1}\!(\mathtt{close}, \mathtt{close})%
    \!\xrightarrow{\mathtt{Open}_2}\!(\mathtt{close}, \mathtt{open})%
    \!\xrightarrow{\mathtt{Close}_2}\!(\mathtt{close}, \mathtt{close})
  \]
\end{example}

Afterwards, we write \( \Sigma(M) \) for the set of traces of a labeled
transition system \( M \).

Safety and liveness properties can be defined in terms of predicates on
traces\,\cite{alpern1987recognizing,schneider2000enforceable,basin2013enforceable}.
%
\( M \) is said to be correct with respect to a property modeled as a predicate
on traces \( P \) when
%
\[
  \forall \rho \in \Sigma(M), P(\rho).
\]

On the one hand, safety properties are characterized by an invariant \( \iota \)
on trace elements, that is
%
\[
  P(\rho) \triangleq \iota(\rho_0) \wedge P(\rho_{[1..]}),
\]
%
where \( \rho_0 \) is the first element of the trace, and \( \rho_{[1..]} \) is
the trace obtained by removing the first element of \( \rho \).
%
On the other hand, liveness properties are characterized by a predicate
\( \eta \) on trace which has to be satisfied for at least a subtrace, that is
%
\[
  P(\rho) \triangleq \exists n > 0, \eta(\rho_{[..n]}) \vee P(\rho_{[1..]}),
\]
%
where \( \rho_{[..n]} \) is the subtrace made with the \( n \) first elements of
\( \rho \).

\begin{example}[Airlock Safety and Liveness Properties]
  A typical \emph{safety} property for an airlock system is that at least one
  door shall be closed at any time.
  %
  We formalize this property with the invariant \( \iota \), defined as follows:
  %
  \[
    \iota( d_1, d_2) \triangleq d_1 = \mathtt{close} \vee d_2 = \mathtt{close}
  \]
  %
  The specification of the airlock system is defined with a labeled transition
  system.
  %
  Assuming the airlock device is initialized in a correct state (\emph{e.g.}
  both doors are close), we verify this specification is correct with respect to
  the safety property characterized by \( \iota \) by exhibiting a proof that
  \( \iota \) is an invariant with respect to \( R \), that is
  %
  \[
    \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \iota(d_1, d_2) \Rightarrow
    \iota(d_1', d_2')
  \]

  \begin{proof}
    By definition of \( R \), there are four transitions to consider, and our
    proof consists in an enumeration of these cases.
    %
    Case 1, both doors are close, that is \( d_1 = d_2 = \mathtt{close} \).  The
    system opens the first door, that is \( l = \mathtt{Open}_1 \). At the end
    of the transition, only the first door is open, that is
    \( d_1' = \mathtt{open} \) and \( d_2' = \mathtt{close} \).
      %
    By definition of \( \iota \), the statement to prove becomes
      %
    \[
      \mathtt{close} = \mathtt{close} \vee \mathtt{close} = \mathtt{close}
      \Rightarrow \mathtt{open} = \mathtt{close} \vee \mathtt{close} =
      \mathtt{close}
    \]
      %
    By definition of the disjunction \( \vee \), the statement reduces to
    \( \mathrm{True} \Rightarrow \mathrm{True} \), which is \( \mathrm{True} \)
    by definition of the implication \( \Rightarrow \).
    %
    The three other cases follow the exact same procedure.
    %
    \hfill \( \square \)
  \end{proof}

  In addition, we can also prove that both doors of the airlock will
  \emph{eventually} be close.
  %
  We can characterize this liveness property with the predicate \( \eta \) on
  subtraces of one element, such that
  %
  \[
    \eta(d_1, d_2) \triangleq d_1 = \mathtt{close} \wedge d_2 = \mathtt{close}
  \]
  %
  We verify the specification of the airlock system is correct with respect to
  the liveness property characterized by \( \eta \) by exhibiting a proof that
  for each transition of \( R \), one of the states satisfies \( \eta \), that
  is
  %
  \[
    \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \eta(d_1, d_2) \vee \eta(d_1',
    d_2')
  \]

  \begin{proof}
    Again, the proof proceeds by case enumeration with respect to the definition
    of \( R \), and after unfolding \( \eta \), we conclude thanks to the
    definition of \( \wedge \) and \( \vee \).
    %
    \hfill \( \square \)
  \end{proof}
\end{example}

Not all security policies can be formalized with predicates on traces.
%
For instance, \emph{noninterference}\,\cite{goguen1982security} is a
confidentiality policy which requires that so-called public inputs handled by a
given system always produce the same output, regardless of concurrent secret
inputs.
%
In this context, considering each trace independently is not sufficient, as to
witness a violation of the security policy requires to compare two traces
together.
%
As a consequence, such policies are characterized by sets of sets of traces;
they are called \emph{hyperproperties}\,\cite{marr2002hypertheading}.
%
Verifying a system with respect to a hyperproperty is harder in the general
case, but certain hyperproperties, called \( k \)-safety
properties\,\cite{marr2002hypertheading}, can be reduced to an invariant
enforcement which is more manageable to prove.
%
% For instance, we assume \( M \) handles inputs which can be either secret or
% public.
%%
% Let \( \equiv \) be the binary relation, such that two states \( s \) and
% \( r \) satisfies this relation (\( s \equiv r \)) if and only if they
% characterize two instances of the system which have handled the same public
% inputs and produced the same visible behavior.
%%
% Similarly to Gilles Barthe \emph{et al.}\,\cite{barthe2011virtcert1}, we can
% prove \( M \) \GH{Je n'aime pas cette formulation ambigue "we can
% prove". Est-ce que tu es en train de dire que Barthe a utilisé cette technique
% pour prouver le résultat? Dans ce cas, utilise la troisième personne : Barthe
% prove....} enforces noninterference if for any public input \( l \), then
%%
% \[
%   \forall (s, r) \in S \times S, s \equiv r \Rightarrow (s \xrightarrow{l} s'
%   \wedge r \xrightarrow{l} r') \Rightarrow s' \equiv r',
% \]
% where \( s \xrightarrow{l} s' \) is a transition of the system from a state
% \( s \) to a state \( s' \) wherein the input \( l \) is handled. \GH{et? Tu
% donnes des détails sur la non-interférence mais pas assez pour qu'on voit ou
% tu veux en venir. Donc soit tu t'en tiens à "certain hyperproperties ... can
% be reduced to an invariant" (avec une ref). Soit tu expliques un peu plus ce
% que tu veux nous faire comprendre...}

% \subsection{Adversary Model}
%
% An \emph{adversary model} (or \emph{threat model}) characterizes what
% attackers can and cannot do inside a system.
%%
% Security guarantees shall always be defined with respect to a certain
% adversary model, to define the limits of the system security enforcement
% mechanisms.
%%
% That is, attackers which can leverage capabilities outside of the adversary
% model are likely to defeat the security policies.
%%
% Adversary model is a theoretical tool commonly used in the verification of
% cryptographic protocol, with a well-identified hierarchy of archetypes
% (\emph{e.g.} the Dolev–Yao model allows attackers to intercept, modify,
% generate any messages, but require necessary secret to encrypt and decrypt
% messages\,\thomasrk{ref}).

% \begin{itemize}
% \item Combinatronics of system actions (Pip, VirtCert)
% \item Additional rule to model more powerful attacker (Moat, XOM + bus
%   snooping)
% \end{itemize}

\paragraph*{}
%
In the context of formal verification, a security policy is characterized by a
(set of) set(s) of traces wherein the policy is enforced at all times.
%
Because hardware features are unsafe, \emph{i.e.} they need to be configured by
trusted software components which implements \ac{hse} mechanisms, legitimate
traces of a general-purpose x86 model will not be part of the ``secure'' traces.
%
Our formal theory of \ac{hse} mechanisms allows for identifying the subset
of traces wherein the mechanism is correctly implemented by the trusted software
components. Verifying a \ac{hse} mechanism consists of proving this set of
traces satisfies the predicate which characterizes the targeted security policy.
%
Because of the complexity of a typical x86 architecture, this work cannot be
achieved manually and we need the support of an appropriate tooling.

\subsection{Approaches and Tools}
\label{subsec:sota:tools}

\GH{Je trouve que ce tour d'horizon des méthodes formelles est un peu rapide. Il
  gagnerait à être plus complet et mieux structuré.}
%
\thomasrk[inline]{Suite à notre conversation téléphonique, j’ai changé mon fusil
  d’épaule. J’ai enlevé la partie sur la construction de la preuve (sans doute
  intéressante, mais pas forcément utile), et j'ai changé la mentalité de la
  présentation des différentes logiques pour en faire une présentation des
  outils dispo et pourquoi on a choisit Coq.}

Formal verification leverages two classes of approaches with their dedicated
tools.
%
On the one hand, the most generic approach is the construction a proof, that is
a succession of inference rules to derive the statement to be proven from
formulas known to be true.
%
Theorem provers provide facilities to construct proofs, and a checker to
automatically verify these proofs.
%
On the other hand, it is possible to rely on algorithms whose correctness have
been formally established to handle a well-defined class of problems.
%
Model checking\,\cite{clarke2018modelc} and satisfiability
solvers\,\cite{gomes2008satisfiability} are two classical instances of this
approach.

The choice of one approach over another for a given verification problem is a
compromise constrained by requirements in terms of expressiveness, automation
and applicability.
%
More expressiveness for formal language increase the scope of verification
problem it can cover, but it also reduces the level of automation of the tools
used to verify its statements.
%
Fully automated procedures rely on algorithms whose computational complexity
impair their applicability for more complex problems, \emph{e.g.}  model
checking and the \emph{state explosion problem}.

We now give an overview of state of the art tools which are commonly leveraged
for formal verification of hardware and software components.
%
We have organized it according to the formal language they rely on.

\paragraph{Propositional and First-Order Logic.}
%
Propositional logic is characterized by \emph{terms}, which represents objects,
and \emph{logical operators}, such as conjunction \( \wedge \), disjunction
\( \vee \), implication \( \Rightarrow \), negation \( \neg \).
%
First-order logic\,\cite{smullyan2012fol} extends propositional logic with
\emph{predicates}, that is parameterized formulas that can be true or false with
respect to the applied terms, and \emph{quantifier}, such as \( \forall \) (all
values) or \( \exists \) (there exists a value).

SAT solvers \GH{ref, exemples de solver... Comme tu le fais plus loin pour les model checker} form a class of tools whose purpose is to determine whether a
given propositional formula with boolean variables is satisfiable, by finding
appropriate instances for these variables.
%
SMT solvers have a similar purpose, but they target first-order logic formula
---without quantifiers--- and are not limited to boolean variables (SMT stands
for satisfiability modulo theories).
%
Hence, in the theory of natural numbers, a SMT solver will find that the formula
\( x > y \wedge x + y = 5 \) is satisfiable with \( \{ x = 3, y = 2 \} \), but
the formula \( x - y = 0 \wedge x \neq y \) is not.
%
The lack of quantifiers has a significant impact on formulas expressiveness
which reduces its applicability when it comes to formal verification,
\emph{e.g.} we cannot express a specification of the form ``at any point in a
trace, a predicate \( P \) is satisfied'' if we consider a system can operate
infinitely.

% Finally, automated theorem provers (\emph{e.g.}
% Vampire\,\cite{riazanov2002vampire}, Z3\,\cite{de2008z3}) construct proofs of
% first-order logic formulas with quantifiers.

\paragraph{Temporal Logic.}
%
Modal logic\,\cite{chagrov1997modal} is a formal system which extends
first-order logic with modal operators.
%
Temporal logic forms a family of modal logic systems, including \emph{e.g.}
Linear Temporal Logic (LTL)\,\cite{sistla1985ltl} and Computation Logic Tree
(CTL)\,\cite{clarke1981ctl}.
%
Examples of LTL modular operators are \( \square P \) (\( P \) is always true),
\( \Diamond P \) (\( P \) will eventually become true), \( \bigcirc P \)
(\( P \) will be true after the next transition of the system).
%
CTL considers trees of possible futures (by opposition to a \emph{linear}
future).
%
CTL modal operator includes \( \mathbf{A} P \) (\( P \) is true for all possible
futures) and \( \mathbf{E} P \) (there exists at least one path where \( P \)
becomes true).
%
Temporal logic operators allow for reasoning about propositions over time on
infinite traces.
%
Temporal logic formulas are commonly verified thanks to model checkers,
\emph{e.g.}  NuSMV\,\cite{cimatti2002nusmv}, SPIN\,\cite{holzmann1997spin} or
TLA+\,\cite{lamport2002tla}.

Despite improvements in algorithms, model checkers remains subject to the
\emph{state explosion problem} \GH{ref sur ce problème?}, which imposes modeling compromises. For example, verification of cache coherency protocols with a fixed number of cores and
address spaces limited in size (\emph{e.g.} in \cite{lie2003xom}, the model only
considers three cache locations). \GH{Cette dernière phrase est à revoir, il y a un exemple dans un exemple. Outre que le fait que la phrase n'est pas très élégante, c'est hyper spécifique alors que tu veux illustrer un point asses générique. Tu devrais plutôt donner plusieurs examples assez générique pour donner du poid à ton argument}
%
% Other approaches can be used to that end ---for instance Gilles Barthe
% \emph{et al.} have encoded \( \square \) and \( \Diamond \) in
% Coq\,\cite{barthe2011virtcert1}--- yet model checkers have the benefit of
% automation and counter-example generation.
%
Bounded model checkers\,\cite{biere2003bounded} overcome this limitation by considering only finite
traces.
%
As a consequence, temporal logic formula can be translated into acceptable
inputs for SMT solvers, but this can abate the verification results, in
particular if the chosen maximum length of traces is too low. \GH{ref?}

\paragraph{Higher-order Logic.}
%
First-order logic quantifiers can only be applied on sets of terms (\emph{e.g.}
natural numbers, booleans, or more complexe structures such as the states of an airlock system).
%
Higher-order logic\,\cite{leivant1994hol} does not suffer the same limitation,
since they allow quantification over sets of sets, functions and predicates.
%
Hence, it becomes possible to express statements such as \emph{for all sets with
  a total order \( < \), for all pair of values \( \alpha, \beta \), then either
  \( \alpha < \beta \) or \( \beta < \alpha \) or \( \alpha = \beta \)}.
%
Therefore, higher order logic is more expressive than first-order logic, but it
comes at a cost in terms of automation.
%
Interactive theorem provers (\emph{e.g.}  Coq, Isabelle/HOL, \GH{ref sur Coq, Isabelle et HOL} or more recently
Lean\,\cite{de2015lean}) are based on higher-order logic.

We leverage a higher-order logic to propose our formal theory of \ac{hse}
mechanisms, which allows us to reason about high-level properties implying
\ac{hse} mechanisms. For example, in Section~\ref{subsec:speccert2:coop} \GH{la référence est cassée}, we
reason about the composition of two \ac{hse} mechanisms whose only the targeted
security policies are known ---even the hardware model is left as a parameter of
the proof.
%
To increase our confidence in our results, we systemically wrote our proofs in
the Coq theorem prover, and we made the resulting projects available under free
software license\,\cite{letan2016speccertcode,letan2018freespeccode}. \GH{cette dernière remarque n'a rien à faire dans l'état de l'art}

\GH{je trouve que le choix de Coq mériterait d'être un peu mieux justifié. Pourquoi a-t-on besoin d'une logic d'ordre supérieur. Tu ne le justifie que sur un aspect assez anecdotique de ton travail (la composition des HSE).}

\subsection{Tour of Existing x86 Models}
\label{subsec:sota:ltsrelated}

To experiment with our approach, we decided to focus on the \ac{hse} mechanism
implemented by the \ac{bios} at runtime to remain isolated from the rest of the
software stack (Section \ref{sec:usecase:hse}). We specify this mechanism and verify its correctness with the security policy it aims to enforce using Coq.
%
We now give an overview of existing x86 models, and justify our choice to
develop our own model.

\paragraph{x86 Models by Intel.}
%
Intel has integrated formal verification in its processors design process for
more than a decade now.
%
Intel engineers first verified arithmetic operations performed by the
processors\,\cite{harrison2000x86}, then increased the verification scope to
cover the complete execution unit\,\cite{kaivola2009formalintel}.
%
More recently, the SGX instructions ---which allow system software components to
create and manage enclaves\,\cite{costan2016sgxexplained}--- have been verified
with respect to security properties, rather than functional
specification\,\cite{leslie2015linsgx}.
%
Each project focused on one aspect of the x86 architecture and led to uncover
logic errors and inconsistencies in processor designs, while we aim for a more
general-purpose model with a large scope with respect to hardware components.
%
However, the models and tools used by Intel are rarely publicly available, hence
we could not leverage them to experiment with our approach.
%
Besides, to the extend of our knowledge, Intel has not advertised about a
``global'' model of its architecture, even though Nachiketh Potlapally, who was
working at Intel at the time, discussed the benefits of such a model in
2011\,\cite{potlapally2011hardwaresecurity}.

\paragraph{x86 ISA Models.}
%
Additionally, several x86 model have been proposed by academic researchers over
the years for purposes of formally reasoning about machine-code programs.
%
To that end, they have modeled the x86 instructions set semantics, often
referred to as x86 ISA.

Probably the most mature projects include RockSalt by Morissett \emph{et
  al.}\,\cite{morrisett2012rocksalt}, Goel \emph{et al.}
framework\,\cite{goel2014x86}, and CompCert x86 assembly
model\,\cite{leroy2012compcert}.
%
These models allow for reasoning about the execution of one software component
in isolation, and focus on the semantics of the x86 instructions set and
abstract away as many hardware details as possible to increase the applicability
of the model.
%
For instance, memories are commonly limited to the \ac{dram}.
%
This approach works well when software components use a limited amount of
hardware features, as applications typically do, and to reason about correction
with respect to functional specifications.
%
It has been shown in the past that it is possible to extend them, when their
abstraction is too strong.
%
For instance, Chen \emph{et al.} have extended the hardware model of CompCertX,
a variant of CompCert used in the development of formally verified
kernels\,\cite{gu2016certikos}, with a notion of input devices and
interrupts\,\cite{chen2018interrupt}.

However the primarily focus of these projects is to reason about software
components, not the underlying hardware architecture.

\paragraph{Ad-hoc x86 Models}
%
Another category of x86 models is ad-hoc models, specially developed to verify a
dedicated system software component.
%
As such, they focus on hardware features used by the target of verification.
%
The objective of these approaches is to verify the software component and so
they suppose the hardware will behave as expected.
%
On the contrary, we aim to specify requirements on software components, and to
use these requirements as assumptions to verify the underlying architecture.

The seL4 microkernel\,\cite{sel4website} is, to date, the most advanced and
mature verified implementation of a microkernel.
%
A C implementation of the kernel is proven correct with respect to a functional
implementation modeled in the Isabelle/HOL theorem prover, and the authors have
proven this model correctly enforces security policies including information
flow control, integrity and confidentiality\,\cite{klein2009sel4}.
%
In practice, the hardware model focus on \ac{mmu}, cache and interrupt handling,
and in large parts the exact behavior of hardware devices is left
non-deterministic, in order to reduce the assumptions made by the model about
the hardware.
%
Besides, we already mentioned the work of Jomaa \emph{et
  al.}\,\cite{jomaa2016mmu}.
%
In 2016, they have proposed a formal machine-checked proof (in Coq) of guests
isolation by an idealized protokernel based on a \ac{mmu}.
%
Similarly to seL4, their hardware model focus on \ac{mmu} and interrupt
handling.
%
In both cases, there is a clear separation between the software component model
and the hardware model, and it may be possible to extract the hardware model and
reuse it.
%
However, their scope does not include the hardware features involved in the
\ac{hse} mechanisms implemented by the \ac{bios} and described in
Section~\ref{subsec:usecase:firm:sec}.

Between 2011 and 2014, Gilles Barthe \emph{et al.} have worked on an idealized
model of a
hypervisor\,\cite{barthe2011virtcert1,barthe2012virtcert2,barthe2014virtcert3}.
%
This model is defined in terms of states, actions and the semantics of actions
as state trans\-formers.
%
The state definition mixes information about both hardware components (\ac{cpu}
execution mode, registers, memory content, etc.) and software components (list
of guests, the current active guest, memory mapping for the hypervisor and the
guests, etc.).
%
The set of actions describes the events which can trigger a transformation of
the model states.
%
For instance, it includes various tasks that the hypervisor must carry out, such
as scheduling the guests OS, hypercalls handling, or memory management.
%
Certain actions also witness the execution of guests, for instance when the
currently running OS reads from or writes to memory.
%
The resulting project, called VirtCert and implemented in the Coq theorem
prover, is fairly large, with over 50,000 lines of code.
%
The verification results focus on various isolation properties, from the most
natural and straightforward (\emph{i.e.} an OS guest cannot write to or read
from a page it does not own) up to non-interference variants including
protection against cache-timing attacks, notoriously harder to reason with.
%
However, the model combines hardware and software components behavior and we
would have to make significant changes prior to using it.

\paragraph{Other Hardware Architecture Models.}
%
The x86 architecture is not the only hardware architecture which has been the
object of formal verification projects.
%
We detail two projects targeting two architectures ---ARM and XOM--- because
they follow alternative approaches that are of interest with respect to our
goal.

The two latest versions of the ARM processors have been formally
specified\,\cite{fox2010armv7,reid2016armv8}.
%
It is important to emphasize that the specification of the ARMv8
architectures\footnote{There are three variants of the ARM Architecture, for as
  many use cases: the A-class architecture provides the necessary features to
  allow an operating system to manage applications, the R-class processors are
  dedicated to real-time systems, and the M-class are used in microcontrollers.}
is the result of an important 5 year effort by ARM Ltd to integrate formal
specification definition to their regular specification
process\,\cite{reid2016armv8}.
%
The formal specification of ARMv8 architectures is written in a dedicated
language called ARM Specification Language, and has been intensively validated
against the ARM internal conformance testsuit.
%
Once the level of trustworthiness of the ASL specifications have been asserted,
they have been able to leverage them to formally verify properties of the
hardware architectures, \emph{e.g.} by compiling them to a subset of Verilog
accepted by commercial Verilog model checkers\,\cite{reid2016end}.
%
The result of these efforts is being made available on the ARM website, in
addition to regular informal specifications\,\cite{arm2018aspec}.
%
This represent an exciting opportunity for research targeting ARM architectures,
and we can only hope that it eventually becomes a standard in the industry.

ASL is used to \emph{describe} the architecture in an unambiguous fashion, but
it cannot be used as-is to reason about the correctness of this architecture.
%
This means the ASL model has to be compiled to another representation,
\emph{e.g.} Verilog or a model checker modeling language.
%
On the contrary, we decided to implement our model directly in the language used
by the tool supporting our verification process because we were targeting a
proof of concept.

The \ac{xom} microprocessor architecture maintains separate so-called
\emph{compartments} for applications\,\cite{lie2000architectural}.
%
A \ac{xom} \ac{cpu} keeps track of each memory location owner, thanks to a
tagging mechanism, and supposedly prevents an application from accessing a
memory location it does not own.
%
In 2003, David Lie \emph{et al.} have verified the \ac{xom}
architecture\,\cite{lie2003xom} using the Mur$\varphi$ model
checker\,\cite{murphi}.
%
The verification objective of the authors was to prove that the \ac{xom}
architecture fulfills its promise to be tamper-resistant, by forbidding an
attacker to modify the memory location owned by a given application.
%
The verification proceeds as follows:
%
\begin{enumerate}
\item A first specification of the \ac{xom} architecture, called the ``actual
  model'', is defined.
  %
  States of this first model contain different hardware components of a \ac{xom}
  microprocessor, \emph{i.e.} registers, cache, volatile memory, and the
  internal machinery of \ac{xom} to track ownership of memory locations.
  %
  Transitions can be divided into two categories: the normal execution of an
  application by the microprocessor, and active tampering from an adversary
  part, leading the actual model to embed an adversary model.
  %
\item A second specification, called the ``idealized model'', abstracts away the
  memory hierarchy formed by the cache and the volatile memory, and models the
  execution of a single application, without an adversary.
  %
  From this perspective, it encodes the security property.
  %
\item To let Mur\( \varphi \) explore both models simultaneously, the authors
  have manually defined a third model.
  %
  Transitions which describe the execution of an application in the actual model
  also update the idealized model, whereas transitions which describe actions by
  the attacker only affect the actual model.
  %
\item The authors have defined a function which checks if an ``actual state'' is
  equivalent to an ``idealized state'', and let Mur\( \varphi \) verify that the
  state equivalence is an invariant of the third model.
\end{enumerate}
%
In the process of verifying \ac{xom}, the authors have been able to show with
their model that the \ac{xom} architecture was subject to several replay
attacks, and that the countermeasures they proposed were effective.
%
The formalism used to define the actual model follows a logic which is
approaching our needs.
%
The labels of the transitions characterize the execution of a software component
by the architecture, without any detail in the model about its behavior or its
implementation.
%
However, we believe the necessity to manually maintain a merge of two transition
systems reduces its applicability in the long run, as new architecture versions
are released frequently.
%
This is why our formal theory of \ac{hse} mechanism is characterized by a subset
of traces of a model, rather than an additional, idealized model.
%
% Besides, the state explosion problem forces the authors to simplify their
% model, in order to reduce the state combinatory.
%%
% From a security perspective, simplifying the model comes with the risk to hide
% an attack path.

\subsection{Conclusion}
\label{subsec:sota:ltsconclusion}

We face a 'chicken-and-egg' problem:
%
\begin{inparaenum}[(1)]
\item our approach assumes the existence of a general-purpose hardware model,
  comprehensive it terms of hardware feature,
  %
\item the existing models focuses on providing an abstraction of a x86 hardware
  architecture to reason about machine-code, or on a particular sets of hardware
  features to verify them in isolation or because they are leveraged by a system
  software component,
  %
\item we anticipate a great care should taken in defining our required model, to
  manage the scale of the x86 hardware architecture.
\end{inparaenum}
%
It would require a tremendous amount of efforts to be developed, reviewed and
validated, and the question of its applicability in a verification process would
have to be demonstrated.

Therefore, we decided to compromise and experiment on an ad-hoc model with the
aim of identifying desirable properties for a large-scale, general-purpose model
that would optimize the applicability of our approach; and because the scope of
existing models does not cover the features that a \ac{bios} relies on to
enforce its isolation, we developed our own minimal model.
%
\GH{Je trouve cet argumentaire un peu casse-gueule... Tu laisse entendre que les
  modèles existants sont incomplet et spécifique à un mécanisme. Or tu as
  développé un modèle largement incomplet et dédié à la vérification d'un seul
  mécanisme (même s'il pourrait sans doute être étendu).}%
\thomasrk[inline]{Est-ce que ça te semble mieux ?}

To verify a specific \ac{hse} mechanism, the need for higher-logic is not
prominent because first-order logic quantifiers are expressive enough.
%
Therefore, we can theoretically leverage a large class of tools, in particular
model checkers which have the benefit of automation.
%
We anticipate the scale of the x86 hardware architecture, with hundreds of
interdependent features, would make a general-purpose model subject to the state
explosion problem, which would reduce the applicability of model checkers.
%
Hardware verification by means of theorem provers has proven to be a practical
alternative to model checking\,\cite{vijayaraghavan2015modular,choi2017kami},
and a successful solution to address the state explosion problem.
%
For these reasons, we decided to implement our model and proofs using the Coq
theorem prover.

\section{Compositional Verification}
\label{section:sota:compsec}

Our formal theory of \ac{hse} mechanisms makes a clear distinction between
software components and the underlying hardware architecture which executes
them.
%
A \ac{hse} mechanism consists of requirements that trusted software components
need to satisfy in order for the hardware architecture to correctly enforce a
targeted security policy at all time.

Our approach is reminiscent of assume-guarantee\,\cite{pnueli1985ag} and
rely-guarantee\,\cite{jones1983tentative} paradigms, where a component \( C \)
is proven to enforce a guarantee \( G \) as long as an assumption \( A \) is
met.
%
Compositional reasoning is not limited to reasoning about components in
isolation, it also allows for verifying their composition.
%
If a component \( C' \) is proven to enforce \( A \), then the composition of
\( C \) and \( C' \) enforces \( G \).

Our second contribution generalizes the key idea of our \ac{hse} mechanisms
formal theory ---that is specifying requirements and verifying they fulfill
their promises--- with compositional reasoning, in order to address the
challenge posed by the inevitable complexity of a general-purpose hardware
architecture model.
%
Given three components, such that a component \( R \) uses a component \( S \)
to operate, and \( S \) uses a third component \( T \), we target a verification
approach that we summarize as follows.

\begin{center}
  \begin{tikzpicture}
    \node [draw, inner sep=16pt, text badly centered] (A) {\( R \)};%
    \node [draw, inner sep=16pt, text badly centered, right=35pt of A] (B)
    {\( S \)};%
    \node [draw, inner sep=16pt, text badly centered, right=35pt of B] (C)
    {\( T \)};%

    \draw [-latex] ([yshift=7pt]A.east) to node [above] {(2)}
    ([yshift=7pt]B.west);%
    \draw [-latex] ([yshift=7pt]B.east) to node [above] {(3)}
    ([yshift=7pt]C.west);%
    \draw [-latex] ([yshift=-7pt]C.west) to node [below] {(4)}
    ([yshift=-7pt]B.east);%
    \draw [-latex] ([yshift=-7pt]B.west) to node [below] {(1)}
    ([yshift=-7pt]A.east);%
  \end{tikzpicture}
\end{center}

The verification goal is to prove that \( S \) enforce a guarantee for \( R \)
(1), as long as \( R \) satisfies certain assumption (2).
%
% note: “cannot but” est l’équivalent anglais de “ne peut que”, que j’aime
% personnellement beaucoup
Because \( S \) uses \( T \), such a proof cannot but depend on how \( T \)
operates.
%
We propose to define another pair of assumption and guarantee for \( T \), and
assume \( T \) is correct with respect to this pair.
%
In this context, it is possible to prove that \( S \) enforces its guarantee if
it satisfies the assumptions of \( T \), and if the guarantee of \( T \) are
sufficient about the guarantee of \( S \).
%
In practice, \( T \) may use another component \( U \) to operate, and a proof
of correctness for \( U \) will therefore follows the same approach.

Previous work have already advocated for compositional reasoning for security,
notably Garg \emph{et al.}\,\cite{garg2010compositional} and Heyman \emph{et
  al.}\,\cite{heyman2012securemodel}.
%
Therefore, this reasoning methodology goes beyond our initial scope, that is
\ac{hse} mechanisms specification and verification, and can be leveraged for a
large range of verification problems involving interconnected components.
%
For this reason, we aim to propose a general-purpose framework for Coq to
support this approach, with two objectives in particular:
%
\begin{inparaenum}[(1)]
\item we want to use well-established constructions in functional programming
  communities in order to favor adoption, and
\item we want to enable component models to be executable if needed, \emph{e.g.}
  to validate them against concrete implementation or to act as a reference
  implementation.
\end{inparaenum}

The rest of this Section proceeds as follows.
%
First, we discuss how labeled transition systems can be used to model
interacting components (\ref{subsec:sota:ioauto}), and how process algebra
systems have been used to facilitate the definition of these interactions
(\ref{subsec:sota:palgebra}).
%
We then explain how we take advantage of a functional programming language
paradigm called programs with effects and effect handlers as a foundation for a
compositional reasoning framework for Coq, drawn from these two approaches and which
addresses our objectives (\ref{subsec:sota:peff}).

\subsection{Labeled Transition Systems and Components Composition}
\label{subsec:sota:ioauto}

Labeled transition systems have originally been introduced to reason about
automata compositions\,\cite{loiseaux1995lts}, with the idea that transitions of
different transition systems which share the same label happen simultaneously.
%
In our context, an interesting variant of LTS is interface
automata\,\cite{de2001interfaceautomata}, because they distinguish between three
classes of transitions, modeled with three disjoint sets of labels: input
actions (denoted by \( \mathrm{in}(S) \) for an automaton \( S \)), output
actions (denoted by \( \mathrm{out}(S) \)), and internal actions (denoted by
\( \mathrm{int}(S) \)).
  %
%
They form the signature of a given automaton (denoted by \( \mathrm{act}(S) \)).
%
Its transition relation \( R(S) \) is a subset of
\( \mathrm{state}(S) \times \mathrm{act}(S) \times \mathrm{state}(S) \), where
\( \mathrm{state}(S) \) is the set of states of \( S \).
%
Composition of interface automata is achieved \emph{via} input and output
actions.
%
More precisely, when one automaton performs an output action \( \pi \) during a
transition, all automata having \( \pi \) as input action perform \( \pi \)
simultaneously.

\begin{example}[Airlock System as Interface Automata]
  \label{example:sota:airlockinterface}

  In order to illustrate how a system can be broken down into small components,
  we take once again the example of the airlock system.
  %
  In this context, the most obvious component is the door.
  %
  A door has two states: it can be either open or close.
  %
  It takes two input actions: \( \mathtt{Open} \) (the action to open the door)
  and \( \mathtt{Close} \) (the action to close the door).
  %
  It does not have any output action, which means a door does not interact
  actively with the rest of the system.
  %
  One possible specification for the \( i^{th} \) door of a airlock system is
  the following interface automaton:

  \begin{center}
    \begin{tikzpicture}
      \node [draw, circle] (o) {1};%
      \node [draw, circle, right=of o] (c) {2};%

      \draw [-latex] (o) edge [bend left] node [above] {\( \mathtt{Open}_{i} \)}
      (c);%
      \draw [-latex] (c) edge [bend left] node [below]
      {\( \mathtt{Close}_{i} \)} (o);%
      \draw [-latex] (c) edge [loop right] node {\( \mathtt{Open}_{i} \)} (c);%
      \draw [-latex] (o) edge [loop left] node {\( \mathtt{Close}_{i} \)} (o);%

      \node [draw, fit=(o) (c), inner sep=20pt, text width=130pt, text badly
      centered] (d1) {};%

      \node [yshift=10pt, left=35pt of d1.west] (open) {};%
      \draw [-latex] (open) to node [above] {\( \mathtt{Open}_{i} \)}
      ([yshift=10pt]d1.west);%
      \node [yshift=-10pt, left=35pt of d1] (close) {};%
      \draw [-latex] (close) to node [above] {\( \mathtt{Close}_{i} \)}
      ([yshift=-10pt]d1.west);%
    \end{tikzpicture}
  \end{center}

  In addition to two doors, an airlock system needs a controller, whose purpose
  is to handle requests coming from users and effectively open and close doors
  in consequence.
  %
  We consider a slightly different situation than the specification given in
  Example~\ref{example:sota:airlocklts}.
  %
  Here, there are only two commands, modeled with two input actions:
  \( \mathtt{Req}_1 \) (one user wants the first door to be opened) and
  \( \mathtt{Req}_2 \) (one user wants the second door to be opened).
  %
  The controller does not embed the states of the doors, but has four output
  actions, two per doors (\( \mathtt{Open}_i \) and \( \mathtt{Close}_i\), for
  \( i \in \{1, 2\}\)).
  %
  We propose the following interface automaton:

  \begin{center}
    \begin{tikzpicture}
      \node [draw, circle] (s1) {2};%
      \node [draw, circle, right=50pt of s1] (s2) {3};%
      \node [draw, circle, right=50pt of s2] (s3) {4};%

      \draw [-latex] (s1) to node [above] {\( \mathtt{Close}_2 \)} (s2);%
      \draw [-latex] (s2) to node [above] {\( \mathtt{Open}_1 \)} (s3);%

      \node [draw, circle, below=60pt of s3] (s4) {5};%
      \node [draw, circle, left=50pt of s4] (s5) {6};%
      \node [draw, circle, left=50pt of s5] (s6) {7};%

      \draw [-latex] (s4) to node [below] {\( \mathtt{Close}_1 \)} (s5);%
      \draw [-latex] (s5) to node [below] {\( \mathtt{Open}_2 \)} (s6);%

      \node [draw, circle, below=21pt of s2] (s7) {1};%

      \draw [-latex] (s7) to node [left,yshift=-5pt] {\( \mathtt{Req}_1 \)}
      (s1);%
      \draw [-latex] (s7) to node [right,yshift=5pt] {\( \mathtt{Req}_2 \)}
      (s4);%

      \draw [-latex] (s3) edge [bend left] node [right] {\( \mathtt{Req}_2 \)}
      (s4);%
      \draw [-latex] (s6) edge [bend left] node [left] {\( \mathtt{Req}_1 \)}
      (s1);%

      \node [draw, fit=(s1) (s4), inner sep=20pt, text width=220pt] (ctrl) {};%

      \node [yshift=20pt, left=35pt of ctrl] (in_open1) {};%
      \draw [-latex] (in_open1) to node [above] {\( \mathtt{Req}_1 \)}
      ([yshift=20pt]ctrl.west);%
      \node [yshift=-20pt, left=35pt of ctrl] (in_open2) {};%
      \draw [-latex] (in_open2) to node [above] {\( \mathtt{Req}_2 \)}
      ([yshift=-20pt]ctrl.west);%

      \node [yshift=45pt, right=35pt of ctrl] (out_open1) {};%
      \draw [latex-] (out_open1) to node [above] {\( \mathtt{Open}_1 \)}
      ([yshift=45pt]ctrl.east);%
      \node [yshift=15pt, right=35pt of ctrl] (out_close1) {};%
      \draw [latex-] (out_close1) to node [above] {\( \mathtt{Close}_1 \)}
      ([yshift=15pt]ctrl.east);%

      \node [yshift=-15pt, right=35pt of ctrl] (out_open2) {};%
      \draw [latex-] (out_open2) to node [above] {\( \mathtt{Open}_2 \)}
      ([yshift=-15pt]ctrl.east);%
      \node [yshift=-45pt, right=35pt of ctrl] (out_close2) {};%
      \draw [latex-] (out_close2) to node [above] {\( \mathtt{Close}_2 \)}
      ([yshift=-45pt]ctrl.east);%

      \draw (s3) edge [loop right] node {\( \mathtt{Req}_1 \)} (s3);%
      \draw (s6) edge [loop left] node {\( \mathtt{Req}_2 \)} (s6);%
    \end{tikzpicture}
  \end{center}
\end{example}

Input and output actions models two facets of a component: how it is being used
(input), and how it uses other components (output).
%
However, it is a fairly low-level modeling structure, which complicates its
usage for a large scale model --- for instance, our airlock system controller is
modeled with seven different states--- and impair the model readability.
%
As a possible solution to overcome this difficulty, we investigate the
possibility to associate input actions with ``programs'' of output actions a
component executes.
%
To continue with the airlock system example, the input action ``Request to open
the first door'' could be associate with the sequence of output actions ``Close
the second door'' then ``Open the first door''.

\subsection{Process Algebra}
\label{subsec:sota:palgebra}

Process algebra have been developed to reason about programs executed in
parallel, and it comes with a proof system to verifying the resulting system.
%
In process algebra such as Calculus of Communication
Systems\,\cite{milner1980ccs} or the Communicating Sequential
Processes\,\cite{hoare1978csp}, concurrent threads run in parallel, and
synchronization is achieved by sending and waiting for messages, as specified by
a dedicated language.

Using these languages, we can write our ``programs of output actions'', as we
demonstrate in the following example.

\begin{example}[Airlock System in \( \pi \)-calculus]
  \label{example:sota:airlockprocess}

  We now try to give a specification of our airlock system using a process
  algebra called \( \pi \)-calculus.
  %
  Once again, we consider three components: two doors and a controller.
  %
  Our objective is to write a specification equivalent to our interface automata
  (although we do not provide a proof of that equivalence).

  We have used the following \( \pi \)-calculus construction to specify the
  airlock system:
  %
  \begin{itemize}
  \item \( c(x). P\) means receiving a value from the channel \( c \), bounding
    this value to the fresh name \( x \), then executing the process \( P \).
  \item \( \bar{c} \langle x \rangle . P \) means sending the name \( x \)
    through the channel \( c \), then executing the process \( P \).
  \item \( [x = \mathrm{OPEN}] P \) is a guard, that is \( P \) is executed if
    \( x \) is equal to the name \( \mathrm{OPEN} \).
  \item \( P + Q \) is the nondeterministic choice operator, we use it here in
    conjunction with guards to implement a \texttt{if-then-else} construct. That
    is, considering the process
    %
    \[
      c(x) . ([x = 1] P + [x = 2] Q)
    \]
    %
    If the value received from \( c \) is \( 1 \), \( P \) is executed.
    %
    If it is \( 2 \), then \( Q \) is executed.
  \item \( \nu c. P \) means a new name \( c \) is created, and available for
    \( P \) to use it.
  \item \( P || Q \) is the parallel execution of \( P \) and \( Q \).
  \end{itemize}

  \[
    \begin{array}{rcl}
      \mathrm{CloseDoor}(c)
      & \triangleq
      & c(x) . \ ([x = \mathrm{OPEN}] \mathrm{OpenDoor}(c) \\
      &
      & \qquad + [x = \mathrm{CLOSE}] \mathrm{CloseDoor}(c)) \\
      & & \\
      \mathrm{OpenDoor}(c)
      & \triangleq
      & c(x) . \ ([x = \mathrm{CLOSE}] \mathrm{CloseDoor}(c) \\
      &
      & \qquad + [x = \mathrm{OPEN}] \mathrm{OpenDoor}(c)) \\
      & & \\
      \mathrm{Controller}(c, d_1, d_2)
      & \triangleq
      & c(x). \ \ [x = \mathrm{OPEN}_1] \bar{d_2} \langle
        \mathrm{CLOSE} \rangle . \bar{d_1} \langle \mathrm{OPEN} \rangle . \mathrm{Controller}(c, d_1, d_2) \\
      &
      & \qquad + [x = \mathrm{OPEN}_2] \bar{d_1} \langle
        \mathrm{CLOSE} \rangle . \bar{d_2} \langle \mathrm{OPEN} \rangle. \mathrm{Controller}(c, d_1, d_2) \\
      & & \\
      \mathrm{System}
      & \triangleq
      & \nu c. \nu d_1. \nu d_2. (\mathrm{Controller}(c, d_1, d_2) \\
      &
      & \quad\qquad\qquad ||\ \mathrm{CloseDoor}(d_1) \\
      &
      & \quad\qquad\qquad ||\ \mathrm{CloseDoor}(d_2))
    \end{array}
  \]

  The system, modeled with the process \( \mathrm{System} \) creates the
  channels used by its components to communicate, then starts their concurrent
  executions.
  %
  A door is either open or close, and we model this with two mutually recursive
  processes \( \mathrm{CloseDoor} \) and \( \mathrm{OpenDoor} \).
  %
  They take one channel \( c \) as an argument, then wait for new inputs coming
  from \( c \).
  %
  A controller is a recursive process which takes three channels \( c \),
  \( d_1 \) and \( d_2 \) as arguments.
  %
  It waits for new requests coming from \( c \).
  %
  When it receives a new request to open the first (resp. second) door, it first
  close the second (resp. first) door, using the channel \( d_2 \) (resp.
  \( d_1 \)).
  %
  Then, it opens the first (resp. second) door, using the channel \( d_1 \)
  (resp. \( d_2 \)).
\end{example}

Process algebras such as \( \pi \)-calculus are well suited formalisms for
describing component interactions.
%
In our case, we implement a simple pattern: wait for requests, act accordingly,
then start again.
%
A similar approach has been proposed by Choi \emph{et al.} in 2017.
%
They have released {\scshape Kami}\,\cite{choi2017kami}, a framework for Coq to
design, verify and extract (in the form of BlueSpec\,\cite{nikhil2004bluespec}
programs) hardware components implementations.
%
In {\scshape Kami}, components are defined as modules \( M \), that is a
particular labeled transition system, whose transitions are of the form
%
\[
  p \xrightarrow[a]{i} (v, q)
\]
%
where \( i \) is an operation called by another component, \( p \) is the state
of the component before the operation \( i \), \( a \) is a program of actions
performed by the component in order to compute the result of \( i \), \( v \) is
the result of \( i \) that is returned to the caller, and \( q \) is the
modified state of the component.
%
Actions, in this context, are either local manipulation of the component's state
or calls of operations handled by other components.

To reason about \( M \) with respect to a specification \( M_S \), {\scshape
  Kami} introduces a refinement relation \( \sqsubseteq \).
%
A module \( M \) refines a module \( M_S \) (\emph{i.e.} \( M \) is an
implementation of \( M_S \)) if any traces of \( M \) can also be produced by
\( M_S \).
%
A component \( M \) can be composed with another component \( M' \) to form a
larger component \( M + M' \), for instance when the operations exposed by
\( M' \) are used by \( M \).
%
The authors introduced another ``modular'' refinement property, whose simplest
expression could be
%
\[
  M \sqsubseteq N \wedge R \sqsubseteq S \Rightarrow M + R \sqsubseteq N + S
\]
%
They proved the correctness of a realistic multiprocessor system with respect to
a simple ISA semantics and Lamport's sequential
consistency\,\cite{lamport1979sc} as the memory model.
%
Their proofs consist in a succession of refinement proofs from their
implementation to high-level modules which model the instructions semantics and
processor memory model.

{\scshape Kami} relies on a very interesting approach to model interconnected
components.
%
It extends labeled transition systems to associate programs of output actions to
transitions labeled with input actions.
%
However, and similarly to previous hardware verification researches, the proofs
focus on properties that are transparent to software components and do not
require configuration from their part.
%
The verification process relies an successive refinement, rather than a
compositional reasoning based on assume-guarantee paradigm.
%
Besides, {\scshape Kami} targets hardware designers, and the syntax used to
define modules is heavily inspired by the BlueSpec language.
%
On the contrary, we aim to provide a more general-purpose framework, which
enables compositional reasoning.

\subsection{Programs with Effects and Effect Handlers}
\label{subsec:sota:peff}

We remind our initial objective: reasoning about the interactions of a component
with the rest of the system.
%
We believe it is reminiscent of the functional programming language problematic
to model and verify large programs with side-effects.
%
These side-effects are often carried out by an outer environment, \emph{e.g.} a
program which reads the content of a file relies on an operating system to
access the file stored in a hard drive and makes this content available in its
address space.
%
Modeling side effects in pure programming language, such as Haskell or {\scshape
  Gallina}, is usually achieved thanks to
monads\,\cite{wadler1990comprehending,jones2005io}, but they have a reputation
not to compose very well\,\cite{hyland2006combining}, despite constructions such
as monad transformers\,\cite{liang1995mtl}.

Recently, algebraic effects and effect handlers\,\cite{bauer2015effects} have
been proposed to address this limitation, and they have been the object of
implementations for several significant functional programming languages
functional languages (\emph{e.g.}  Eff\,\cite{bauer2015effects}, {\scshape
  Idris}\,\cite{brady2013idris}, or Haskell\,\cite{kiselyov2013extensible}).
%
We advocate that an approach based on algebraic effects and effect handlers
addresses our two objectives: we can leverage the ``do-notation'' ---already
used in language such as Haskell\,\cite{haskell13}--- to improve our models
readability, and the paradigm is now well-established in the functional
programming language community.

\paragraph{Related Work}
%
The \texttt{Coq.io} framework, developed and released by Guillaume Claret
\emph{et al.}\,\cite{claret2015coqiowww}, is a first step in that direction.
%
Programs with effects in \texttt{Coq.io} are defined in a dedicated monad, with
side effects (\emph{e.g.}  system calls to read from or write to a file)
axiomatized as monadic operations of this monad.
%
The proofs rely on scenarios which determine how an environment (\emph{e.g.} an
operating system) would react to the program requests.
%
The verification goal is to verify that, under the hypothesis that the
environment is correct with respect to a scenario, then a program with effects
is also correct with respect to an expected trace of side effects operations it
produces.
%
\texttt{Coq.io} paves the road towards a compositional approach reasoning in
Coq, but remains incomplete in our perspective.
%
A program with effects can be verified, but the verification of the composition
of this program with its environment is out of the scope of the project.

Our approach replaces \texttt{Coq.io} scenarios by so-called abstract
specifications which enable compositional reasoning similar to what have been
proposed\,\cite{souquieres2005verifying,chouali2006proving,lanoix:hal-00105041}
for the B-method\,\cite{abrial2005b}, a well-established method of software
development based on the B formal system.
%
B allows for the definition of functional specifications, called abstract
machines, and the refinement of these specifications up to executable code.
%
An abstract machine is characterized by a set of variables, and several
operations which update these variables. Preconditions in form of predicates on
the machine variables can be attached to a given operation to specify when the
operation can be used.
%
B has already been used in order to reason about systems made of components
which interact \emph{via}
interfaces\,\cite{souquieres2005verifying,chouali2006proving,lanoix:hal-00105041}.
%
In particular, Lanoix \emph{et al.}\,\cite{lanoix:hal-00105041} proposed the
following reasoning:
%
\begin{itemize}
\item Interfaces and requirements over components which expose these interfaces
  are defined in the form of an abstract machine, where the operations
  preconditions models the assumption a user needs to satisfy.
  %
\item A component which exposes this interface is expected to be a refinement (a
  more concrete implementation) of this abstract machine.
  %
\item A model of a component which uses an interface can \emph{include} the
  abstract machine which models this interface and uses its operations,
  similarly to what aggregation enables in object orienting programming
  language.
\end{itemize}

% The formal framework proposed by Garg \emph{et
% al.}\,\cite{garg2010compositional} does not suffer this limitation.
% %
% It consists in a logic of programs with effects and a companion proof system
% that enables compositional reasoning.
% %
%
% but to the extent of our knowledge, it lacks an implementation of their
% approach, and the examples which support the description of the paper rely on
% paper proofs.

\subsection{Conclusion}
\label{subsec:sota:compconclu}

Our formal theory of \ac{hse} mechanisms is reminiscent of the assume-guarantee
paradigm, where a component is verified in isolation in terms of assumptions it
has on the rest of the system and guarantees it enforces for that system if its
assumptions are met.
%
To address the inevitable complexity of a general-purpose hardware architecture
model, we make an additional step in that direction and verify each hardware
component in isolation with a similar reasoning.
%
With FreeSpec\,\cite{letan2018freespeccode}, we aim to provide a generic
compositional reasoning framework for Coq.
%
As detailed in Chapter~\ref{chapter:freespec}, FreeSpec leverages programs with
effects and effect handlers to model component-based system.
%
FreeSpec relies on so-called abstract specification in order to enable a
verification methodology inspired by the assume-guarantee paradigm similar to
what Lanoix \emph{et al.} for the B-method\,\cite{lanoix:hal-00105041}.

\section{Conclusion}
\label{sec:sota:conclusion}

In this Chapter, we have discussed our two contributions with respect to related
work.
%
Our theory of \ac{hse} mechanisms, presented in Part~\ref{part:speccert}, aims
to specify requirements that trusted software components have to satisfy in
order for the underlying hardware architecture to enforce a targeted security
policy at all time.
%
Our initial goal is to leverage formal \ac{hse} definition to support
verification of hardware architectures, a research direction which was little
investigated in the past, with the notable exception of the work of Jomaa
\emph{et al.} about \ac{mmu}-based memory isolation\,\cite{jomaa2016mmu}.
%
Our approach presupposes the existence of a general-purpose model of the
hardware architecture.
%
To manage the scale of such a model, we propose in Part~\ref{part:freespec} a
compositional reasoning framework for Coq, in the continuity of similar research
efforts, notably Garg \emph{et al.}\,\cite{garg2010compositional} and Heyman
\emph{et al.}\,\cite{heyman2012securemodel}.