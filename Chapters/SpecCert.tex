\chapter{A Formal Definition of HSE Mechanisms}
\label{chapter:speccert}

\endquote{``\emph{The purpose of abstraction is not to be vague, but to create a
    new semantic level in which one can be absolutely precise}''

  \hfill\footnotesize --- Edsger Dijkstra}

\vspace{1cm}\noindent
%
Our first contribution is a formal definition of \ac{hse} mechanisms, which
takes into account that
%
\begin{inparaenum}[(1)]
\item interfaces exposed by commodity hardware architectures to software
  components are not safe,
\item trusted and untrusted software components use the same interface and
  manipulates the same stateful environment, and
\item several \ac{hse} mechanisms are often implemented simultaneously, to
  enforce several security policies.
\end{inparaenum}

These characteristics convinced us to break down our approach into three
components: hardware models, security policies and \ac{hse} mechanisms.
%
First, we model the hardware architecture as a \ac{lts} whose sequences of
transitions, also called traces, characterize every possible software components
executions (Section~\ref{subsec:speccert:hardware}).
%
This model acts as a foundation for the two other components: both security
policies and \ac{hse} mechanisms are express against it
(Section~\ref{sec:speccert:hse}).
%
This opens the road toward using one hardware model to define and verify as many
\ac{hse} mechanisms as necessary.
%
As we conclude this Chapter, we illustrate how our formalism can be leveraged in
order to reason about the isolation of components of a software stack, notably
in terms of sharing of responsibility between software components.

For the reader familiar with Coq, we present an implementation of our formalism
in Appendix~\ref{appendix:speccert}.
%
This development comprises machine-checked proofs of the theoretical results
that we present throughout this Chapter, and we have used these proofs to phrase
the proof sketches which follow.

\section{Hardware Model}
\label{subsec:speccert:hardware}

In line with the works we have described in Section~\ref{sec:related:review}, we
model a hardware architecture which executes several software components as a
\ac{lts} with controllable and observable transitions.
%
We then introduce the notion of traces of a hardware model, and model security
policies as predicate on sets of traces
(\ref{subsec:speccert:def}).
%
This allows us to model the different classes of security policies discussed
previously (\ref{subsec:state:secu}).

\subsection{Definition}
\label{subsec:speccert:def}

The state of a hardware architecture models the configuration of its devices at
a given time.
%
This configuration may change over time with respect to the hardware
specifications and comprises any relevant data such as registers values, inner
memory contents, etc.
%
These state transformations occur during the system's transitions.
%
We distinguish between two classes of transitions: the software transitions
which are direct and foreseeable side-effects of the execution of a \ac{cpu}
instruction and the hardware transitions which are not.
%
Differentiating between transitions which are controllable and transitions which
are only observable is not a novel approach.
%
David Basin \emph{et al.} have notably emphasize the importance of transitions
which are only observable in terms of security\,\cite{basin2013enforceable}.

\begin{definition}[Hardware Model]
  \label{def:speccert:model}
  A hardware model $\Sigma$ is a tuple
  $\langle H, L_S, L_H, \rightarrow \rangle$, where
  %
  \begin{itemize}
  \item $H$ is the set of configurations of the hardware architecture
  %
  \item $L_S$ is the set of labels to identify software transitions
  %
  \item $L_H$ is the set of labels to identify hardware transitions
  %
  \item $\rightarrow$ is a the transition relation of the system
  \end{itemize}

  The transition relation $\rightarrow$ is a predicate on
  $H \times (L_S~\uplus~L_H) \times H$.
  %
  Afterwards, we simply write $L$ for $L_S \uplus L_H$.
  %
  A transition labelled with $l$ from $h$ to $h'$ is denoted by
  %
  \[
    \transition{h}{l}{h'}
  \]
  %
  and we write $\mathcal{T}(\Sigma)$ for the set of triples which satisfy the
  transition relation, that is
  \[
    \mathcal{T}(\Sigma) \triangleq \{\ (h, l, h')\ |\ \transition{h}{l}{h'}\ \}
  \]
\end{definition}

The execution of an instruction can be broken down into sequences of these
transitions.
%
For instance, to execute the x86 instruction\,\footnote{Written in AT\&T syntax
  here.} \texttt{mov (\%ecx),\%eax}, a x86 \ac{cpu}:
%
\begin{itemize}
\item reads the content of the register \texttt{ecx}
%
\item interprets this value as an address and reads the main memory at this
  address
%
\item writes this content into the register \text{eax}
%
\item updates the register \texttt{eip} with the address of the next instruction
  to execute
\end{itemize}

This translates into four software transitions, if the content of \texttt{ecx}
is a valid address.
%
On the contrary, the \ac{cpu} typically raises an interrupt.
%
In this scenario, only one software transition occurs, when the \ac{cpu} reads
the content of \texttt{ecx}.
%
The following transition models the interrupt, and is labelled as ``hardware''.

Hardware transitions are not limited to interrupts raised by a \ac{cpu}.
%
They make be provoked by other hardware components as well.
%
For instance, \ac{dma} transactions by a network card qualify as hardware
transitions.
%
This allows for taking into account active peripherals whose trustworthiness is
not guaranteed.
%
Finally, and as suggested by David Bosin \emph{et al.}, hardware transitions can
be leveraged to model a clock, and therefore reasoning about time.

\subsection{Security Policies}
\label{subsec:speccert:security}

We now explain how we model the different security policies discussed in
Section~\ref{subsec:state:secu}.
%
These security policies are defined against traces of the model.

\begin{definition}[Traces]
  \label{def:speccert:trace}
  A trace is a sequence of transitions of~$\Sigma$, such that for two
  consecutive transitions, the resulting state of the first is the initial state
  of the next.

  We write $\pathesLTS{Ez}$ for the set of traces of a hardware model $\Sigma$,
  and we consider the following functions:
  %
  \begin{itemize}
  \item $\func{init} : \pathesLTS{Ez} \rightarrow S$ maps a trace with its
    initial state
  \item
    $\func{trans} : \pathesLTS{Ez} \rightarrow \powerset(\mathcal{T}(\Sigma))$
    maps a trace with the set of transitions
  \end{itemize}
\end{definition}

We start from the most general definition possible, then discuss how more
specific security properties can be modelled as a specialization of that general
definition.

\begin{definition}[Security Policy]
  \label{def:speccert:secpol}
  %
  A security policy is a predicate on sets of traces
  $\powerset(\pathesLTS{Ez})$.
\end{definition}

Hyperproperties\,\cite{clarkson2010hyperproperties} such as noninterference
require a definition that general.
%
Liveness properties (something ``good'' happens) and safety properties (nothing
``bad'' happens) are said to be security
properties\,\cite{schneider2000enforceable}.

\begin{definition}[Security Property]
  A security property is a predicate on traces $\pathesLTS{Ez}$.
  %
  We write $\partial P$ for the security policy derived from the security
  property $P$, such that
  %
  \[
    \partial P(R) \triangleq \forall \rho \in R, P(\rho)
  \]
\end{definition}

Safety properties focus on avoiding ``bad'' transitions, and therefore their
definition can be even more simple, \emph{if the hardware model allows for
  distinguish between safe and unsafe transitions solely based on the current
  state, and not the traces past}.

\begin{definition}[Safety Property]
  \label{def:speccert:safetyprop}
  %
  A safety property is a predicate on transitions $\mathcal{T}(\Sigma)$.
  %
  We write $\partial^2 P$ for the security policy derived from the safety
  property $P$.
  %
  A set of trace $R$ satisfies $\partial^2 P$ if and only if every transitions
  of every traces $\rho \in R$ satisfy $P$, that is
  %
  \[
    \partial^2 P(R) \triangleq \forall \rho \in R, \forall (h, ev, h') \in
    \func{trans}(\rho), P(h, ev, h')
  \]
\end{definition}

\section{HSE Mechanisms}
\label{sec:speccert:hse}

The previous definitions allows us to propose a formal definition for \ac{hse}
mechanisms, notably based on requirements on states and requirements on
transitions (\ref{subsec:speccert:hsedef}).
%
Then, we detail two so-called \ac{hse} Laws, whose main purpose is to enforce
requirements consistency: requirements on transitions should preserve
requirements on states (\ref{subsec:speccert:laws}).
%
From a \ac{hse} mechanism definition, we derive a set of compliant traces
(\ref{subsec:speccert:compliant}) which we use to determine if the \ac{hse}
mechanism is correct with respect to a targeted security policy
(\ref{subsec:speccert:correct}).

\subsection{Definition}
\label{subsec:speccert:hsedef}

One of the specificities of \ac{hse} mechanisms is the sharing of the \ac{cpu}
interface between the trusted components and the rest of the software stack,
considered as the adversary.
%
To reason about HSE mechanisms, it is necessary to be able to determine which
software component is executed at a given time.
%
In practice, a subset of states of the hardware architecture is dedicated to
each software component.
%
For instance, the x86 \ac{cpu} has a feature called protection rings where each
ring can be seen as an execution mode dedicated to a software component.
%
Hence, the ring 0 is dedicated to the operating system whereas the userland
applications are executed when the \ac{cpu} is in ring 3, with a particular page
table setup.

\begin{definition}[Hardware-Software Mapping]
  \label{def:hardsoftmap}
  A hardware-software mapping $\func{con\-text} : H \rightarrow S$ is a function
  which takes a hardware state and returns the software component currently
  executed.
\end{definition}

Dealing with multi-core architectures would require additional efforts and
notations.
%
One possible solution could be to define an identifier per core and to use this
identifier in addition to the current hardware state to deduce the software
component currently executed by the corresponding core.
%
However, this is out of the scope of this Chapter.

A \ac{hse} mechanism is a set of requirements on states to characterize safe
hardware configurations and a set of requirements on software transitions to
preserve the state requirements through software execution.
%
The software components which implement a \ac{hse} mechanism form its the
\ac{tcb}.

\begin{definition}[HSE Mechanism]
  \label{def:speccert:hse}
  A \ac{hse} mechanism $\Delta$ is a tuple
  $\langle S, T, \func{context}, \func{inv}, \func{behaviour} \rangle$, such
  that
  %
  \begin{itemize}
  \item $S$ is the set of software components executed by the hardware
    architecture
  %
  \item $T \subseteq S$ is the set of trusted software components which
    implement the \ac{hse} mechanism and form its \ac{tcb}
  %
  \item $\func{context}$ is a hardware-software mapping to determine when the
    \ac{tcb} is executed
  %
  \item $\func{inv}$ is a predicate on $H$ to distinguish between safe hardware
    configurations and potentially vulnerable ones
  %
  \item $\func{behaviour}$ is a predicate on $H \times L_S$ to distinguish
    between safe software transitions and potentially harmful ones
  \end{itemize}
\end{definition}

We illustrate this definition with the Flash Memory Lock-down mechanism
described in Section~\ref{subsec:usecase:hse:smm}.
%
As a reminder, the Flash Memory Lock-down mechanism enforces the integrity of
the \ac{bios} code within the Flash Memory, as follows:
%
\begin{enumerate}
\item By default, the Flash Memory is locked and its content cannot be modified
%
\item When a software component (\emph{e.g.} system software) tries to unlock
  the Flash Memory, the \ac{pch} triggers a \ac{smi}
%
\item This forces the \ac{cpu} to enter \ac{smm}
%
\item The \ac{smm} code is expected to lock the Flash Memory again, before
  resuming the execution of the system software
\end{enumerate}

\begin{example}[Flash Memory Lock-down Mechanism]
  \label{example:speccert:flashdef}
  In this example, the trusted software component ($T$) is the \ac{bios}.
  %
  The \ac{cpu} executes the \ac{bios} when it is in \ac{smm} (\func{context}).
  %
  A safe hardware state ($\func{inv}$) is either a state wherein the \ac{bios}
  is executed, or a state wherein the Flash Memory is locked.
  %
  It is expected that the \ac{bios} locks the Flash Memory before using the
  \texttt{rsm} instruction ($\func{behaviour}$).
\end{example}

\subsection{HSE Laws}
\label{subsec:speccert:laws}

For a \ac{hse} mechanism to be correctly defined, it must obey a few axioms,
together called the \ac{hse} Laws.
%
The first law says that the state requirements specified by $\func{inv}$ are
preserved through transitions as long as the \ac{tcb} avoids software
transformations which do not satisfy $\func{behaviour}$.
%
The second law says that the $\func{behaviour}$ predicate specifies restrictions
of software transitions for the \ac{tcb} only.
%
The software components which are not part of the \ac{tcb} are considered
untrusted and we make no assumption on their behaviour.

\begin{definition}[\ac{hse} Laws]
  \label{def:laws}
  A \ac{hse} mechanism $\Delta$ has to satisfy the following properties:
  %
  \begin{enumerate}
  \item \func{behaviour} preserves \func{inv}:
    $\forall (h, l, h') \in \mathcal{T}(\Sigma)$,
    \[
      \begin{array}{l} \func{inv}(h) \Rightarrow (l \in L_S \Rightarrow
        \func{behaviour}(h,l)) \Rightarrow \func{inv}(h')
      \end{array}
    \]
  %
  \item $\func{behaviour}$ only restricts the \ac{tcb}:
    $\forall (h, l, h') \in \mathcal{T}(\Sigma)$, $\forall x \not\in T$,
    %
    \[
      l \in L_S \Rightarrow \func{context}(h) = x \Rightarrow
      \func{behaviour}(h, l)
    \]
  \end{enumerate}
\end{definition}

\begin{example}[Flash Memory Lock-down Inconsistency]
  We can convince ourselves that the informal definition description we have
  discussed in the Example~\ref{example:speccert:flashdef} obeys the second HSE
  Law, but \emph{does not} obey the first one.
  %
  \paragraph{\func{behaviour} only restricts the \ac{tcb}}
  %
  The only software restriction we formulate concerns the use of the
  \texttt{rsm} instruction.
  %
  In particular, we do not forbid the attacker to unlock the Flash Memory.

  \paragraph{\func{behaviour} does not preserve \func{inv}}
  %
  A \ac{cpu} is either in \ac{smm} or not in \ac{smm}.
  %
  If it is in \ac{smm}, the only way to leave \ac{smm} is to execute the
  \texttt{rsm} instruction, which qualifies as a software transition.
  %
  If the \ac{cpu} is in \ac{smm}, the \func{behaviour} will hold true for this
  software transition only if the Flash Memory is already locked.
  %
  As a consequence, it is not possible to leave \ac{smm} with the Flash Memory
  unlocked.
  %
  However, if the \ac{cpu} is not in \ac{smm}, and tries to open the Flash
  Memory, two things happen sequentially.
  %
  First, the Flash Memory is effectively opened (software transition)
  %
  Then, the \ac{pch} triggers a \ac{smi}, which eventually forces the \ac{cpu}
  to enter \ac{smm} (hardware event).
  %
  That is, the protection consists in two transitions, and the \func{inv}
  predicate is not satisfied in between.

  \paragraph{}
  %
  It is because the Flash Memory Lock-down as described here does not satisfy
  the first law that the race condition uncovered by Corey Kallenberg \emph{et
    al.}\,\cite{kallenberg2015racecondition} is possible.
  %
  On the contrary, the \texttt{SMM\_BWP} register semantics allows for defining
  a HSE mechanisms which satisfies both laws, because the register ties together
  the state of the \acp{cpu} and the Flash Memory state.
\end{example}

\subsection{Trace Compliance}
\label{subsec:speccert:compliant}

We say a trace complies to a \ac{hse} mechanism definition when its initial
state satisfies the state requirements (\func{inv}) and each software
transitions of the trace satisfies the software requirements (\func{behaviour}).
%
\begin{definition}[Compliant Traces]
  We write $\mathcal{C}(\Delta)$ for the set of the traces which comply with
  $\Delta$.
  %
  Given $\rho \in \pathesLTS{Ez}$, then $\rho \in \mathcal{C}(\Delta)$ iff
  \[
    \func{inv}(\func{init}(\rho)) \wedge \forall (h,l,h') \in
    \func{trans}(\rho)\text{, }l \in L_S \Rightarrow \func{behaviour}(h, l)
  \]
  % \[
  %   \begin{array}{lcl}
  %     \rho \in \mathcal{C}(\Delta)
  %     & \triangleq
  %     & \func{inv}(\func{init}(\rho))\ \wedge \\
  %     &
  %     & \forall (h,l,h') \in \func{trans}(\rho), l \in L_S \Rightarrow
  %      %     \func{behaviour}(h, l)
  %   \end{array}
  % \]
\end{definition}

\begin{example}[Memory Flash Lock-down Compliance]
  We consider the execution to start at the end of the boot sequence, when the
  \ac{bios} gives the control flow to the system software component it has
  selected.
  %
  At the time, it is expected that the \texttt{BIOS\_CNTL} register of the
  \ac{pch} has been correctly set; in particular, the \texttt{SMM\_BWP} bit
  should be set, to avoid the Speed Racer
  attack\,\cite{kallenberg2015racecondition}.
  %
  If the \ac{bios} fails to do so, then the related trace is not compliant.
\end{example}

\begin{lemma}[HSE Invariant Enforcement]
  \label{lemma:speccert:hseinv}
  We prove that \func{inv} is satisfied throughout compliant traces, that is
  %
  \[
    \forall \rho \in \mathcal{C}(\Delta), \forall (h, l, h') \in
    \func{trans}(\rho), \func{inv}(h) \wedge \func{inv}(h')
  \]

  \begin{proof}
    By definition of $\mathcal{C}(\Delta)$, we know the initial state of the
    trace satisfies \func{inv}, and thanks to the first HSE Law, we can conclude
    the state after the first transition also satisfies \func{inv}.
    %
    We generalize to the trace by induction.
  \end{proof}
\end{lemma}

\subsection{HSE Mechanism Correctness}
\label{subsec:speccert:correct}

The main purpose of the \ac{hse} Laws is to verify it is consistent.
%
However, they say nothing about the security policy the \ac{hse} mechanism
supposedly enforce.
%
Eventually, we aim to prove that a HSE mechanism is sound ---it succeeds in
enforcing a security policy--- under the assumption that software components of
the \ac{tcb} always behave according to the specification given in the HSE
mechanism definition.

\begin{definition}[Correct HSE Mechanism]
  A \ac{hse} mechanism $\Delta$ is correct with respect to a security policy $P$
  (denoted by $\Delta \models P$) if and only if the set of compliant traces of
  $\Delta$ satisfies $P$, that is
  %
  \[
    \Delta \models P \triangleq P(\mathcal{C}(\Delta))
  \]
\end{definition}

It is possible to define a \ac{hse} mechanism which satisfies the \ac{hse} Laws,
yet is not correct with respect to its targeted security policy.
%
It was the case, for instance, for the protection of the SMRAM by the sole
\texttt{SMRAMC} register.
%
The state requirement at the time would have been focused on the SMRAM content,
which is correctly guarded against unprivileged modifications by the memory
controller.
%
However, this property alone is not strong enough to enforce the BIOS Integrity
security property (Definition~\ref{def:usecase:biosint}), as evidenced by the
SMRAM Cache Poisoning attack.

\begin{theorem}[Correct HSE Mechanism for Safety Properties]
  \label{theorem:speccert:correcthse}
  Given $P$ a safety property defined as a predicate on $\mathcal{T}(\Sigma)$,
  then
  %
  \[
    \begin{array}{l}
      \forall (h, l, h') \in \mathcal{T}(\Sigma), \\
      \qquad \func{inv}(h) \\
      \qquad \Rightarrow (l \in L_{S} \Rightarrow \func{behaviour}(h, l))\\
      \qquad \Rightarrow P(h, l, h')
    \end{array}
  \]
  %
  is a sufficient condition for
  %
  \[
    \Delta \models \partial^2 P
  \]

  \begin{proof}
    With Lemma~\ref{lemma:speccert:hseinv}, we know that every initial state of
    a transition of $\rho$ satisfies $\func{inv}$.
    %
    By definition of Compliant Runs, we know that any transitions meaning they
    all satisfies the safety property $P$.
    %
    We conclude with the Definition of $\partial^2 P$.
  \end{proof}
\end{theorem}

\section{Use Case: Execution Isolation Policy}
\label{sec:speccert:usecase}

We now focus on a class of security policies we call \emph{execution isolation
  policies}.
%
Such a policy prevents a software component to tamper with the execution of
their \acp{tcb}.
%
We consider that a software component tampers with the execution of another when
it is able to make the latter execute an instruction of its choice.
%
This is particular sub-case of the Integrity property
(Definition~\ref{def:usecase:int}), as we focus on instructions fetches
exclusively.
%
We use it as an illustration to demonstrate how our \ac{hse} mechanism
definition can be used to reason about enforcement of security policies which
involves several software components.

We give a generic definition of software execution tampering
(\ref{subsec:speccert:tampering}).
%
We leverage it as a foundation for defining global execution policies which
apply to complete software stacks (\ref{subsec:speccert:globalsec}).
%
Because such policies are enforced \emph{via} several \ac{hse} mechanisms, we
then introduce partial execution policies (\ref{subsec:speccert:partialsec}),
and \ac{hse} mechanisms cooperation (\ref{subsec:speccert:coop}).

\subsection{Execution Tampering}
\label{subsec:speccert:tampering}
%
A memory location within a hardware architecture is a container which is able to
store data used by a software component \emph{e.g.}~a general-purpose register
of a \ac{cpu}, a \ac{dram} memory cell, etc.
%
A hardware model tracks the memory location ownership when the hardware
architecture states maps each memory location with a software component called
its \emph{owner}, and transition relation updates this mapping throughout
traces.
%
A software component becomes the new owner of a memory location when it
overwrites its content during a transition.
%
By extension, we say a software component owns some data when it owns the memory
location in which these data are stored.

With this mapping, it becomes possible to determine the owner of an instruction
fetched by the \ac{cpu} in order to be decoded and executed.

\begin{definition}[Transition-Software Mapping]
  \label{def:minx86:transsoft}
  A transition-software mapping
  $\func{fetched}_{\Sigma}: H \times L \rightarrow \powerset(S)$ is a function
  which takes an initial hardware state, a transition label and returns the set
  of owners of the fetched instructions during this transition.
\end{definition}

Hence, $s \in \func{fetched}_{\Sigma}(h, l)$ means that an instruction owned by
$s$ was fetched in order to be executed by the \ac{cpu} during a transition
labelled with $l$ from a state $h$.

\paragraph{}
%
With a hardware-software mapping and an event-software mapping, we give a formal
definition of a \textit{software execution tampering}.

\begin{definition}[Software Execution Tampering]
  \label{def:codeinjection}
  A software component $x \in S$ tampers with the execution of another software
  component $y \in S$ during a transition labelled with $l \in L$ from a state
  $h \in H$ to a state $h' \in H$, denoted by
  $h \xrightarrow[x \leadsto y]{l} h'$, when the \ac{cpu} fetches an instruction
  owned by $x$ while executing $y$, that is
  %
  \[
    h \xrightarrow[x \leadsto y]{l} h' \triangleq x \in
    \func{fetched}_{\Sigma}(h, l) \wedge \func{context}(h) = y
  \]

  We write $h \xrightarrow[x \not\leadsto y]{l} h'$ when $x$ does not tamper
  with the execution of~$y$.
\end{definition}

We now give two examples of recent attacks which qualify as software execution
tampering.

\begin{example}[Thinkpwn]
  The \ac{bios} of certain Lenovo laptops were subject to an trivial attack
  called Thinkpwn.
  %
  Under certain circumstances, the \ac{smm} code was using the content of a
  structure provided by an untrusted source (\emph{e.g.} system software) as a
  function pointer, without any safety checks.
\end{example}

\begin{example}[Rowhammer]
  Rowhammer designates a class of security vulnerabilities which leverage a flaw
  in several \ac{dram}, such that repeated write accesses to a given memory line
  provoke bit flips in neighbouring lines.
  %
  Rowhammer has been shown to be an efficient attack vector, as it can be used
  by an attacker to modify memory cells it should not be able to access.
\end{example}

\subsection{Global Execution Isolation Policies}
\label{subsec:speccert:globalsec}

We leverage the software execution tampering property to propose a generic
formalization of \emph{software execution isolation policies}, to determine if a
given software component is authorized to tamper with the execution of another
software component in the context of a software stack.

\begin{definition}[Global Execution Isolation Policy]
  \label{def:softwareisolation}
  A Global Execution Isolation Policy $I$ is a safety property characterized by
  a tuple $\langle S, \ge, \func{context} \rangle$, such that
  %
  \begin{itemize}
  \item $S$ is a set of software components executed by the hardware
    architecture
  \item $\ge$ is a non-strict partial order over $S$, such that given
    $(x, y) \in S \times S$, $x \ge y$ means $x$ is part of the \ac{tcb} of $y$
  \item \func{context} is a hardware-software mapping.
  \end{itemize}

  A transition labelled with $l \in L$ from $h \in H$ to $h' \in H$ satisfies I
  when only a software components which are part of the \ac{tcb} of $x$ can
  tamper with the execution of $x$, that is
  %
  \[
    \begin{array}{l}
      I(h, l, h') \triangleq
      \forall (x, y) \in S \times S \text{, } h \xrightarrow[y
      \leadsto x]{l} h' \Rightarrow y \ge x
    \end{array}
  \]
\end{definition}

\begin{corollary}
  A software component which is not part of the \ac{tcb} of a software component
  $x$ cannot tamper with the execution of y, that is
  %
  \[
    I(h, l, h') \iff \forall (x, y) \in S \times S \text{, } y \not\ge x
    \Rightarrow h \xrightarrow[y \not\leadsto x]{l} h'
  \]

  \begin{proof}
    This is the contrapositive of Definition~\ref{def:softwareisolation}.
  \end{proof}
\end{corollary}

\begin{example}[Software Stack Isolation]
  \label{example:speccert:ssisolation}
  Using our definition, we can define a isolation policy for a whole software
  stack which comprises the \ac{bios}, a system software components and several
  applications ($S$).
  %
  When the \ac{cpu} is in \ac{smm}, the \ac{bios} is executed, when the \ac{cpu}
  is not in \ac{smm} and is in ring 0, the system software component is
  executed, and when the \ac{cpu} is not in \ac{smm} and is in ring 3, one of
  the applications ---identified by the page tables used by the \ac{cpu}--- is
  executed (\func{context}).
  %
  We give a graphic representation of the considered partial order in
  Figure~\ref{fig:speccert:partialorder}.
  %
  This reads as follows: a software component is part of its own \ac{tcb}, and
  of the \ac{tcb} of any software component higher in the graph.

  According of the definition of the Software Execution Isolation Policy, the
  \ac{bios} can tamper with the execution of the system software component and
  any applications, but applications can only tamper with their own executions.
\end{example}

\begin{figure}
  \begin{center}
    \begin{tikzpicture}
      \node (A1) {$\mathtt{app}_1$};
        %
      \node [right=of A1] (A2) {$\mathtt{app}_2$};
        %
      \node [right=of A2] (Aetc) {$\ldots$};
        %
      \node [right=of Aetc] (An1) {$\mathtt{app}_{n-1}$};
        %
      \node [right=of An1] (An) {$\mathtt{app}_{n}$};

      \node [below=of Aetc] (OS) {$\mathtt{os}$};

      \draw (A1.south) -- (OS.north);
        %
      \draw (A2.south) -- (OS.north);
        %
      \draw (An1.south) -- (OS.north);
        %
      \draw (An.south) -- (OS.north);

      \node [below=of OS] (bios) {$\mathtt{bios}$};

      \draw (OS.south) -- (bios.north);
    \end{tikzpicture}
  \end{center}
  \caption{Representation of the partial order of
    Example~\ref{example:speccert:ssisolation}.}
  \label{fig:speccert:partialorder}
\end{figure}

\subsection{Partial Execution Isolation Policies}
\label{subsec:speccert:partialsec}

A security policy such as the one detailed in
Example~\ref{example:speccert:ssisolation} is not enforced by one but many HSE
mechanisms.
%
We can break it down to more specific security policies, by designating sets of
software components whose executions has to be constrained with respect to the
global security policy $I$.

\begin{definition}[Partial Execution Isolation Policies]
  Given $I$ a global execution isolation policy and $U \subseteq S$ a set of
  software components, we write $I|_{U}$ for the partial execution isolation
  policy whose purpose is to enforce that all components of $U$ are constrained
  with respect to $I$, that is
  %
  \[
    I|_{U}(h, l, h') \triangleq \forall u \in U, \forall x \in S, h
    \xrightarrow[u \leadsto t]{l} h' \Rightarrow u \ge x
  \]
  %
  This safety property is typically enforced by a \ac{hse} mechanism implemented
  by the \acp{tcb} of the software components of $U$, that is
  %
  \[
    T = \{ t \in S\ |\ t \not\in U \wedge \forall u \in U, t \ge u \}
  \]
\end{definition}

\begin{example}[Sharing of Responsibility]
  For
  $U_{\mathtt{apps}} = \{ \mathtt{app}_1, \mathtt{app}_2, \ldots,
  \mathtt{app}_{n-1} \mathtt{app}_{n} \}$ the set of applications whose
  executions have to be constrained, the related \ac{tcb} is the set
  $T_{\mathtt{apps}}~=~\{ \mathtt{bios}, \mathtt{os} \}$.
  %
  $I_{U_{\mathtt{apps}}}$ states than one application can only tamper with its
  own execution.
  %
  The responsibility to constrain the execution of applications cannot fall
  entirely on system software.
  %
  For instance, the \ac{bios} executed while the \ac{cpu} is in \ac{smm} has to
  be careful not to tamper with the page tables previously configured by the
  system software component.

  On a similar basis, for $U_{\mathtt{os}} = \{ \mathtt{os} \}$, the related
  \ac{tcb} is the set $T_{\mathtt{bios}}~=~\{ \mathtt{bios} \}$.
  %
  Only the \ac{bios} is responsible for constraining the system software
  execution.
  %
  $I_{\mathtt{os}}$ states that a system software component can tamper with the
  applications it manages, with its own execution, but not the \ac{bios}'s.
\end{example}

\subsection{HSE Mechanisms Concurrent Implementation}
\label{subsec:speccert:coop}

In practice, a global execution isolation policy is enforced thanks to several
\ac{hse} mechanisms in charge of enforcing one partial execution isolation
policy.
%
We model the requirement to implement both \ac{hse} mechanisms concurrently as a
third \ac{hse} mechanism, constructed by a dedicated operator $\sqcap$.

\begin{definition}[HSE Mechanisms Concurrent Implementation]
  Given two HSE mechanism $\Delta_1$ and $\Delta_2$, such that
%
  \[
    \begin{array}{rcl}
      \Delta_1
      & =
      & \langle S, T_1, \func{context}, \func{inv}_1, \func{behaviour}_1
        \rangle \\
      \Delta_2
      & =
      & \langle S, T_2, \func{context}, \func{inv}_2, \func{behaviour}_2
        \rangle
    \end{array}
  \]
%
  We write $\Delta_1 \sqcap \Delta_2$ for the \ac{hse} mechanism which combines
  the requirements of both $\Delta_1$ and $\Delta_2$, that is
%
  \[
    \Delta_1 \sqcap \Delta_2 \triangleq \langle S, T_1 \cup T_2, \func{context},
    \func{inv}_{1\wedge2}, \func{behaviour}_{1\wedge2} \rangle
  \]
%
  where
  \[
    \begin{array}{rcl}
      \func{inv}_{1\wedge2}(h)
      & \triangleq
      & \func{inv}_1(h) \wedge \func{inv}_2(h) \\
      \func{behaviour}_{1\wedge2}(h,l)
      & \triangleq
      & \func{behaviour}_1(h,l) \wedge \func{behaviour}_2(h,l)
    \end{array}
  \]
\end{definition}

\begin{lemma}[Compliant Traces of Intersection]
  \label{lemma:speccert:compinter}
  The set of compliant traces of the intersection of $\Delta_1$ and $\Delta_2$
  is the intersection of the sets of compliant traces of $\Delta_1$ and
  $\Delta_2$, that is
  \[
    \mathcal{C}(\Delta_1 \sqcap \Delta_2) = \mathcal{C}(\Delta_1) \cap
    \mathcal{C}(\Delta_2)
  \]

  \begin{proof}
    We leverage the definition of $\wedge$ and $\Rightarrow$ to turn a statement
    of the form
    %
    \[
      (P \wedge P') \wedge (R \Rightarrow Q \wedge Q')
    \]
    %
    into
    %
    \[
      (P \wedge (R \Rightarrow Q)) \wedge (P' \wedge (R \Rightarrow Q'))
    \]
    %
    and vice versa, where $P$ and $P'$ are statements about the initial states
    of traces and \func{inv}, $R$ is the premice about software transitions, and
    $Q$ and $Q'$ are statement about \func{behaviour}.
  \end{proof}
\end{lemma}

\begin{example}[Global Execution Policy Enforcement]
  We consider two HSE mechanisms: $\Delta_\mathtt{bios}$ implemented by the
  \ac{bios} to constrain the execution of the system software component, and
  $\Delta_\mathtt{os}$ primarily implemented by the system software component to
  constrain the execution of the applications, that is
  %
  \[
    \begin{array}{cl}
      \Delta_{\mathtt{bios}}
      & \models \partial^2 I|_{U_{\mathtt{os}}} \\
      \Delta_{\mathtt{os}} & \models
                             \partial^2 I|_{U_{\mathtt{apps}}}
    \end{array}
  \]

  We can prove that any execution which complies with $\Delta_\mathtt{bios}$ and
  $\Delta_\mathtt{os}$ satisfies the software execution isolation policy $I$,
  that is
  %
  \[
    \Delta_{\mathtt{bios}} \sqcap \Delta_{\mathtt{os}} \models \partial^2 I
  \]

  \begin{proof}
    By definition of correct \ac{hse} mechanism, we need to prove that the set
    of traces which comply with
    $\Delta_{\mathtt{bios}} \sqcap \Delta_{\mathtt{os}}$ has to satisfy the
    security policy derived from our isolation policy $I$.
    %
    With Lemma~\ref{lemma:speccert:compinter}, we know that the set of compliant
    traces of $\Delta_{\mathtt{bios}} \sqcap \Delta_{\mathtt{os}}$ is the
    intersection of the sets of compliant traces of $\Delta_{\mathtt{bios}}$ and
    $\Delta_{\mathtt{os}}$.
    %
    We know that the transitions of these traces satisfies respectively
    $I_{U_{\mathtt{os}}}$ and $I_{U_{\mathtt{bios}}}$.
    %
    This is enough to conclude, based on the definitions of global and partial
    execution isolation policies.
  \end{proof}
\end{example}

\section{Conclusion}

In this Chapter, we present our formal definition of \ac{hse} mechanisms, and we
have shown how we can leverage this definition to reason about so-called
execution isolation policies.
%
These policies prevent software components to tamper with the execution of their
\ac{tcb}, where ``tampering with the execution'' means being able to provoke the
execution of an instruction of their choice.
%
These security policies are representative of what real-world \ac{hse}
mechanisms are meant to enforce.

\chapter{Specifying and Verifying an Idealized BIOS HSE Mechanism}

\section{{\sc MinX86}}
\label{sec:speccert:hardware}

$\formatLTS{Minx86}$ is intended to be a minimal model for single core x86-based
machines and we have used publicly available Intel
documents\,\cite{intel2013celeron,intel2009mch,intel2014manual} to define it.

\subsection{Model Scope}

The hardware architecture we are modeling with $\formatLTS{Minx86}$ contains a
\ac{cpu}, a cache, a memory controller, a \ac{dram} controller and a VGA
controller\,\footnote{A VGA controller is a hardware device which on we can
  connect a screen. It exposes some memory to the \ac{cpu} for communication
  purposes.} which both expose some memory to the \ac{cpu}.

$\formatLTS{Minx86}$ is meant to illustrate how our formalism can be leveraged
to formally specify and verify a HSE mechanism, and thus is not exhaustive.
%
In its current state of implementation, its scope focuses on the \ac{smm}.

\paragraph{Hardware Specifications}
%
We consider the \ac{cpu} can be either in System Management Mode (\ac{smm}) or
in an unprivileged mode.
%
We give a brief summary of how the \ac{smm} works.
%
We remind our readers that Section~\ref{subsec:usecase:hse:smm}
%
The \ac{smm} is ``a special-purpose operating mode provided for handling
system-wide functions like power management, system hardware control, or
proprietary OEM-designed code''\,\cite{intel2014manual}.
%
It is the most privileged execution mode of x86 processors.
%
When a \ac{cpu} receives a special hardware interrupt called System Management
Interrupt (SMI), it halts its current execution and reconfigures itself to a
specified state from which it executes the code stored in memory at the address
$\mathtt{SMBASE} + \texttt{0x8000}$.
%
In practice, the SMBASE value points to the base of a memory region called the
SMRAM.
%
Leaving the \ac{smm} is done by executing a special purpose instruction called
\texttt{rsm} (for \emph{resume}).

The \ac{cpu} relies on a cache to reduce the Input/Output (\IO, that is a read
or write access to the memory) latency.
%
We model one level of cache which stores both data and instructions and we
consider two cache strategies: uncacheable (UC) and writeback (WB).
%
With the UC cache strategy, the cache is not used and all \IOs are forwarded to
the memory controller, whereas with the WB strategy, the cache is used as much
as possible\,\footnote{These cache strategies are explained in
  \cite{intel2014manual}, Volume 3A, Chapter 11, Section 11.3 (page 2316 --
  2317)}.
%
To determine which cache strategy to use, the \ac{cpu} relies on several
configuration registers and mechanisms.
%
One of them is a pair of registers called the \ac{smrr} which can only be
configured when the \ac{cpu} is in \ac{smm}.
%
They are used to tell the \ac{cpu} where the SMRAM is and which cache strategy
to use for \IO targeting the SMRAM when the \ac{cpu} is in \ac{smm}.  When it is
not in \ac{smm}, the \ac{cpu} always uses the UC strategy for \IO targeting the
SMRAM.
%
\ac{smrr} have been introduced as a countermeasure of the SMRAM cache poisoning
attack\,\cite{wojtczuk2009smram,duflot2009smram} which allowed an untrusted code
to tamper with the copy of the SMRAM stored in the cache.
%
The memory controller\,\cite{intel2009mch} receives all the \ac{cpu} \IOs which
are not handled by the cache and dispatches them to the DRAM controller or to
the VGA controller. It exposes a unified view (the memory map) of the system
memory to the \ac{cpu}.
%
The \ac{cpu} manipulates this memory map with a set of addresses called the
physical addresses.
%
The memory controller dedicates a special range of physical addresses to form
the SMRAM.
%
The SMRAM is dedicated to store the code intended to be executed when the
\ac{cpu} is in \ac{smm}.

\paragraph{Tracking the Memory Ownership}
%
The \formatLTS{Minx86} definition is parameterized by a hardware-software
mapping (Definition~\ref{def:hardsoftmap}).
%
The memory locations of \formatLTS{Minx86} Computing Platforms are either cache
lines or memory cells exposed by the \ac{dram} controller or the VGA controller.
%
The memory ownership is updated through transitions according to three rules:
%
\begin{enumerate}
\item When a cache line gets a copy of a DRAM or VGA cell content, the owner of
  this cell becomes the new owner of this cache line.
%
\item When the content of this cache line is written back to a memory cell, the
  new owner of this memory cell is the owner of this cache line.
%
\item When the content of a memory location is overwritten during a transition,
  the software currently executed becomes the new owner of this memory location.
%
\end{enumerate}

Given $S$ a set of software components, the set of states of \formatLTS{Minx86}
Computing Platform hardware architecture is denoted by
$\texttt{Archi}_{\set{S}}$ and the set of \formatLTS{Minx86} Computing Platform
events is denoted by $\texttt{Event}$.
%
Given $context$ a hardware-software mapping, we denote the Computing Platform
$\formatLTS{Minx86}$ parameterized with $context$\,\footnote{The related
  definitions and explanations are given on page \pageref{page:minx86def}.} such
that
%
\[
  \formatLTS{Minx86}(context) \triangleq (minx86\_pre, minx86\_post(context))
\]

\subsection{Hardware Architecture State}

$\texttt{Archi}_{\set{S}}$ is defined as the Cartesian product of the set of
states of the \ac{cpu}, the \ac{cpu}'s cache, the memory controller and the
hardware memories exposed by both the DRAM controller and the VGA controller.
%
Each of these sets is defined in order to model the hardware features we have
previously described.
%
We define
$\texttt{PhysAddr} \triangleq \setdef{\val{pa}_i}{i \leq \val{max\_addr}}$ the
set of physical addresses the \ac{cpu} uses to perform \IO.
%
The maximal address offset (denoted by $\val{max\_addr}$ here) is specific to
the \ac{cpu} and may vary in time according to its addressing mode (real mode,
long mode, etc.), therefore we left its value as a parameter of our model.

%%%%% APPENDIX State %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
To describe the hardware architecture state of \formatLTS{Minx86} Computing
Platforms, we use record types and maps with the notations listed in Table
\ref{tab:notation}.
%
Given $\set{S}$ a set of software components, the set of states of the hardware
architecture is denoted by $\texttt{Archi}_{\set{S}}$.
%
\[
  \texttt{Archi}_{\set{S}} \triangleq
  \begin{array}{ll}
    \,\{proc &: \texttt{Proc}          \\
    ;\,mc    &: \texttt{MC}            \\
    ;\,mem   &: \texttt{Mem}_{\set{S}} \\
    ;\,cache &: \texttt{Cache}_{\set{S}}\,\}
  \end{array}
\]
%
$\texttt{Proc}$ denotes the \ac{cpu} set of states, $\texttt{MC}$ the memory
controller set of states, $\texttt{Mem}_{\set{S}}$ the physical memories set of
states and $\texttt{Cache}_{\set{S}}$ the cache set of states.

We define $\texttt{CacheStrat} \triangleq \setshortdef{\val{UC}, \val{WB}}$ the
set of the modelled cache strategies.
%
The set of states of the \ac{smrr}s is denoted $\texttt{Smrr}$.

\[ \texttt{Smrr} \triangleq
  \begin{array}{ll}
    \{\,range &: \set{P}(\texttt{PhysAddr}) \\
    ;\,smram\_strat &: \texttt{CacheStrat} \}
  \end{array}
\]

The set of physical addresses $range$ tells the \ac{cpu} the location of the
SMRAM and $\func{smram\_strat}$ tells which cache strategy has to be used when
the \ac{cpu} is in \ac{smm}.
%
As we said, the set of states of the \ac{cpu} is denoted $\texttt{Proc}$.

\[
  \texttt{Proc} \triangleq
  \begin{array}{ll}
    \{\,in\_smm &: \setshortdef{\val{true}, \val{false}} \\
    ;\,pc &: \texttt{PhysAddr} \\
    ;\,smbase &: \texttt{PhysAddr} \\
    ;\,smrr &: \texttt{Smrr} \\
    ;\,strat &: [ \texttt{PhysAddr} \rightarrow \texttt{CacheStrat}]\,\}
  \end{array}
\]

The boolean $in\_smm$ is a boolean set to $\val{true}$ when the \ac{cpu} is in
\ac{smm} and to $\val{false}$ when it leaves it.
%
The physical address $pc$ models the program counter, a register used to store
the address of the next instruction to be fetched and executed.
%
The physical address $smbase$ models the register of the same name.
%
The map $strat$ abstracts away the numerous mechanisms of the x86
microprocessors to determine which cache strategy to use for a given \IO.

The set of states of the \formatLTS{Minx86} Computing Platforms memory
controller is denoted by $\val{MC}$.

\[
  \texttt{MC} \triangleq
  \begin{array}{ll}
    \{\,d\_open &: \setshortdef{\val{true}, \val{false}} \\
    ;\,d\_lock &: \setshortdef{\val{true}, \val{false}}\,\}
  \end{array}
\]
%
The two booleans $d\_open$ and $d\_lock$ model two bits of a configuration
register named \texttt{smramc}.
%
They are used to determine how the memory controller dispatches the \IO which
targets a physical address of the SMRAM.

For a memory controller state $mc \in \texttt{MC}$ to be consistent with respect
to the hardware specifications, it has to to verify that
$d\_lock(mc) = \val{true} \Rightarrow d\_open(mc) = \val{false}$.

We then define several address spaces:
%
\begin{itemize}
\item $\texttt{PhysAddr} \triangleq \setdef{\val{pa}_i}{i \leq \val{max\_addr}}$
  the set of physical addresses the \ac{cpu} uses to perform \IO.
%
\item
  $\texttt{DRAMAddr} \triangleq \setdef{\val{dram}_i}{i \leq \val{max\_addr}}$
  the set of addresses of the memory cells exposed by the DRAM controller
%
\item $\texttt{VGAAddr} \triangleq \setdef{\val{vga}_i}{i \leq \val{max\_addr}}$
  the set of addresses of the memory cells exposed by the VGA controller
%
\item $\texttt{HardAddr} \triangleq \texttt{DRAMAddr} \uplus \texttt{VGAAddr}$
\end{itemize}

The maximal address offset (denoted by $\val{max\_addr}$ here) is specific to
the \ac{cpu} (for the physical addresses), the DRAM controller and the
VGA controller. By convenience, we give the same values to each of them in our
model.

The memory controller translates physical addresses into hardware addresses and
forwards the \IO accordingly.
%
We model this translation with the function
%
\[
  phys\_to\_hard : \texttt{MC} \times \setshortdef{\val{true},\,\val{false}}
  \times \texttt{PhysAddr} \rightarrow \texttt{HardAddr}
  %
\]
%
which maps a state of the memory controller, a boolean which tells if the
\ac{cpu} is in \ac{smm} or not and a physical address to a hardware address.
%
It is important to keep in mind that the same physical address can be translated
into two different hardware addresses for two memory controller states $m$ and
$m'$, hence it is possible to have
%
\[
  phys\_to\_hard(m, b, pa) \neq phy\_to\_hard(m', b, pa)
\]

We model the SMRAM with two ranges of addresses:
%
\begin{itemize}
\item
  $\texttt{hSmram} \triangleq \setdef{\val{dram}_i}{\val{smram\_base} \leq i \le
    \val{smram\_end}}$ the SMRAM memory range within the DRAM memory
%
\item
  $\texttt{pSmram} \triangleq \setdef{\val{pa}_i}{\val{smram\_base} \leq i \le
    \val{smram\_end}}$ the projection of the SMRAM in the memory map
\end{itemize}

The values of $\val{smram\_base}$ and $\val{smram\_end}$ are specified in the
memory controller specifications.
%
It is the software responsability to set the \ac{smrr} accordingly.
%
We assume $\val{smram\_end} - \val{smram\_base} > 0x8000$.  This way, when the
SMBASE contains the address of the beginning of the SMRAM, the \ac{smm} entry
point (that is $SMBASE + 0x8000$) is in SMRAM.

The physical memories state (exposed by the DRAM controller and the
VGA controller) is modelled with a mapping between the hardware addresses and
the software component which owns the related memory location.
%
Given $\set{S}$ the set of software components, we denote
$\texttt{Mem}_{\set{S}}$ the set of states of the physical memories.
\[
  \texttt{Mem}_{\set{S}} \triangleq [ \texttt{HardAddr} \rightarrow \set{S} ]
\]
% which can be available or already used. A cache line already used is tagged
% with the physical address of its content. For a given physical address, the
% \ac{cpu} computes an index to select a cache line and verify its tag.  hich
% contain, in addition to the copy of the cached memory content, a "dirty bit"
% and a tag. A cache line is marked as dirty when its content is modified which
% indicates if the cache line content has been modified without propagating the
% underlying hardware memories and the .

We assume $\texttt{Index}$ is the set of cache indexes and
$index : \texttt{PhysAddr} \rightarrow \texttt{Index}$ the function used by the
\ac{cpu} to determine which index to use for a given physical address.
%
The cache is divided into several cache lines which contain the cached memory
content and several additional information required by the cache strategy
algorithm.
%
The set of states of the cache line is denoted by
$\texttt{CacheLine}_{\set{S}}$.
%
In addition to modeling the hardware specifications, the definition of
$\texttt{CacheLine}_{\set{S}}$ attaches a software owner to a cache line.
%
We do not give more details about the cache line model because the cache
behavior is out of the scope of this article.

% \[
%   \texttt{CacheLine}_{\set{S}} \triangleq \begin{array}{ll} \{\,dirty &:
%     \setshortdef{\val{true},\,\val{false}} \\
%     ;\,tag
%     &:
%     \texttt{PhysAddr}
%     \\
%     ;\,owner
%     &:
%     \set{S}\,\}
%   \end{array} \]

\[
  \texttt{Cache}_{\set{S}} \triangleq [ \texttt{Index} \rightarrow
  \texttt{CacheLine}_{\set{S}} ]
\]

The hardware architecture states are implemented in the
\emph{SpecCert.x86.Archi\-tecture} module (about 1\,500 lines of code).
%
In addition to the state definitions, we have implemented several helper
functions and predicates.
%
For instance,
%
\begin{itemize}
\item
  $address\_location\_owner : \texttt{Archi}_{\set{S}} \rightarrow
  \texttt{PhysAddr} \rightarrow \set{S}$
  \begin{quote}
    \small Given a hardware architecture state and a physical address, returns
    the memory content software owner
  \end{quote}
%
\item
  $cache\_hit : \texttt{Archi}_{\set{S}} \rightarrow \texttt{PhysAddr}
  \rightarrow \ac{prop}$
  \begin{quote}
    \small Given a hardware architecture state and a physical address, holds
    true if the memory content is in the cache
  \end{quote}
%
\item
  $cache\_line\_owner : \texttt{Archi}_{\set{S}} \rightarrow \texttt{Index}
  \rightarrow \set{S}$
  \begin{quote}
    \small Given a hardware architecture state and a cache line index, returns
    the owner of this cache line
  \end{quote}
%
\item
  $resolve\_cache\_strategy : \texttt{Archi}_{\set{S}} \rightarrow
  \texttt{PhysAddr} \rightarrow \texttt{CacheStrat}$
  \begin{quote}
    \small Given a hardware architecture state and a physical address, returns
    the cache strategy used by the \ac{cpu} for this address
  \end{quote}
%
\item
  $translate\_physical\_address : \texttt{Archi}_{\set{S}} \rightarrow
  \texttt{PhysAddr} \rightarrow \texttt{HardAddr}$
  \begin{quote}
    \small Given a hardware architecture state and a physical address, returns
    the result of the memory controller address translation
  \end{quote}
\end{itemize}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We model the projection of the SMRAM in the memory map such that
$\texttt{pSmram} \triangleq \setdef{\val{pa}_i}{\val{smram\_base} \leq i \le
  \val{smram\_end}}$.
%
The values of $\val{smram\_base}$ and $\val{smram\_end}$ are specified in the
memory controller specifications.
%
It is the software responsability to set the \ac{smrr} accordingly.
%
We assume $\val{smram\_end} - \val{smram\_base} > \val{0x8000}$.
%
This way, when the SMBASE contains the address of the beginning of the SMRAM,
the \ac{smm} entry point (that is $SMBASE + \val{0x8000}$) is in SMRAM.

The hardware architecture states are implemented in the
\emph{SpecCert.x86.Archi\-tecture} module (about 1\,500 lines of code).

\subsection{Events as State-Transformers}

The set of events which trigger the state-transformations is denoted by
$\texttt{Event}$.
%
As we said in Section \ref{subsec:speccert:computing}, we distinguish hardware
events denoted by $\texttt{Event}_{Hard}$ and software events denoted by
$\texttt{Event}_{Soft}$.

\begin{table}
  \centerline{%
    \begin{tabular}{lp{3cm}p{6cm}}
      \hline
      \textbf{Event} & \textbf{Paramters} & \textbf{Description} \\
      \hline
      $Write$ & $pa \in \texttt{PhysAddr}$ & A \ac{cpu} \IO to write at physical address
                                             $pa$ \\
      \hline
      $Read$ & $pa \in \texttt{PhysAddr}$ & A \ac{cpu} \IO to read at physical address $pa \in
                                            \texttt{PhysAddr}$ \\
      \hline
      $SetCacheStrat$ & $pa \in \texttt{PhysAddr}$ \newline $strat \in
                        \setshortdef{\val{UC}, \val{WB}}$ & Change the cache strategy for $pa$ to
                                                            $strat$ ($\val{WB}$ means write-back and $\val{UC}$ means uncacheable) \\
      \hline
      $UpdateSmrr$ & $smrr \in \texttt{Smrr}$ & Update the \ac{smrr} content with the
                                                new value $smrr$ \\
      \hline
      $Rsm$ & \centering --- & The \ac{cpu} leaves \ac{smm} \\
      \hline
      $OpenBitFlip$ & \centering --- & Flip the $d\_open$ bit \\
      \hline
      $LockSmramc$ & \centering --- & Set the $d\_lock$ bit \\
      \hline
      $NextInstruction\quad$ & $pa \in \texttt{PhysAddr}$ & The program counter register
                                                            of the \ac{cpu} is set to $pa$ \\
      \hline
    \end{tabular}
  }
  \caption{List of software events}
  \label{tab:softev}
\end{table}

Table~\ref{tab:softev} lists the software events we consider in the
$\formatLTS{Minx86}$ Computing Platforms.
%
We model the \ac{cpu} \IOs with $Read(pa)$ and $Write(pa)$, the configuration of
the memory controller with $OpenBitFlip$ and $LockSmramc$, the configuration of
the cache strategy with $SetCacheStrat(pa,strat)$, the configuration of the
\ac{smrr} with $UpdateSmrr(smrr)$ the exit of the \ac{smm} with $Rsm$ and the
update of the \ac{cpu} program counter register with $NextInstruction(pa)$.

\begin{table}
  \bigcentering
  \begin{tabular}{lp{9cm}}
    \hline
    \textbf{Event} & \textbf{Description} \\
    \hline
    $Fetch$ & A \ac{cpu} \IO to fetch the instruction stored at the physical address
              contained in the program counter register \\
    \hline
    $ReceiveSmi\quad$ & A SMI is raised and the \ac{cpu} handles it \\
    \hline
  \end{tabular}
  \caption{List of hardware events}
  \label{tab:hardev}
\end{table}

The other causes of state-transformations are modelled using hardware events.
%
Table \ref{tab:hardev} lists the hardware events we consider in the
$\formatLTS{Minx86}$ Computing Platforms.
%
$Fetch$ models the \IO to fetch the instruction pointed by the program counter
register.
%
$ReceiveSmi$ models a System Management Interrupt being risen and handled by the
\ac{cpu}.

We define $minx86\_fetched$ an event-software mapping for $\formatLTS{Minx86}$
Computing Platforms (see Definition \ref{def:evsoft}).
%
The $minx86\_fetched$ function maps a state-transformation to the set of
software components which own an instruction fetched during this
state-transformation.
%
In the case of \formatLTS{Minx86}, there is only one event which implies
fetching instructions: $Fetch$.
%
Let $o$ be the owner of the instruction pointed by the program counter register
in the formula
%
\[
  minx86\_fetched(h, ev) \triangleq
  \begin{cases}
    \setshortdef{o} & \text{if }ev = Fetch \\
    \emptyset       & \text{otherwise} \\
  \end{cases}
\]
%
We can determine $o$ because $\formatLTS{Minx86}$ tracks the memory location
ownership.

\label{page:minx86def} Given $context$ a hardware-software mapping (see
Definition \ref{def:hardsoftmap}), the precondition predicate of the Computing
Platform $\formatLTS{Minx86}(context)$ is named $min\-x86\_pre$ and the
postcondition predicate is named $min\-x86\_post(con\-text)$.
%
We give an informal description of the $min\-x86\_pre$ and
$minx\-86\_post(context)$ for each event.
%
These definitions have been implemented in Coq in the module
\emph{Spec\-Cert.x86.Transi\-tion}.

We first give the semantics of software events as state-transformers.
%
A software component can always read and write at any physical address.
%
As a consequence, the precondition for $Read(pa)$ and $Write(pa)$ always holds
true.
%
The postcondition for $Read(pa)$ and $Write(pa)$ requires the memory ownership
to be updated according to the memories and cache state updates.
%
The memory controller enforces a simple access control to protect the
SMRAM content in the DRAM memory by forwarding the related \IO to the VGA
controller when the \ac{cpu} is not in \ac{smm}.
%
To determine the owner of the memory location which sees its content overriden
during a state transformation, the postcondition uses the hardware-software
mapping used to define the Computing Platform.

A software component can always update the cache strategy used for an \IO.
%
The postcondition for $SetCacheStrat(pa,strat)$ requires only the cache strategy
setting for this physical address $pa$ to change.
%
The precondition for $UpdateSmrr$ requires the \ac{cpu} to be in \ac{smm}.
%
The postcondition requires the \ac{smrr} of the \ac{cpu} to be updated with the
correct value, the rest of the hardware architecture state being left unchanged.

A software component can jump to any physical address, hence the postcondition
for $\func{NextInstru\-ction}(pa)$ always holds true.
%
The postcondition for $NextInstru\-ction(pa)$ requires the program counter
register to be updated with $pa$. The $OpenBitFlip$ precondition requires the
SMRAMC register to be unlocked. The postcondition requires the \texttt{d\_open}
bit to be updated. The $Lock\-Smramc$ precondition requires the
$\texttt{d\_lock}$ bit to be unset. The postcondition requires the
$\texttt{d\_open}$ bit to be unset and the $d\_lock$ bit to be unset.

We now describe the semantics of hardware events as state-transformers.
%
$\func{Fetch}$ models the fetching of an instruction by the \ac{cpu}.
%
As a consequence, the definition of its precondition and postcondition are the
same as $Read(pa)$ with $pa$ being the program register value.
%
$ReceiveSmi$ precondition requires the \ac{cpu} not to be in \ac{smm} because
\ac{smm} is non-reentrant.
%
The postcondition of $ReceiveSmi$ requires the program counter to be set with
the $smbase + \val{0x8000}$ (where $smbase$ is the value of the SMBASE register
of the \ac{cpu}) and the \ac{cpu} is in \ac{smm}.

\newpage

In this Chapter, we introduce a three-step methodology for specifying and
verifying \ac{hse} mechanisms against hardware architecture models, that is
%
\begin{inparaenum}[(1)]
\item specifying the software requirements that must be satisfied by the trusted
  software components which implement the \ac{hse} mechanism,
%
\item specifying the targeted security policy the \ac{hse} mechanism supposedly
  enforces, and
%
\item verifying that the \ac{hse} mechanism is sound.
\end{inparaenum}
%
A \ac{hse} mechanism specification is sound when untrusted software components'
executions are constrain with respect to the security property as long as the
trusted software component correctly implements it.
%
As we have already argued in Section~\ref{sec:intro:verif}, we believe this
approach would benefit to both hardware designers and software developers.
%
Formal specifications for \ac{hse} mechanisms can be the foundation of a
systematic approach to verify hardware specifications, and form a valuable
addition to the existing documentation.

In Section \ref{sec:speccert:framework}, we give a formal definition of the
SpecCert formalism.
%
In Section \ref{sec:speccert:hardware}, we define a model of x86-based hardware
architectures to verify \ac{hse} mechanisms targeting software isolation
policies using publicly available Intel specifications.
%
In Section \ref{sec:speccert:smm}, we verify the soundness of the \ac{hse}
mechanism implemented in many x86 computer firmware codes to isolate the code
executed while the \ac{cpu} is in System Management Mode (\ac{smm}), a highly
privileged execution mode of x86 microprocessors.
%
Our model and proofs have been implemented using Coq, a proof assistant system
and have been released as an open source software\,\footnote{Which can can be
  found at: \url{https://github.com/lthms/speccert}}.
%
We discuss our results in Section \ref{sec:speccert:discuss}.

\section{SpecCert Formalism} \label{sec:speccert:framework}

\begin{table}[h]
  \centerline{%
    \begin{tabular}{clc}
      \hline
      \bf Notation  & \multicolumn{1}{c}{\bf Description} \\
      \hline
      $\set{S}$ & Set of software components \\
      \hline
      $\set{H}$ & Set of states of the hardware architecture \\
      \hline
      $\set{E}$ & Set of states of events of the hardware architecture \\
      \hline
      $\shortLTS{Ez}$ & Semantic of events as state-transformers (Computing
                        Platform) \\
      \hline
      $\transition{h}{ev}{h'}$ & State-transformation according to
                                        $\shortLTS{Ez}$ \\
      \hline
      $\pathesLTS{Ez}$ & Set of sequences of $\shortLTS{Ez}$ state-transformations
                         (Traces) \\
      \hline
      $P$ & Predicate on trace to model a EM-enforceable security policy \\
      \hline
      $\Delta$ & Requirements on states and state-transformation (\ac{hse} mechanism)
      \\
      \hline
    \end{tabular}
  }
  \caption{SpecCert CheatSheet}
\end{table}


\section{System Management Mode HSE}
\label{sec:speccert:smm}

In \cite{intel2014manual}, Intel states ``the main benefit of \ac{smm} is that
it offers a distinct and easily isolated processor environment that operates
transparently to the operating system or executive and software applications''.
%
For the \ac{smm} processor environment to be isolated, the code executed when
the \ac{cpu} is in \ac{smm} needs to implement a \ac{hse} mechanism.
%
In this section, we formalize and verify this mechanism against the model we
have previously introduced.

\subsection{Computing Platform and Security Policy}

We consider three software components: the boot sequence code, the \ac{smm} code
and the OS code.
%
During the boot sequence, only the boot sequence code is executed and it loads
both the OS code and the \ac{smm} code into memory.
%
At the end of the boot sequence, the OS kernel is executed.
%
This OS kernel will schedule different applications.
%
Because applications are less privileged than the OS kernel, we will not
distinguish them from the kernel code.
%
Thus, in the following, OS code refers to both OS kernel and application codes.

At tracetime, both the OS code and the \ac{smm} code can be executed.
%
Our objective is to evaluate the security provided by the hardware to isolate
\ac{smm} code from OS code.
%
Thus, we define
%
\[
  \set{S} \triangleq \setshortdef{\val{smm}, \val{os}}
\]

We assume the \ac{smm} is dedicated to the \ac{smm} code.
%
Let
$cpu\_in\_smm : \texttt{Archi}_{\set{S}} \rightarrow \setshortdef{\val{true},
  \val{false}}$ be the function which returns $\val{true}$ if the \ac{cpu} is in
\ac{smm} and $\val{false}$ otherwise.
%
We define $smm\_context$ a hardware-software mapping such that
%
\[
  smm\_context(h) \triangleq
  \begin{cases}
    \val{smm} & \text{if } \func{cpu\_in\_smm}(h) = \val{true} \\
    \val{os} & \text{otherwise}
  \end{cases}
\]
%
Let $\formatLTS{Smmx86}$ be the Computing Platform such as
%
\[
  \formatLTS{Smmx86} \triangleq \formatLTS{Minx86}(smm\_context)
\]

We assume that both the OS code and the \ac{smm} code have been loaded in
distinct memory regions. In particular, all the \ac{smm} code has been loaded in
SMRAM.
%
Our objective is to enforce a security policy which prevents the OS code to
tamper with the \ac{smm} code execution.
%
This way, the \ac{smm} (which is the most privileged execution mode of the
\ac{cpu}) cannot be used to perform an escalation privilege.
%
We define $smm\_security$ a predicate to model this security policy such as
given $\rho \in \formatLTS{Smmx86}$,
%
\[
  \begin{array}{l} smm\_security(\rho) \triangleq \\
    \qquad software\_execution\_isolation(smm\_context, minx86\_execute, \rho,
    \setshortdef{\val{smm}})
  \end{array}
\]

\subsection{HSE Definition}

We define $\Delta_{Smm}$ to model the \ac{hse} mechanism applied by the \ac{smm}
code such that
$\Delta_{Smm} = (inv_{Smm}, behavior_{Smm}, \setshortdef{\val{smm}},
smm\_context)$ (see Definition \ref{def:hse}).

In order to enforce the \ac{smm} security policy, we have identified six
requirements on states.
\begin{itemize}
\item When the \ac{cpu} executes the \ac{smm} code, the program counter register
  value needs to be an address in SMRAM.
\item The SMBASE register was correctly set during the boot sequence to point to
  the base of the SMRAM.
\item The SMRAM contains only \ac{smm} code.
\item For a physical address in SMRAM, in case of cache hit, the related cache
  line content must be owned by the \ac{smm} code.
\item In order to protect the content of the SMRAM inside the DRAM memory, the
  boot sequence code has locked the SMRAMC controller. This ensures that an OS
  cannot set the \texttt{d\_open} bit any longer and only a \ac{cpu} in \ac{smm}
  can modify the content of the SMRAM.
\item The range of memory declared with the \ac{smrr} needs to overlap with the
  SMRAM.
\end{itemize}

%%%%%% APPENDIX INV %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We now define $\func{behavior_{Smm}}$.
%
We only define two restrictions.
%
First, we force the \ac{smm} code execution to remain confined within the SMRAM.
%
The reason is simple: the OS code can tamper with the memory outside the SMRAM.
%
As a consequence, jumping outside the SMRAM is the best way to fail the security
policy.
%
Secondly, we prevent the \ac{smm} code to update the \ac{smrr} registers as it
is the responsability of the boot sequence code to correctly set them.

\[
  \func{behavior_{Smm}}(h, ev) \triangleq
  \begin{array}{l}
    \func{smm\_context}(h) = \val{smm} \\
    \quad \Rightarrow ((e =
    NextInstruction(pa)
    \Rightarrow pa \in \texttt{pSmram}) \\
    \qquad \wedge\,(e \neq UpdateSmrr(smrr))) \\
  \end{array}
\]

For $\Delta_{Smm}$ to be a \ac{hse} mechanism, we need to prove the two \ac{hse}
Laws (see Definition \ref{def:laws}).
%
The first law states the state requirements modelled with $inv_{Smm}$ are
preserved through state-transformations if the transformations which do not
satisfy $behavior_{Smm}$ are discarded.
%
We prove this by enumeration of $ev \in \texttt{Event}$ and
$h \in \texttt{Archi}_{Smm}$, we check that each requirement described
previously is preserved by $\Delta_{Smm}$.
%
We use those intermediary results to conclude.
%
The second law states that the $behavior_{Smm}$ predicate specifies
state-trans\-formation requirements for the \ac{tcb} only.
%
In this use case, it means $behavior_{Smm}$ should always hold true when the OS
code is executed by the hardware architecture.
%
By definition of $behavior_{Smm}$, $smm\_context(h) = \val{smm}$ is an
antecedent of the conditional.

Let $smm\_secure\_transformation$ be a predicate which holds true when a
state-transformation does not imply the OS code to tamper with the execution of
\ac{smm} code.
\[ \begin{array}{l}
     smm\_secure\_transformation(h, ev) \triangleq \\
     \qquad \neg software\_tampering(smm\_context, minx86\_execute, h, ev,
     \val{os}, \val{smm})
   \end{array} \]

 We prove that this predicate holds true for a state-transformation with respect
 to the \ac{hse} mechanism. With this result, we can prove the \ac{hse}
 mechanism is sound (see Definition \ref{def:sound}).

\begin{lemma}[Invariants Enforce Security]
  $\forall \transitionLTS{Smmx86}{h}{ev}{h'}$,
  \[ \begin{array}{l}
       inv_{Smm}(h) \\
       \qquad \Rightarrow (ev \in \texttt{Event}_{Soft} \Rightarrow
       behavior_{Smm}(h,ev) \\
       \qquad\qquad \Rightarrow smm\_secure\_transformation(h, ev)
     \end{array} \]

  \begin{proof}
    By enumeration of $ev \in \texttt{Event}$ and
    $h \in \texttt{Archi}_{\set{S}}$.
  \end{proof}
\end{lemma}

\begin{theorem}[$\Delta_{Smm}$ is Sound]
  \[ sound(\Delta_{Smm}, smm\_security) \]
  \begin{proof}
    The "Invariants Enforce Security" lemma applies for one transition and the
    first \ac{hse} law allows to reason by induction on traces.
  \end{proof}
\end{theorem}


\section{Conclusion}
\label{sec:speccert:discuss}

Our effort has been originally motivated by the disclosure of several
vulnerabilities targeting multiple x86 \ac{hse} mechanisms for the past few
years\,\cite{wojtczuk2009smram,duflot2009smram,rutkowska2008remap,domas2015sinkhole,kallenberg2015racecondition}.
%
These attacks do not benefit from a software implementation error but rather
from a flaw in the hardware specifications themselves.
%
The result of our work is a three-steps methodology for formally specifying and
verifying \ac{hse} mechanisms against a hardware architecture model.
%
We believe each aspect is important.

First, the hardware architecture model can be used as a formal specification.
%
The main benefit of a formal specification is to avoid any ambiguity such as the
one we have found in \cite{intel2009mch}.
%
One can read at Section 3.8.3.8, page 102 that ``the OPEN bit must be reset
before the LOCK bit is set''.
%
At the same page, in the description of the LOCK bit, one can also read that
``when [LOCK] is set to 1 then [OPEN] is reset to 0''.
%
We had modelled the second statement as the behavior of the memory controller is
not specified if the first statement is true\,\footnote{If we had to actually
  implement the \ac{hse} mechanism, we would have to assume the first was the
  correct one.}  \formatLTS{Minx86} as a formal specification does not suffer
from the same flaw.

Secondly, a formal specification of a \ac{hse} mechanism will help software
developers when the time comes to implement it.
%
For instance, the Chapter 34, Volume 3C of \cite{intel2014manual} about \ac{smm}
is about 30 pages long, it gives many details on how the \ac{smm} actually
works, yet no section is actually dedicated to security.
%
On the contrary, our \ac{hse} mechanism definition gathers six requirements on
hardware configurations and two requirements on software executions to enforce a
well-defined security property.
%
Even if the proofs only apply to an abstract model, we believe it is a valuable
improvement.

Lastly, the verification process of a \ac{hse} mechanism specification against a
hardware architecture model may help to highlight hidden flaws in the hardware
specifications assumptions.
%
We take the example of the SMRAM cache poisonning
attack\,\cite{wojtczuk2009smram,duflot2009smram}, which has motivated the
introduction of the \ac{smrr}.
%
If an attacker can set the proper cache strategy (WB) for the SMRAM physical
addresses, then the code inside the SMRAM is loaded into the cache as soon as
the \ac{cpu} in \ac{smm} is executing it.
%
From this point forward ---because the access control is enforced at the memory
controller level--- nothing prevents the attacker to tamper with it.
%
The next time the \ac{cpu} enters in \ac{smm}, it executes the code stored in
the cache. With a \ac{smrr}-less version of \formatLTS{Minx86}, we were not able
to conclude our \ac{hse} mechanism was sound: such a scenario draws attention of
the SpecCert user who is forced to investigate.

From our point of view, the clear separation between the hardware model, the
security properties and the \ac{hse} mechanisms to enforce those properties are
the main advantage of our approach, as two different use cases can be studied
against the same hardware model.
%
However, the scalability of SpecCert remains to be proven.
