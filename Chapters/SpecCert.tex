%!TEX root = ../main.tex
\chapter{A Theory of HSE Mechanisms}
\label{chapter:speccert}

\endquote{``\emph{The purpose of abstraction is not to be vague, but to create a
    new semantic level in which one can be absolutely precise}''

  \hfill\footnotesize --- Edsger Dijkstra}

\vspace{1cm}%
\noindent
%
Our first contribution is a theory of \ac{hse} mechanisms which takes into
account that
%
\begin{inparaenum}[(1)]
\item hardware architectures often allow for implementing several \ac{hse}
  mechanisms, and
\item hardware features involved in \ac{hse} mechanisms are not safe by default,
  hence the role played by trusted software components to configure them.
\end{inparaenum}
%
The rest of this Chapter proceeds as follows.
%
First, we detail how our theory allows for specifying and verifying \ac{hse}
mechanisms against general-purpose hardware models, in isolation and in
composition (Section~\ref{sec:speccert:theory}).
%
To demonstrate how we can reason about composition of \ac{hse} mechanisms, we
proceed through a case study focused on a so-called code injection policy.
%
More precisely, we prove how we can enforce this policy by means of two \ac{hse}
mechanisms implemented at the same time (Section~\ref{sec:speccert:casestudy}).
%
This case study is used as the basis of a more in-depth experiment in the next
Chapter.

For the reader familiar with Coq, we present an implementation of our theory in
Appendix~\ref{appendix:speccert}.
%
This development comprises machine-checked proofs of the theorems and lemmas
that we present throughout this Chapter.

\section{Theory Definition}
\label{sec:speccert:theory}

We model the hardware architecture as a labeled transition system whose
sequences of transitions, also called traces, characterize every possible
execution of software components (Section~\ref{subsec:speccert:hardware}).
%
This model acts as a foundation for our \ac{hse} mechanisms theory
(Section~\ref{subsec:speccert:hse}).
%
We then define what correctness means in the context of \ac{hse} mechanisms
(Section~\ref{subsec:speccert:security}).
%
Our motivation to separate the model of the hardware architecture and \ac{hse}
mechanism definitions is to enable the reuse of the same hardware model to
verify the correctness of several \ac{hse} mechanisms.
%
Beside, it makes reasoning about \ac{hse} mechanisms composition ---that is, the
implementation, at the same time, of two \ac{hse} mechanisms or more--- possible
(\ref{subsec:speccert:compo}).

\subsection{Hardware Model}
\label{subsec:speccert:hardware}

We model a hardware architecture, which can execute different software
components, as a particular \ac{lts} (Definition~\ref{def:sota:lts}) with two
sets of labels instead of one.

\paragraph{States.}
%
The set of states of the \ac{lts} models the possible configurations of the
hardware components.
%
This configuration changes over time with respect to the hardware specifications
and comprises any relevant data such as register values, inner memory contents,
etc.
%
These state transformations occur during the system's transitions.

\paragraph{Transitions.}
%
We distinguish between two classes of transitions: the software transitions
which are direct and foreseeable side effects of the execution of an instruction
and the hardware transitions which are not.
%
Following the terminology of David Basin \emph{et
  al.}\,\cite{basin2013enforceable}, software transitions are ``controllable'',
while hardware transitions are only ``observable''.

We illustrate this definition with the x86 instruction \texttt{mov
  (\%ecx),\%eax}\,\footnote{Written in AT\&T syntax here.}.
%
With respect to the semantics of this instruction, a x86 core:
%
\begin{inparaenum}[(1)]
\item reads the content of the register \texttt{ecx},
%
\item interprets this value as an address and reads the main memory at this
  address,
%
\item writes this content into the register \texttt{eax},
%
\item updates the register \texttt{eip} with the address of the next instruction
  to execute.
\end{inparaenum}
%
The execution of this instruction by a core may result in several sequences of
transitions.
%
First, the four execution steps described above translate into four software
transitions.
%
Between each of these transitions, a hardware transition can occur.
%
For instance, one hardware component can initiate a \ac{dma}.
%
Also, if the content of \texttt{ecx} is not a valid address, the processor
raises an interrupt.
%
In this scenario, only one software transition occurs ---when the core reads the
content of \texttt{ecx}--- then the next transition models the interrupt.

\begin{definition}[Hardware Model]
  \label{def:speccert:model}
  A hardware model $\Sigma$ is a tuple
  $\langle H, L_S, L_H, \rightarrow \rangle$, where
  %
  \begin{itemize}
  \item $H$ is the set of configurations of the hardware architecture
  %
  \item $L_S$ is the set of labels to identify software transitions
  %
  \item $L_H$ is the set of labels to identify hardware transitions
  %
  \item $\rightarrow$ is the transition relation of the system
  \end{itemize}

  The transition relation \( \rightarrow \) is a predicate on
  $H \times L \times H$, where \( L = L_S\,\uplus\,L_H \) and \( \uplus \) is
  the disjoint union which requires that \( L_S\,\cap\,L_H = \emptyset \).
  %
  A transition labeled with $l$ from $h$ to $h'$ is denoted by
  %
  \[
    \transition{h}{l}{h'}
  \]
  %
  and we write $\mathcal{T}(\Sigma)$ for the set of triples which satisfy the
  transition relation, that is
  \[
    \mathcal{T}(\Sigma) \triangleq \{\ (h, l, h')\ |\ \transition{h}{l}{h'}\ \}
  \]
\end{definition}

\paragraph{Traces.}
A trace is a non-empty sequence of transitions of~$\Sigma$, such that for two
consecutive transitions, the resulting state of the first one is the initial
state of the next one.

% \TODO{Tu ne donnes qu'une définition informelle (en anglais) des traces. Tu
% pourrais donner la formule correspondante. Idem pour init et trans}
% \thomasrk[inline]{Bien que je comprenne l'argument, je ne pense
% personnellement pas que ça apportenait vraiment quelque chose.}

\begin{definition}[Traces]
  \label{def:speccert:trace}
  We write $\pathesLTS{Ez}$ for the set of traces of a hardware model $\Sigma$,
  and we consider the following functions:
  %
  \begin{itemize}
  \item $\func{init} : \pathesLTS{Ez} \rightarrow H$ maps a trace to its initial
    state
  \item
    $\func{trans} : \pathesLTS{Ez} \rightarrow \powerset(\mathcal{T}(\Sigma))$
    maps a trace to the set of transitions which occurred during the trace
  \end{itemize}
\end{definition}

Mainstream hardware architectures are not ``safe'' by default, and required
additional software configuration to enforce security properties.
%
For instance, it is legitimate, from a x86 specifications perspective, to enter
ring 3 mode with a page table which allows for modifying kernel code and data.
%
We aim to model \ac{hse} mechanisms as traces subsets, to discard traces
legitimate from a hardware specification perspective, yet dangerous from a
security perspective.

\subsection{HSE Mechanisms}
\label{subsec:speccert:hse}

In our theory of \ac{hse} mechanism, a \ac{hse} mechanism is primarily
characterized by a set of trusted software components, a set of requirements
over states and a set of requirements over software transitions.
%
Trusted software components are responsible for implementing the \ac{hse}
mechanism.
%
To that end, they correctly configure the underlying hardware mechanism in
accordance with the two requirements over states and over software transitions.

On the one hand, the purpose of the requirements over states is to identify the
hardware configurations which constrain the execution of untrusted software
components with respect to a targeted security policy.

On the other hand, the purpose of the requirements over software transitions is
to guarantee requirements over state hold true at all time.
%
Because we consider an adversary model where attackers control untrusted
software components, we do not consider any hypotheses on their behavior.
%
Therefore, requirements over software transitions should only constrain the
execution of trusted software components, which implement the \ac{hse}
mechanism.

These two classes of requirements allow us to determine a subset of compliant
traces, that is traces where trusted software components have correctly
implemented a \ac{hse} mechanism by satisfying the requirements at all time.
%
% \TODO{Peut être rappeller que "correctly implement the HSE" veut dire
% respecter les contraintes sur les états et les transititions software. C'est
% un peu trop implicite.}
%
From this perspective, to verify this \ac{hse} mechanism is correct with respect
to a targeted security policy means proving the set of compliant traces of this
mechanism satisfies the predicate which models the policy.

\paragraph{HSE Mechanisms.}
%
In the context of \ac{hse} mechanisms, trusted and untrusted software components
alike use the same interface to interact with the underlying hardware
components: the processor instructions set.
%
To reason about HSE mechanisms, it is necessary to be able to determine which
software component is executed at a given time.
%
In practice, a subset of states of the hardware architecture is dedicated to
each software component.
%
For instance, x86 processors protection rings are commonly used to execute
several software components.
%
Ring 0 is dedicated to the operating system, whereas the applications are
executed by a core is in ring 3, with a particular page table setup.

\begin{definition}[Hardware-Software Mapping]
  \label{def:speccert:hardsoft}
  Given \( S \) a set of software components, a hardware-software mapping
  $\func{con\-text} : H \rightarrow S$ is a function which takes a hardware
  state and returns the software component currently executed.
\end{definition}

This definition is of key importance, because it implies strong hypotheses on
how a software stack is executed.
%
First, we assume only one software component is executed at a given time by the
hardware architecture, in order to simplify our definitions.
%
We believe dealing with multi-core architectures is possible with the cost of
additional efforts ---\emph{e.g.} by defining a set of identifiers to select a
particular core--- yet it remains to be proven as we have not tackled this
challenge during this thesis.
%
Besides, there are approaches which allow for executing two software components
using the same ``hardware context'', \emph{e.g.} JavaScript programs of two tabs
inside a browser are arguably two distinct software components.
%
However, from the hardware architecture perspective, these three components
---the browser and the two JavaScript programs--- are indistinguishable, and
enforcing a security policy in such a context is achieved by means of software
measures, \emph{e.g.} program interpretation or software fault
isolation\,\cite{morrisett2012rocksalt}.

We say a software transition is trusted (respectively untrusted) when it occurs
from a state associated to a trusted (respectively untrusted) software
component.
%
A hardware-software mapping is mandatory to define requirements over software
transitions that are consistent with respect to our adversary model, \emph{i.e.}
which only constrain trusted software components.

\begin{definition}[HSE Mechanism]
  \label{def:speccert:hse}
  A \ac{hse} mechanism $\Delta$ is a tuple
  $\langle S, T, \func{context}, \func{hardware\_req}, \func{software\_req}
  \rangle$, such that
  %
  \begin{itemize}
  \item $S$ is the set of software components executed by the hardware
    architecture.
  %
  \item $T \subseteq S$ is the set of trusted software components which
    implement the \ac{hse} mechanism and form its \ac{tcb}.
  %
  \item $\func{context}$ is a hardware-software mapping to determine which
    software component is currently executed by the core.
  %
  \item $\func{hardware\_req}$ is a predicate on $H$ to distinguish between safe
    hardware configurations and potentially vulnerable ones.
  %
  \item $\func{software\_req}$ is a predicate on $H \times L_S$ to distinguish
    between software transitions that trusted software components can safely
    use, and potentially harmful ones they need to avoid.
  \end{itemize}
\end{definition}

We illustrate this definition with the flash memory lockdown mechanism described
in Section~\ref{subsec:usecase:firm:sec}.
%
As a reminder, such mechanism enforces the integrity of the \ac{bios} code
within the flash memory and is implemented by the \ac{pch}.
%
As pictured in Figure~\ref{fig:speccert:flash}, the \ac{pch} acts as a proxy
between the core and a collection of peripherals, including the flash memory.
%
The \ac{hse} mechanism proceeds as follows:
%
\begin{enumerate}
\item By default, the flash memory is locked and its content cannot be modified.
  %
  By setting the correct bit of a dedicated register of the \ac{pch}
  (\texttt{BIOS\_CNTL}), a software component requests to unlock the flash
  memory.
%
\item When a software component (\emph{e.g.} system software) unlocks the flash
  memory, the \ac{pch} triggers a \ac{smi}.
%
\item This forces the core to enter \ac{smm}.
  %
  By doing so, the core stops the execution of the software component which has
  unlocked the flash memory and starts the execution of the \ac{bios}.
%
\item In order to protect the integrity of the flash memory content, the
  \ac{bios} is expected to lock the flash memory again, before resuming the
  execution of the system software with the \texttt{rsm} assembly instruction.
\end{enumerate}

Legacy \acp{bios} probably used this mechanism in order to implement an ad-hoc
communication channel between the \ac{bios} and the system software component,
\emph{e.g.} to initiate a \ac{bios} update.
%
The \ac{uefi} standard introduces dedicated protocols to enable communication
between the \ac{bios} and the system software component, and our understanding
is that in most implementations the \ac{bios} action, in response to a \ac{smi}
triggered by the unlocking of the flash memory, is limited to lock it again and
resume.

\begin{figure}
  \centering
  \begin{tikzpicture}
    \node [draw, inner sep=12pt, text badly centered] (CPU) {Processor};%
    \node [draw, below=15pt of CPU, inner sep=25pt, text badly centered] (PCH)
    {PCH};%
    \draw (CPU) -- (PCH);%

    \node [draw, inner sep=5pt, below=10pt of PCH, text width=45pt,
    xshift=-55pt, text badly centered] (Flash) {Flash Memory};%
    \draw ([xshift=-10pt]PCH.south) |- (Flash.east);%

    \node [draw, text=white, dashed, inner sep=10pt, below=10pt of PCH, text
    width=25pt, xshift=55pt, text badly centered] (TPM) {TPM};%
    \draw [dashed] ([xshift=10pt]PCH.south) |- (TPM.west);%

    \node [draw, text=white, dashed, inner sep=10pt, right=20pt of PCH, text
    width=45pt, text badly centered] (USB) {USB Controller};%
    \draw [dashed] (PCH) -- (USB);%

    \node [draw, text=white, dashed, inner sep=10pt, left=20pt of PCH, text
    width=45pt, text badly centered] (PCI) {PCI Controller};%
    \draw [dashed] (PCH) -- (PCI);%
  \end{tikzpicture}

  \caption{From the processor to the flash memory}
  \label{fig:speccert:flash}
\end{figure}

\begin{example}[Model of Flash Memory Lockdown Mechanism]
  \label{example:speccert:flashdef}
  %
  The set of trusted software components is limited to the \ac{bios}, that is
  \( T = \{ \mathtt{bios} \} \).
  %
  This means the rest of the software stack (\emph{e.g.} the operating system
  and its applications) are untrusted and therefore assumed to be under the
  control of attackers.
  %
  The hardware-software \( \func{context} \) maps \acp{cpu} in \ac{smm} with the
  execution of the \ac{bios}, that is
  %
  \[
    \begin{array}{rcll}
      \func{context}(h) & = & \mathtt{bios} & \text{if } h \text{ characterizes
                                              a \ac{cpu} in \ac{smm}} \\
      \func{context}(h) & \in & S \backslash \{ \mathtt{bios} \} & \text{otherwise}
    \end{array}
  \]
  %
  % \TODO{La phrase n'est pas suffisamment préciser. En outre, j'ai mis du temps
  % à
  % me rappeler que context ne doit pas être pris ici comme un mot commun mais
  % un nom de fonction!. Il faudrait dire que par défaut contexte(h)=non trusté
  % sauf lorsque le CPU est en SMM, c'est à dire lorsqu'une SMI se produit et
  % avant que le bios exécute une instruction rsm}
  %
  A safe hardware state ($\func{hardware\_req}$) is either a state wherein the
  \ac{bios} is executed, or a state wherein the flash memory is locked.
  %
  It is expected that the \ac{bios} locks the flash memory before using the
  \texttt{rsm} instruction ($\func{software\_req}$).
\end{example}

\paragraph{HSE Laws.}
%
As it is, our theory of \ac{hse} mechanisms is too permissive.
%
For a \ac{hse} mechanism to be consistent, it must also obey two requirements,
together called the \ac{hse} laws.
%
The first law says that the $\func{software\_req}$ predicate always holds true
for untrusted software transitions.
%
That is, the first law enforces that a \ac{hse} mechanism definition does not
make any assumption regarding untrusted software components.
%
The second law says that the requirements over states specified by
$\func{hardware\_req}$ are invariant with respect to $\func{software\_req}$.
%
As long as the trusted software components which implement the \ac{hse}
mechanism only generate software transitions which satisfy the
$\func{software\_req}$ predicate, the $\func{hardware\_req}$ predicate holds
true.
%
This means the software transitions at the untrusted software components
disposal cannot put the system into an unsafe state.

\begin{definition}[\ac{hse} Laws]
  \label{def:speccert:laws}
  A \ac{hse} mechanism $\Delta$ has to satisfy the following properties:
  \begin{enumerate}
  %
  \item Untrusted software transitions satisfy $\func{software\_req}$:
    $\forall (h, l, h') \in \mathcal{T}(\Sigma)$, $\forall x \not\in T$,
    %
    \[
      (l \in L_S \wedge \func{context}(h) = x) \Rightarrow
      \func{software\_req}(h, l)
    \]
  %
  \item $\func{hardware\_req}$ is an invariant with respect to
    $\func{software\_req}$: $\forall (h, l, h') \in \mathcal{T}(\Sigma)$,
    \[
      (\func{hardware\_req}(h) \wedge (l \in L_S \Rightarrow
      \func{software\_req}(h,l))) \Rightarrow \func{hardware\_req}(h')
    \]
  \end{enumerate}
\end{definition}

On the one hand, a \ac{hse} mechanism definition which does not satisfy the
first law is incorrectly making assumption about ``untrusted'' software
components.
%
This makes these components part of the \ac{tcb} \emph{de facto}, even though
they do not belong to $\mathcal{T}$.
%
Formally defining a \ac{hse} mechanism may be the occasion to uncover such
implicit assumptions.
%
On the other hand, a \ac{hse} mechanism which does not satisfy the second law
has to be carefully reviewed.
%
As it stands, it lets the hardware architecture reach a state wherein the
hardware configuration does not satisfy the requirements over states, despite
the correct implementation of the mechanism by the trusted software components.
%
In such a condition, the hardware architecture may stop to constrain the
execution of untrusted software components with respect to the targeted security
policy.
%
This could mean that constrains over trusted software components execution are
incomplete, or that requirements over hardware states are too restrictive.
%
If it is not possible to loosen the requirements over hardware states without
threatening the security policy enforcement or to find additional restrictions
over trusted software execution, then the \ac{hse} mechanism probably does not
serve its purpose.
% \TODO{Cela veut surrement dire que les contraintes sur l'exécution du code
% trusté sont incomplètes ou que le la restriction sur l'état du hardware est au
% contraire trop restrictive. S'il n'est pas possible de trouver une contrainte
% sur l'état du hardware moins restrictive permettant d'assurer la propriété de
% sécurité ou de restreindre le code trusté pour vérifier cette seconde loi, il
% y a de forte chance que le HSE ne permette pas d'assurer la propriété de
% sécurité visée.... }

\begin{example}[Flash Memory Lockdown Inconsistency]
  We can convince ourselves that the informal definition description we have
  discussed in the Example~\ref{example:speccert:flashdef} obeys the first
  \ac{hse} law, but \emph{does not} obey the second one.
  %
  \paragraph{Untrusted software transitions satisfy $\func{software\_req}$.}
  %
  The only software restriction we have formulated concerns the use of the
  \texttt{rsm} instruction by the \ac{bios}.
  %
  The rest of the software stack can leverage the complete x86 instructions set
  with no restriction.
  %
  In particular, an attacker is free to unlock the flash memory thanks to the
  \texttt{BIOS\_CNTL} register.

  \paragraph{$\func{hardware\_req}$ is not an invariant with respect to
    $\func{software\_req}$.}
  %
  A \ac{cpu} is either in \ac{smm} or not in \ac{smm}.
  %
  If it is in \ac{smm}, the only way to leave \ac{smm} is to execute the
  \texttt{rsm} instruction, which qualifies as a software transition.
  %
  If the \ac{cpu} is in \ac{smm}, the \func{software\_req} hold true for this
  software transition when the flash memory is locked.
  %
  As a consequence, a \ac{bios} which correctly implements this \ac{hse}
  mechanism locks the flash memory prior to leaving the \ac{smm}.
  %
  However, if the \ac{cpu} is not in \ac{smm}, and tries to open the flash
  memory, two things happen sequentially.
  %
  First, the flash memory is effectively opened.
  %
  This has to be modelled by a software transition.
  %
  Then, the \ac{pch} triggers a \ac{smi}, leading the \ac{cpu} to enter
  \ac{smm}.
  %
  A \ac{smi} has to be modelled as a hardware transition.
  %
  Between the modification of the \texttt{BIOS\_CNTL} register and the treatment
  of the \ac{smi} by the \ac{cpu}, the \func{hardware\_req} predicate is not
  satisfied.

  It is because the flash memory lockdown as described here does not satisfy the
  first law that the race condition uncovered by Corey Kallenberg \emph{et
    al.}\,\cite{kallenberg2015racecondition} is possible.
  %
  On the contrary, the \texttt{SMM\_BWP} register semantics ---detailed in
  Subsection~\ref{subsec:usecase:hse:speed}--- allows for defining a HSE
  mechanism which satisfies both laws, because the register ties together the
  state of the \acp{cpu} and the flash memory state.
\end{example}

\paragraph{Trace Compliance.}
%
Whether trusted software components are correctly implementing a given \ac{hse}
mechanism is a safety property: trusted software components shall \emph{never}
generate a software transition which does not satisfy the requirements of the
\ac{hse} mechanism.
%
Because the purpose of these requirements over software transitions is to
prevent untrusted software components to reach a hardware configuration wherein
the requirements over states are not satisfied, so it is required that the
initial state of the trace satisfies the requirements over states.
%
A trace whose initial state satisfies the requirements over states and where
trusted software components do correctly implement a \ac{hse} mechanism is said
to comply with this mechanism.

\begin{definition}[Compliant Traces]
  We write $\mathcal{C}(\Delta)$ for the set of the traces which comply with
  $\Delta$.
  %
  Given $\rho \in \pathesLTS{Ez}$, then $\rho \in \mathcal{C}(\Delta)$ iff
  \[
    \func{hardware\_req}(\func{init}(\rho)) \wedge \forall (h,l,h') \in
    \func{trans}(\rho)\text{, }l \in L_S \Rightarrow \func{software\_req}(h, l)
  \]
\end{definition}

\begin{example}[Memory Flash Lockdown Compliance]
  We consider the trace to start at the end of the boot sequence, when the
  \ac{bios} gives the control flow to the system software component it has
  selected.
  %
  At the time, it is expected that the \texttt{BIOS\_CNTL} register of the
  \ac{pch} has been correctly set; in particular, the \texttt{SMM\_BWP} bit
  should be set, to avoid the Speed Racer
  attack\,\cite{kallenberg2015racecondition}.
  %
  If the \ac{bios} fails to do so, then the related trace is not compliant.
\end{example}

\begin{lemma}[HSE Invariant Enforcement]
  \label{lemma:speccert:hseinv}
  As intended, \func{hardware\_req} is an invariant of traces which complies
  with $\Delta$, that is
  %
  \[
    \forall \rho \in \mathcal{C}(\Delta), \forall (h, l, h') \in
    \func{trans}(\rho), \func{hardware\_req}(h) \wedge \func{hardware\_req}(h')
  \]

  \begin{proof}
    By definition of $\mathcal{C}(\Delta)$, we know the initial state of the
    trace satisfies \func{hardware\_req}, and thanks to the second HSE law, we
    can conclude the state after the first transition also satisfies
    \func{hardware\_req}.
    %
    We generalize to the trace by induction.
    %
    \hfill \( \square \)
  \end{proof}
\end{lemma}

As a consequence, a \ac{hse} mechanism allows for satisfying a given set of
requirements over hardware configurations throughout the execution of a software
stack, as long as a set of trusted software components correctly implement the
mechanism.

\subsection{HSE Mechanism Correctness}
\label{subsec:speccert:security}

It is important to keep in mind that preserving a set of requirements over
states is only a mean to an end.
%
The true purpose of a \ac{hse} mechanism is to constrain the execution of
untrusted software components with respect to a targeted security policy.

It is possible to define a \ac{hse} mechanism which satisfies the \ac{hse} laws,
yet failed to constrain the execution of untrusted software components with
respect to a targeted security policy.
%
The SMRAM cache poisoning attack disclosed in 2009 is a good illustration of
that eventuality\,\cite{duflot2009smram,wojtczuk2009smram}.
%
Back then, the isolation of the \ac{bios} at runtime is enforced by only two
hardware mechanisms: the \ac{smm} of the \ac{cpu} and the \texttt{SMRAMC}
register of the memory controller.
%
By correctly configuring the memory controller \emph{via} the \texttt{SMRAMC}
register, the \ac{bios} can activate the protection of a dedicated memory region
called the SMRAM.
%
In such a case, only a core in \ac{smm} can read or write to the SMRAM.
%
As it stands, the \ac{hse} mechanism described here satisfies both laws.
%
However, between the core and the memory controller lies the cache, as pictured
in Figure~\ref{fig:speccert:smram}.
%
If the cache does not take into account the SMRAM ---as it was the case in
2009--- it can be used to somehow circumvent the protection enforced by the
memory controller: as we have already explained in
Subsection~\ref{subsec:usecase:hse:smram}, the integrity of the SMRAM is
enforced, but the core does not read its content when it needs it.

\begin{figure}
  \centering
  \begin{tikzpicture}
    \node [draw, inner sep=15pt] (Core) {Core};%
    \node [draw, inner sep=7pt, below=5pt of Core] (Cache) {Cache};%
    % \node [draw, inner sep=10pt, dashed, fit=(Core) (Cache)] (CPU) {};%

    \node [draw, below=10pt of Cache, inner sep=20pt, text width=50pt, text
    badly centered] (MC) {Memory Controller};%

    \draw (Core) -- (Cache);%
    \draw (Cache) -- (MC);%

    \node [draw, right=10pt of MC, minimum height=100pt, inner sep=10pt] (DRAM)
    {DRAM};%

    \draw (DRAM) -- (MC);%

    \draw [dashed] ([yshift=15pt]DRAM.south west) -- ([yshift=15pt]DRAM.south
    east);%
    \draw [dashed] ([yshift=25pt]DRAM.south west) to node [below, yshift=1pt]
    {\small SMRAM} ([yshift=25pt]DRAM.south east);%
  \end{tikzpicture}

  \caption{From the core to the SMRAM}
  \label{fig:speccert:smram}
\end{figure}

We detailed in Subsection~\ref{subsec:sota:security} how various classes of
security policies ---safety and liveness properties, and hyperproperties--- can
be modeled against a transition system.
%
Because our hardware model is a labeled transition system, we can easily
transpose these definitions to our theory.

\begin{definition}[Security Policy]
  A security policy \( P \) is either a predicate on sets of traces, a predicate
  on traces or a predicate on transitions.
\end{definition}

In most cases, the security policy is expected to be enforce in all traces of a
given system, that is \( \mathcal{R}(\Sigma) \).
%
However, hardware architectures are unsafe by default, and have to be configured
by trusted software components in order to enforce a targeted security policy at
all time.
%
As a consequence, the correctness relation of a \ac{hse} mechanism \( \Delta \)
is expressed with respect to \( \mathcal{C}(\Delta) \) rather than
\( \mathcal{R}(\Sigma) \).

\begin{definition}[Correct HSE Mechanism]
  A \ac{hse} mechanism $\Delta$ is correct with respect to a security policy $P$
  (denoted by $\Delta \models P$) if and only if the set of compliant traces of
  $\Delta$ satisfies $P$, that is
  %
  \[
    \Delta \models P \triangleq
    \begin{cases}
      P(\mathcal{C}(\Delta)) & \text{if } P \text{ is a predicate on sets of
        traces} \\
      \forall \rho \in \mathcal{C}(\Delta), P(\rho) & \text{if } P \text{ is a
        predicate on traces} \\
      \forall \rho \in \mathcal{C}(\Delta), \forall \mathit{tr} \in
      \func{trans}(\rho), P(\mathit{tr}) & \text{if }P \text{ is a predicate on
        transitions}
    \end{cases}
  \]
\end{definition}

A proof that a \ac{hse} mechanism \( \Delta \) is correct with respect to a
security policy \( P \) rules out the risk of a vulnerability based on the
hardware features which are part of the scope of the hardware model.
%
Verifying that a \ac{hse} mechanism is correct with respect to a security policy
can be difficult.
%
In the context of this thesis, we focus on safety properties.
%
The reasoning is facilitate because they are characterized by predicates on
transitions.
%
The following theorem takes advantage of this fact.

\begin{theorem}[Correct HSE Mechanism for Predicate on Transitions]
  \label{theorem:speccert:correcthse}
  Given a security policy $P$ defined as a predicate on transitions, then
  %
  \[
    \begin{array}{l}
      \forall (h, l, h') \in \mathcal{T}(\Sigma), \\
      \qquad (\func{hardware\_req}(h) \wedge
      (l \in L_{S} \Rightarrow \func{software\_req}(h, l)))
      \Rightarrow P(h, l, h')
    \end{array}
  \]
  %
  is a sufficient condition for
  %
  \[
    \Delta \models P
  \]

  \begin{proof}
    By definition, a HSE mechanisn \( \Delta \) is correct with respect to a
    security policy characterized by a predicate on transitions \( P \) if the
    transitions of its compliant traces satisfy \( P \).
    %
    With Lemma~\ref{lemma:speccert:hseinv}, we know that initial states of a
    transition of compliant traces satisfy $\func{hardware\_req}$.
    %
    We also know by definition of compliant traces that their transitions
    satisfy \func{software\_req}.
    %
    Therefore, if we can prove that transition which satisfy both
    \func{hardware\_req} and \func{software\_req} also satisfy \( P \), then we
    can conclude that transitions of compliant traces satisfy \( P \).
    %
    \hfill \( \square \)
  \end{proof}
\end{theorem}

A proof of correctness of a given \ac{hse} mechanism in our theory asserts the
hardware architecture enforces a targeted security policy \emph{if trusted
  software components correctly implement this \ac{hse} mechanism}, that is
their executions only imply software transitions which satisfy the appropriate
software requirements.
%
If an untrusted software component proves to be capable of exploiting a security
vulnerability of a trusted software component program, this condition would
instantaneously become false and the security policy enforcement would no longer
be guaranteed, even though the hardware architecture is capable of enforcing it.

Besides, an hypothesis of our model remains implicit: our reasoning is based on
the fact that we can determine the behavior of a software component based on the
current hardware configuration.
%
In practice, this is not true: the behavior of a software component is based on
its programs, as fetched by the core which executes it.
%
If attackers is able to modify the instructions which form the trusted software
components programs, then they can trivially defeat the security enforcement by
modifying the instruction responsible to implement it.

This is why trusted software components are expected to protect themselves
against untrusted software components attempt to modify their program.
%
They satisfy this expectation thanks to dedicated \ac{hse} mechanisms that we
can also verify.
%
This raises the question of the implementation of several \ac{hse} mechanisms at
the same time.

\subsection{HSE Mechanisms Composition}
\label{subsec:speccert:compo}

In common software stacks, several \ac{hse} mechanisms are implemented at the
same time by low-level software components.
%
The fact that two \ac{hse} mechanisms of the same hardware architecture can be
specified against the same general-purpose hardware model allows us to reason
about their \emph{composition}.
%
We model the concurrent implementation of two \ac{hse} mechanisms \( \Delta_1 \)
and \( \Delta_2 \) as a third \ac{hse} mechanism \( \Delta_1 \sqcap \Delta_2 \).
%
For convenience, the \( \sqcap \) operator imposes two restrictions over
\ac{hse} mechanisms: they shall share the same set of software components and
the same hardware-software mapping.

\begin{definition}[Concurrent HSE Mechanisms]
  Given two HSE mechanism \( \Delta_1 \) and \( \Delta_2 \), such that
%
  \[
    \begin{array}{rcl}
      \Delta_1
      & =
      & \langle S, T_1, \func{context}, \func{hardware\_req}_1, \func{software\_req}_1
        \rangle \\
      \Delta_2
      & =
      & \langle S, T_2, \func{context}, \func{hardware\_req}_2, \func{software\_req}_2
        \rangle
    \end{array}
  \]
%
  We write $\Delta_1 \sqcap \Delta_2$ for the \ac{hse} mechanism which combines
  the requirements of both $\Delta_1$ and $\Delta_2$, that is
%
  \[
    \Delta_1 \sqcap \Delta_2 \triangleq \langle S, T_1 \cup T_2, \func{context},
    \func{hardware\_req}_{1\wedge2}, \func{software\_req}_{1\wedge2} \rangle
  \]
%
  where
  \[
    \begin{array}{rcl}
      \func{hardware\_req}_{1\wedge2}(h)
      & \triangleq
      & \func{hardware\_req}_1(h) \wedge \func{hardware\_req}_2(h) \\
      \func{software\_req}_{1\wedge2}(h,l)
      & \triangleq
      & \func{software\_req}_1(h,l) \wedge \func{software\_req}_2(h,l)
    \end{array}
  \]
\end{definition}

We now discuss two properties of \( \sqcap \) which emphasize that its
definition matches legitimate expectations.
%
Firstly, \( \sqcap \) forms a commutative monoid, and as a consequence is both
associative and commutative.
%
This means the order in which we define a ``composite'' \ac{hse} mechanism from
a list of sub-mechanisms is not important.
%
Secondly, the set of compliant traces of the composition of two mechanisms is
the intersection of the sets of compliant traces of these mechanisms.
%
In other word, to comply with the composition of two \ac{hse} mechanisms, a
trace has to comply with each mechanism individually.

\begin{lemma}[Commutative Monoid]
  We write $\Delta_\top$ for the \ac{hse} mechanism whose requirements over
  states and software transitions are always satisfied.
  %
  \( \sqcap \) forms a commutative monoid with the set of \ac{hse} mechanisms
  which share both the same set of software components and the same
  hardware-software mapping, whose identity element is \( \Delta_\top \).

  Indeed, \( \sqcap \) satisfies the following properties:

  \begin{description}
  \item [Associativity:]
    \( (\Delta_1 \sqcap \Delta_2) \sqcap \Delta_3 = \Delta_1 \sqcap (\Delta_2
    \sqcap \Delta_3) \)
    %
  \item [Identity Element:] \( \Delta \sqcap \Delta_\top = \Delta \)
    %
  \item [Commutativity:]
    \( \Delta_1 \sqcap \Delta_2 = \Delta_2 \sqcap \Delta_1 \)
  \end{description}

  \begin{proof}
    \( \sqcap \) is defined with operators which themselves form monoids.
    %
    For each properties, the proof consists in unfolding the definition of
    \( \sqcap \) and relying on the properties of \( \cup \) and \( \wedge \).
    %
    \hfill \( \square \)
  \end{proof}
\end{lemma}

\begin{lemma}[Compliant Traces, Composition and Intersection]
  \label{lemma:speccert:compinter}
  The set of compliant traces of the intersection of $\Delta_1$ and $\Delta_2$
  is the intersection of the sets of compliant traces of $\Delta_1$ and
  $\Delta_2$, that is
  \[
    \mathcal{C}(\Delta_1 \sqcap \Delta_2) = \mathcal{C}(\Delta_1) \cap
    \mathcal{C}(\Delta_2)
  \]

  \begin{proof}
    The main idea of the proof is to leverage the definition of $\wedge$ and
    $\Rightarrow$ to turn a statement of the form
    %
    \[
      (P \wedge P') \wedge (R \Rightarrow Q \wedge Q')
    \]
    %
    into
    %
    \[
      (P \wedge (R \Rightarrow Q)) \wedge (P' \wedge (R \Rightarrow Q'))
    \]
    %
    and vice versa.
    %
    In our case, $P$ and $P'$ are statements about the initial states of traces
    and \func{hardware\_req}, $R$ is the premise filtering software transitions,
    and $Q$ and $Q'$ are statements about \func{software\_req}.
    %
    \hfill \( \square \)
  \end{proof}
\end{lemma}

The definition of a composition operator poses the question of \ac{hse}
mechanisms compatibility.
%
There are obvious scenarios where two \ac{hse} mechanisms \( \Delta_1 \) and
\( \Delta_2 \) can be doubtlessly considered incompatible.
%
For instance, \( \mathcal{C}(\Delta_1 \sqcap \Delta_2) = \emptyset \) would mean
it is not possible to implement both at the same time.
%
We anticipate there are other scenarios more unclear, for instance if the set of
compliant traces \( \mathcal{C}(\Delta_1 \sqcap \Delta_2) \) contains only
traces where a given software component prevents a given software component to
correctly implement its functional specification.
%
We advocate that a similar situation can occur for a single \ac{hse} mechanism.
%
Because we aimed to focused on hardware architecture verification in the context
of this thesis, we therefore did not investigated further a characterization of
compatible and incompatible \ac{hse} mechanisms.

\subsection*{}

In this Section, we introduced our theory to formally specify and verify
\ac{hse} mechanisms.
%
It allows us to verify each \ac{hse} mechanism in isolation, but we also
introduced a composition operator as a first step toward reasoning about the
implementation of two \ac{hse} mechanisms or more at the same time.
%
In the next Section, we proceed with a case study focused on so-called code
injection policies, to act as a detailed example on \ac{hse} compositions.

\section{Case Study: Code Injection Policy}
\label{sec:speccert:casestudy}

We now aim to illustrate further how our theory can be leveraged in order to
reason about security enforcement by means of several \ac{hse} mechanisms
implemented at the same time.
%
To that end, we take as an example a security policy which explicitly forbids
software components of a typical software stack ---that is, the \ac{bios}, an
operating system and several applications--- to perform illegitimate code
injection (\ref{subsec:speccert:globalsec}).
%
As we discussed in Subsection~\ref{subsec:speccert:security}, the integrity of
the trusted software components programs is an implicit hypothesis of our
approach, which makes our code injection policy a prerequisite for reasoning
about other \ac{hse} mechanisms.
%
We detail how this security policy can be enforced through the correct
implementation of two \ac{hse} mechanisms
(\ref{subsec:speccert:isolationenforcement}).

\subsection{Defining Code Injection}
\label{subsec:speccert:tampering}

A memory location within a hardware architecture is a container dedicated to
store data used by software components \emph{e.g.}~a general-purpose register of
a processor, a \ac{dram} memory cell, etc.
%
To formally define a code injection, it is necessary to be able to map an
instruction executed by the processor to the software component which has
written this instruction into its memory location.
%
To that end, we assign to each memory location a so-called \emph{owner}, such
that a software component becomes the new owner of a memory location when it
overwrites its content during a software transition.
%
A hardware model tracks the memory location ownership when
%
\begin{inparaenum}[(1)]
\item the hardware architecture state maps each memory location with a software
  component called its \emph{owner}, and
%
\item its transition relation updates this mapping throughout traces.
\end{inparaenum}
%
By extension, we say a software component owns some data when it owns the memory
location in which these data are stored.

\begin{definition}[Transition-Software Mapping]
  \label{def:speccert:transsoft}
  A transition-software mapping
  $\func{fetched}_{\Sigma}: H \times L \rightarrow \powerset(S)$ is a function
  which takes an initial hardware state, a transition label and returns the set
  of owners of the fetched instructions during this transition.
\end{definition}

With this mapping, specific to a given hardware model, it becomes possible to
determine the owner of an instruction fetched by the processor in order to be
decoded and executed.
%
\( s \in \func{fetched}_{\Sigma}(h, l) \) means that an instruction owned by $s$
was fetched in order to be executed by the processor during a transition labeled
with \( l \) from a state \( h \).

With a hardware-software mapping and an transition-software mapping, we give a
formal definition of a \textit{code injection}.

% GH: "Event-software mapping" c'est la même chose que "transition-software
% mapping"? Ne pas utiliser deux termes différents pour la même notion...
%
% Thomas: C'était un artefact de la version article. Bien vu :)

\begin{definition}[Code Injection]
  \label{def:speccert:tempering}
  A software component $x \in S$ achieves a code injection against another
  software component $y \in S$ during a transition labeled with $l \in L$ from a
  state $h \in H$ to a state $h' \in H$, denoted by
  %
  \[
    h \xrightarrow[x \leadsto y]{l} h'
  \]
  %
  when the processor fetches an instruction owned by $x$ while executing $y$,
  that is
  %
  \[
    h \xrightarrow[x \leadsto y]{l} h' \triangleq x \in
    \func{fetched}_{\Sigma}(h, l) \wedge \func{context}(h) = y
  \]

  We write $h \xrightarrow[x \not\leadsto y]{l} h'$ when $x$ does not achieve a
  code injection against~$y$.
\end{definition}

It is important to emphasize that a code injection is not inherently a ``bad
things.''
%
A software component initialization is most of the time the result of a code
injection.

\begin{example}[Application Code Injection]
  When the user of a computer starts a new application, the operating system
  loads the code of this application into the \ac{dram}.
  %
  Therefore, when the processor starts the execution of the application in
  ring~3, it executes instructions which are owned by the OS.
\end{example}

On the contrary, an illegitimate code injection poses a significant threats
against the security of the software stack, because it constitutes a
straightforward attack vector for a privilege escalation.
%
Low-level software components, such as the \ac{bios}, partly rely on the
hardware architecture to protect them against illegitimate code injection.
%
They store their code in a memory region of their choice and implement a
\ac{hse} mechanism to prevent upper layers of the stack from modifying its
content.
%
As a consequence, unsound \ac{hse} mechanisms pave the road to illegitimate code
injection.

\begin{example}[SMRAM Cache Poisoning]
  The SMRAM cache poisoning attack\,\cite{duflot2009smram,wojtczuk2009smram}
  that we detailed in Subsection~\ref{subsec:usecase:hse:smram} can be used to
  perform a code injection attack against the \ac{bios}.
  %
  For instance, Loic Duflot \emph{et al.} have been able to inject the necessary
  instructions inside the cache for the processor so that the \ac{bios} updates
  the \texttt{SMBASE} register, whose purpose is to determine the first
  instruction executed by a core when it enters \ac{smm}.
\end{example}

\subsection{Code Injection Policy}
\label{subsec:speccert:globalsec}

We leverage the code injection definition to propose a generic formalization of
code injection policy, to determine if a given software component is authorized
to make a code injection against another software component in the context of a
particular software stack.

\begin{definition}[Code Injection Policy]
  \label{def:speccert:global}

  A code injection policy \( I \) is a safety property characterized by a tuple
  \( \langle S, \rightarrowtail, \func{context} \rangle \), such that
  %
  \begin{itemize}
  \item \( S \) is a set of software components executed by the hardware
    architecture
  \item \( \rightarrowtail \) is a binary relation on \( S \), such that given
    \( (x, y) \in S \times S \), \( x \rightarrowtail y \) means \( x \) is
    authorized to make a code injection against \( y \).
    %
    \( \rightarrowtail \) has to be
    %
    \begin{inparaenum}[(1)]
    \item anti-symmetric, and
    %
    \item transitive.
    %
    \end{inparaenum}
    %
    \[
      \begin{array}{lr}
        \forall (x, y) \in S \times S,
        & \\
        \qquad x \rightarrowtail y \wedge y
        \rightarrowtail x \Rightarrow x = y
        & \text{\small (1)} \\
        %
        \forall (x, y, z) \in S \times S \times S,
        & \\
        \qquad x \rightarrowtail y \wedge y
        \rightarrowtail z \Rightarrow x \rightarrowtail z
        & \text{\small (2)}
      \end{array}
    \]
    %
  \item \func{context} is a hardware-software mapping.
  \end{itemize}

  A transition labeled with \( l \in L \) from \( h \in H \) to \( h' \in H \)
  satisfies \( I \) when code injections which occur during this transition are
  authorized by \( \rightarrowtail \), that is
  %
  \[
    I(h, l, h') \triangleq \forall (x, y) \in S \times S \text{, } h
    \xrightarrow[x \leadsto y]{l} h' \Rightarrow x \rightarrowtail y
  \]
\end{definition}

Based on Definition~\ref{def:speccert:global}, we can define a code injection
policy for a typical software stack which comprises the \ac{bios}, an operating
system and \( n \) applications.

\begin{definition}[BIOS-OS-Applications Code Injection Policy]
  \label{definition:speccert:isolation}

  For a software stack made of a \ac{bios}, an operating system an \( n \)
  applications, that is
  \[
    S \triangleq \{ \mathtt{bios}, \mathtt{os}, \mathtt{app}_1, \dots
    \mathtt{app}_n \}
  \]
  %
  we define the authorization relation $\rightarrowtail$ using three rules:
  %
  \begin{description}
  \item [\(\rightarrowtail\)-refl:] A software component is authorized to tamper
    with its own execution, that is
    %
    \[ \forall x \in S, x \rightarrowtail x \]
    %
  \item [\(\rightarrowtail\)-bios:] The \ac{bios} is authorized to tamper with
    the execution of the rest of the software stack, that is
    %
    \[ \forall x \in S, \mathtt{bios} \rightarrowtail x \]
  \item [\(\rightarrowtail\)-os:] The OS is authorized to tamper with the
    execution of the application it manages, that is
    %
    \[ \forall k \in [0, n], \mathtt{os} \rightarrowtail \mathtt{app}_k \]
  \end{description}

  We prove by case enumeration that $\rightarrowtail$ is anti-symmetric and
  transitive.

  The definition of the corresponding $\func{context}$ shall obey the following
  logic: when the processor is in \ac{smm}, the \ac{bios} is executed; when the
  processor is not in \ac{smm} and is in ring 0, the system software component
  is executed; when the processor is not in \ac{smm} and is in ring 3, one of
  the applications ---identified by the page tables used by the processor--- is
  executed.
\end{definition}

\subsection{Code Injection Policy Enforcement}
\label{subsec:speccert:isolationenforcement}

A security policy such as the one detailed in
Definition~\ref{definition:speccert:isolation} is not enforced by one but
several HSE mechanisms.
%
Therefore, we break it down to more specific security sub-policies, with each
one being enforced thanks to a dedicated \ac{hse} mechanism.

\begin{definition}[BIOS Code Injection Sub-policy]
  \label{def:speccert:biospol}

  We write $I_{\mathtt{bios}}$ for the code injection sub-policy, whose purpose
  is to enforce that the only software component authorized to perform a code
  injection against the \ac{bios} is the \ac{bios} itself, that is
  %
  \[
    I_{\mathtt{bios}}(h, l, h') \triangleq \forall x \in S, h \xrightarrow[x
    \leadsto \mathtt{bios}]{l} h' \Rightarrow x = \mathtt{bios}
  \]
\end{definition}

\begin{definition}[OS Code Injection Sub-policy]
  \label{def:speccert:ospol}

  We write $I_{\mathtt{os}}$ for the code injection sub-policy, whose purpose is
  to enforce that applications are only authorized to perform code injection
  against themselves, that is
  %
  \[
    I_\mathtt{os}(h, l, h') \triangleq \forall x \in S, h
    \xrightarrow[\mathtt{app}_k \leadsto x]{l} h' \Rightarrow x = \mathtt{app}_k
  \]
\end{definition}

Without any knowledge about the \ac{hse} mechanisms used to enforce
\( I_{\mathtt{bios}} \) and \( I_{\mathtt{os}} \), we can prove they together
imply the enforcement of \( I \).

\begin{theorem}[Code Injection Policy Enforcement]
  Given two \ac{hse} mechanisms \( \Delta_{\mathtt{os}} \) and
  \( \Delta_{\mathtt{os}} \), if \( \Delta_{\mathtt{bios}} \) is correct with
  respect to \( I_{\mathtt{bios}} \) and \( \Delta_{\mathtt{os}} \) is correct
  with respect to \( I_{\mathtt{os}} \), then
  \( \Delta_{\mathtt{bios}} \sqcap \Delta_{\mathtt{os}} \) is correct with
  respect to \( I \), that is
  %
  \[
    (\Delta_{\mathtt{bios}} \models I_{\mathtt{bios}} \wedge
    \Delta_{\mathtt{os}} \models I_{\mathtt{os}}) \Rightarrow
    \Delta_{\mathtt{bios}} \sqcap \Delta_{\mathtt{os}} \models I
  \]

  \begin{proof}
    By definition of correct \ac{hse} mechanism, we need to prove that the set
    of traces which comply with
    \( \Delta_{\mathtt{bios}} \sqcap \Delta_{\mathtt{os}} \) satisfies the
    security policy characterized by \( I \).
    %
    With Lemma~\ref{lemma:speccert:compinter}, we know that the set of compliant
    traces of \( \Delta_{\mathtt{bios}} \sqcap \Delta_{\mathtt{os}} \) is the
    intersection of the sets of compliant traces of \( \Delta_{\mathtt{bios}} \)
    and \( \Delta_{\mathtt{os}} \).
    %
    As a consequence, we know any transition \( h \xrightarrow{l} h' \) of these
    traces satisfy both \( I_{\mathtt{os}} \) and \( I_{\mathtt{bios}} \).
    %
    We can conclude by case enumeration:
    %
    \begin{itemize}
    \item \( I \) does not impose any restriction if the \( \mathtt{bios} \)
      performs a code injection during such a transition.
    \item Because of \( I_{\mathtt{bios}} \), an \( \mathtt{os} \) can only
      perform a case injection against itself are against an application, which
      satisfies \( I \)
      %
    \item Because of \( I_{\mathtt{os}} \), an application can only perform a
      case injection against iteslf, which also satisfies \( I \). \hfill
      \( \square \)
    \end{itemize}
  \end{proof}
\end{theorem}

\subsection*{}

In this Section, we specified a general-purpose called code injection policy,
and detailed how we could apply it to a typical software stack made of a
\ac{bios}, an operating system and \( n \) applications.
%
More precisely, we proved it is possible to enforce such a policy in this setup
by enforcing two sub-policies (respectively \( I_{\mathtt{bios}} \) to protect
the \ac{bios}, and \( I_{\mathtt{os}} \) to constrain the execution of the
applications) thanks to two \ac{hse} mechanisms (respectively denoted by
\( \Delta_{\mathtt{bios}} \) and \( \Delta_{\mathtt{os}} \)).
%
On a typical x86 hardware architecture, \( \Delta_{\mathtt{bios}} \) relies on
the \ac{smm} and the SMRAMC memory region within \ac{dram} (as we detailed in
Subsection~\ref{subsec:usecase:firm:sec}), and \( \Delta_{\mathtt{os}} \) relies
on the \ac{mmu} and the protection rings.

\section{Conclusion}

In this Chapter, we have presented our theory of \ac{hse} mechanisms, in the
form of requirements over a hardware model.
%
We emphasize that our approach requires a general-purpose hardware model to
define and verify \ac{hse} mechanisms to enable the verification of several
mechanisms against the same reference, both in isolation and in composition.
%
We believe this is an essential property; in practice, these multiple mechanisms
are implemented at the same time by different software components, and they may
interfere with each other, as illustrated by the SENTER Sandman attack discussed
in Subsection~\ref{subsec:usecase:hse:sandman}.

Throughout this Chapter, we have tried to illustrate our definitions with
real-world examples, as our effort has been originally motivated by the
disclosure of several vulnerabilities targeting multiple x86 \ac{hse} mechanisms
for the past few
years\,\cite{wojtczuk2009smram,duflot2009smram,rutkowska2008remap,domas2015sinkhole,kallenberg2015racecondition}.
%
All being told, our approach can be summarized to a three-step methodology for
specifying and verifying \ac{hse} mechanisms against hardware architecture
models, that is
%
\begin{inparaenum}[(1)]
\item specifying the software requirements that must be satisfied by the trusted
  software components which implement the \ac{hse} mechanism,
%
\item specifying the targeted security policy the \ac{hse} mechanism supposedly
  enforces, and
%
\item verifying that the \ac{hse} mechanism is correct with respect to the
  targeted security policy.
\end{inparaenum}
%
We believe this methodology would benefit both hardware designers and software
developers, but we are interested in challenging the applicability of our
approach.
%
To that end, we proceed with the case study introduced in
Section~\ref{sec:speccert:casestudy}, by specifying the \ac{hse} mechanism
implemented by the \ac{bios} to remain isolated from the rest of the software
stack after the end of the boot sequence (detailed
Section~\ref{sec:usecase:hse}), and verifying this \ac{hse} mechanism is correct
with respect to the \ac{bios} code injection
(Definition~\ref{def:speccert:biospol}).
