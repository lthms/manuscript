\chapter{Related Works}
\label{chapter:relatedwork}

Hardware-based Security Enforcement (HSE) mechanisms are fundamental to enforce
primordial security properties such as isolation between layers of abstraction.
%
Because of the complexity of modern computing platforms, HSE mechanism
implementations are subject to architectural attacks, where one attacker is able
to exploit the legitimate use of one hardware component in order to circumvent
the protection normally implemented by another.
%
The important impact of previously disclosed architectural attacks have
motivated our will to formally specify HSE mechanisms, with two objectives in
mind:
%
\begin{inparaenum}[(1)]
\item providing unambiguous, security-focused specification to firmware and
  system software developers, and
%
\item verifying these specifications actually provides the targeted security
  properties.
\end{inparaenum}
%
These objectives are in line with an ongoing effort to strengthen the lower
layers of abstraction.
%
In 2011, Nachiketh Potlapally\,\cite{potlapally2011hardwaresecurity}, who
was working at Intel at the time, lists the same challenges we have detailed in
Chapter\,\ref{chapter:usecase}, and suggests that formal methods for security
validation is one of the possible solutions to these challenges.
%
In 2016, Stephen Chong \emph{et al.} cite ``Hardware Architectures'' and
``Operating Systems'' as areas of interest regarding the use of formal methods
for security\,\cite{chong2016report}.

The main characteristic of HSE mechanisms is that they are the result of both
hardware and software components, in presence of a larger system with untrusted
actors.
%
However, hardware and software components are not of the same nature.
%
Hardware components are physical devices which accept inputs and computes
outputs.
%
Software components are piece of data scattered into memory spaces, whose
semantics are determined by the processor unit that executes them.
%
While both hardware and software components are been subject to formal
verification in the past, these verification works tend to rely on different
representations.
%
Florian Lugou \emph{et al.} explain this in depth while they introduce SMASHUP,
a toolchain for unified verification of Hardware-software
co-designs\,\cite{lugou2017smashup}.
%
It is the main reason why we focus on the specification level in the context of
this thesis.
%
Refine our potential conclusions up to a concrete implementation is necessary in
the long term.
%
Fortunately, it is also a very active fields, with impressive flagship projects
such as DeepSpec\,\cite{appel2017deepspec}.

The rest of this Chapter proceeds as follows.
%
\thomasrk[inline]{Todo again: annonce du plan}
%We first describe the research works whose purpose is to verify system software
%built upon HSE mechanisms (Section\,\ref{sec:relatedwork:software}).
%%
%Then, we focus on research work dedicated to verify that a given piece of
%hardware correctly enforces security properties
%(Section\,\ref{sec:relatedwork:hardware}).
%%
%These projects have in common to model one particular component, and to abstract
%away the rest of the system.
%%
%``Connecting'' these specifications and verification results remains
%challenging.
%%
%Therefore, we finally describe research works focused on modular verification of
%complex systems made of several inter-connected components
%(Section\,\ref{sec:relatedwork:modular}).

\section{Labelled Transition System} % ========================================

When it comes to formally specify a given system, and latter verify it, a common
approach is to model it as a \ac{lts}.
%
A \ac{lts} comprises three components:
%
\begin{inparaenum}[(1)]
%
\item a set of states the system can take,
%
\item a set of labels which describe the events which occur within the system
  and causing its state to change, and
%
\item a set of transitions, from one state to another and caused by one event.
%
\end{inparaenum}

Once defined, a \ac{lts} specifies the system functional behaviour.
%
It can also be used to reason about the system's executions, modelled as
sequences of transitions.
%
In this context, security property definitions are predicates which depend on
these sequences.
%
This is the case, for instance, for \emph{enforceable security properties}, as
defined by Fred B. Schneider\,\cite{schneider2000enforceable}.
%
An enforceable security property is a security property which only depends the
execution past, that is the sequence of transitions which led the system from
its initial state to its current state.
%
A common approach is to distinguish between secure states and insecure states,
secure transitions and insecure transitions, and to verify that, for a subset of
traces --typically traces which start from a secure state---, the system is
never an insecure state, and no insecure transition ever occurs.
%
For instance, the integrity of the SMM code within the SMRAM is an enforceable
security property.
%
Knowing the state of the CPU ---and, in particular, its execution mode--- each
time it has issued a successful write access to the SMRAM suffices to determine
whether a untrusted software component has been able to tamper with its content.
%
In this context, a SMRAM which contains an arbitrary instruction instead of
expected SMM code, constitutes a secure state.

\paragraph{}
%
Hardware and software components alike have been modelled with \ac{lts}, or a
similar formalism.

\paragraph{\ac{xom}.}
%
The \ac{xom} microprocessor architecture maintains separate so-called
\emph{compartments} for applications.
%
With mainstream microprocessor architectures, the system software is responsible
for both memory allocation and access control.
%
It relies on configurable \ac{cpu} mechanisms, such as a \ac{mmu}, to implement
the latter.
%
On the contrary, a \ac{xom} \ac{cpu} keeps track of each memory location owner,
thanks to a tagging mechanism, and prevents an application to access a memory
location it does not own.

In 2003, David Lie \emph{et al.} have modelled the \ac{xom} architecture using
the Mur$\varphi$ model checker.
%
This model follows the principle of a \ac{lts}: a set of states, a set of
labelled transitions (called \emph{rules} in the context of this work), and a
set of transitions.
%
There is two kind of rules: the \ac{xom} instructions set, and some additional
capabilities given to the attacker.
%
As for the transitions set, it is defined in terms of pre and post conditions.
%
On the one hand, the pre condition is parameterized by the initial state and the
labelled event.
%
If the pre condition is satisfied for a given hardware state and labelled event,
then it means that event can occur from this state.
%
On the other hand, the post condition is parameterized by the initial state, the
labelled event and the resulting state.
%
It determines the consequences of that event, in terms of state update.

The security properties targeted by the \ac{xom} architecture are enforceable
security properties, and the authors rely on Mur$\varphi$ to perform the state
exploration of their model.
%
The main advantage of a model checker, in this context, is to be able to print
the trace it has found not to satisfy the targeted security property.
%
This trace describes an attack path, that is the execution steps to reproduce in
order to defeat the security enforcement.
%
Hence, the authors have been able to show with their model that the \ac{xom}
architecture was subject to several replay attacks, and they leverage their
model to validate their countermeasures.
%
However, the state explosion problem obliges the authors to simplify their
model, in order to reduce the state combinatory.

\paragraph{VirtCert}
%
Between 2011 and 2014, Gilles Barthe \emph{et al.} have worked on a idealized
model of a hypervisor.
%
This model is defined in terms of state, actions and a semantics of actions as
state-transformers.
%
That is, even if the authors are not using the terms \ac{lts}, their model
follows the same principles.
%
In their context, the state mixes information about both hardware components
(\ac{cpu} execution mode, registers, memory content, etc.) and software
components (list of guests, current active guest, memory mapping for the
hypervisor and the guests, etc.).
%
The actions are the hypercalls, exposed by the hypervisor for the guests to use.
%
The semantics of actions as state-transformers, that is the set of possible
transitions for the modelled system, is defined in terms of pre and post
conditions.

First, they have shown that their ideal hypervisor was
%
\begin{inparaenum}[(1)]
\item ensuring strong isolation between guests, and
%
\item eventually processing every requests intended by the
  guests\,\cite{barthe2011virtcert1}.
\end{inparaenum}
%
Then, they have incorporated the \ac{cpu} cache to their
model\,\cite{barthe2012virtcert2}.
%
Cache-based attacks, where attackers are able to infer information they should
not have access to by leveraging their knowledge of micro-architectural
implementation specificity, are a very important threat to virtualization
platforms.
%
The authors have show their ideal hypervisor could prevent such attack, at the
cost of flushing the cache before each context switch.
%
They have taken their approach a step further, by focusing on constant-time
cryptography\,\cite{barthe2014virtcert3}.

The scope of this hypervisor model is large, and cover many security aspects
primordial for virtualization platforms.
%
Moreover, there have been an important specification and formalization effort
required to take into consideration the different security properties.
%
Some of them, like constant-time cryptography implementations, are not
enforceable security properties.
%
Indeed, it is not possible, only with the trace of one execution, to know
whether a given implemantion is constant-time.
%
It is required to consider all the possible traces.

\paragraph{}
%
Both \ac{xom} model and VirtCert rely on \acp{lts} or similar formalism to
specify one component in particular and to verify a set of targeted properties.
%
However, in their models, all the trusted components are specified and verified
together.
%
From a \ac{xom} architecture perspective, there is no such thing as a
``trusted'' software component, because the access control mechanism is solely
implemented by the \ac{xom} \ac{cpu}.
%
As for VirtCert, the model purpose is to validate a determined hypervisor model.
%
From this thesis perspective, a hypervisor is a trusted software component which
implements a \ac{hse} mechanism by correctly configuring hardware mechanisms
such as virtualization technologies.
%
If we were eventually able to formally specify a HSE mechanism which was proven
to correctly implement guests isolation, then we could verify that VirtCert
hypervisor satisfies the software requirements of the HSE mechanism.
%
The main idea is to be able to reuse the same software requirements for a
totally different system software, which also happens to use the same
virtualization technologies to enforce guests isolation, but a different
partition algorithm.

\ac{lts} have also been used to specify requirements over software components,
and verify these requirements were sufficient the hardware architecture to
enforce a set of targeted properties.

\paragraph{RockSalt}
%
Thanks to a Google's service called \ac{nacl}, it is possible for software
developers to distribute their web applications in the form of native executable
code.
%
These native applications are executed directly in the context of the browser.
%
\ac{nacl} uses \ac{sfi} to prevent arbitrary native applications to tamper with
the code and data of the browser.
%
\ac{sfi} comprises a set of rules native applications have to comply with, and
that together form a sandbox policy.
%
In practice, the \ac{nacl} checks that an arbitrary native applications respects
the \ac{sfi} rules before loading it to the browser context.
%
As a consequence, the browser is protected from malicious machine code.

From a security perspective, this means there is two requirements over the
\ac{nacl}:
%
\begin{inparaenum}[(1)]
\item verify that the rules indeed are sufficient to constrain the untrusted
  native applications with respect to the sandbox policy, and
%
\item the \ac{nacl} checker correctly verify that native applications respect
  these rules.
\end{inparaenum}
%
This is similar to the challenges faced by \ac{hse} mechanisms.
%
Because \ac{nacl} has been shown to have issues regarding these two
requirements, Greg Morrisett \emph{et al.} have specified the \ac{nacl} checker
in Coq, proven the rules it checks are correct and indeed enforce the targeted
sandbox policy, and then manually translated the checker in
C\,\cite{morrisett2012rocksalt}.
%
By doing so, they have addressed the two requirements listed above, as long as
their translation is correct.
%%
% They proceeded as follows.
%%
% First, they modelled the set of states of the CPU.
%%
% Then, they defined a translator, from the complex x86 instruction set to a
% much simpler instructions set, easier to reason with.
%%
% They define a semantics for this simpler instructions set.
%%

\paragraph{Moat}
%
Intel \ac{sgx} is a recent addition to certain x86 \acp{cpu}, whose purpose is
to provide so-called enclaves to userland
applications\,\cite{costan2016sgxexplained}.
%
These enclaves supposedly offer an execution environment isolated from the
system software.
%
The functioning of \ac{sgx} can be roughly summarized as follows:
\ac{sgx}-capable CPU dedicates a special portion of the system memory, called
the \ac{epc}, to enclaves.
%
The system software is responsible for allocating and initializing memory pages
of the \ac{epc} (thanks to dedicated instructions), but it cannot read or write
to them once it is done.
%
This is enforced by the memory controller, which encrypt the content of the
\ac{epc} transparently from the \ac{cpu}.
%
Hence, the memory controller only decrypts an \ac{epc}'s page if it is accessed
by the enclave which owns it; it will also discards write accesses performed by
another software component than the page owner.

Rohit Sinha \emph{et al.} have modelled SGX instructions semantics, to complete
an existing model, and have developed an automated information flow analysis
tool called Moat, to verify whether are not a given application code may leak
secret or not\,\cite{sinha2015moat}.
%
The work proceeds similarly to RockSalt, where instructions are treated as
labelled transition from one state to another.
%
However, Moat also consider an active and passive adversary, with additional
capabilities (meaning, additional transitions in the system).
%
The approach is similar to what David Lie \emph{et al.} have done for the
\ac{xom} architecture.

\paragraph{}
%
Both RockSalt or Moat express requirements software requirements shall comply
with in order to enable hardware to enforce a targeted security policy.
%
Moat, in particular, allows for considering several software components, in the
form of an active adversary with system software capabilities.
%
We are willing to generalize their approach, to specify and verify \ac{hse}
mechanisms.
%
However, because we target a larger scope, we will remain at the specification
levels, and we do not plan on verifying particular implementations of trusted
software components.

Each work we have been introducing in this Section relies on a model of a
hardware architecture.
%
This model often comprises the hardware features that are directly required by
the software component.
%
Because we mostly focus on architectural attacks, and because architectural
attacks leverage unsuspected compositions of hardware features, we cannot adopt
this approach for the long term.
%
Defining a model which is comprehensive in terms of hardware components, and
usable for verifying relevant properties, calls for methodological
requirements.
%
Indeed, the more complex a model becomes, the more challenging it is to reason
with.

\section{Hoare Logic} % ===============================================

Model complexity originates in two situations:
%
\begin{inparaenum}[(1)]
\item when transitions from one state to another imply important state updates,
  and
%
\item when the state comprises an important number of sub-components.
%
\end{inparaenum}
%
This is reminiscent of the programming language problematic to model large and
verify large programs with side effects.
%
In this context, the execution of functions modifies the state of the program
context, made of its stack, heap, etc.
%
Floyd-Hoare Logic (more commonly, Hoare Logic) is a popular formal system for
reasoning about the correctness of computer programs.
%
The system is defined in terms of state and commands, and a semantics of
commands as state-transformers defined in terms of pre and post conditions.
%
A command can be an axiomatic operation (\emph{e.g.} an assignment statement in
a computer program), or a composition rule (\emph{e.g.} a \emph{if-else}
statement, a function call, etc.).
%
Hoare Logic allows for modular reasoning.
%
Once a couple of pre and post conditions is proven for a given command, further
reasoning wherein this command appears can be based solely on these pre and post
conditions.
%
As a result, the concrete implementation of the command is abstracted away.
%
Defining our hardware model in an imperative style has also the extra benefit of
making it more closer to what domain experts are familiar to, compared to
\emph{e.g.} functional programming.

\paragraph{Frama-C}
%
The Framework for Modular Analysis for C programs (Frama-C) is a set of C
programs analyzers.
%
Several analyzers (\emph{e.g.} WP, Value) are based on Hoare Logic.
%
The program source code is annotated with pre and post conditions, defined in a
dedicated language called \ac{acsl}.
%
The goal of a Frama-C analyzer is to conclude whether the post condition of a C
statement is enforced by the pre condition.
%
The proof can be computed automatically for simpler problems, or interactively
\emph{via} external tools.
%
For instance, Frama-C's analyzers can be configured so that they formulate the
predicates they are not able to prove themselves in Coq lemmas for the user to
prove.
%
If the user is able to write a proof accepted by Coq, then Frama-C can use this
result.

\paragraph{}
%
Using the C language to reason with hardware components.
%
For instance, the reference implementation of XXX\thomasrk{Find the correct name
+ ref}, a cache coherence protocol, is written in C.
%
However, C is a (relatively) low-level language.
%
This makes reasoning with higher-level abstractions more difficult.
%
For instance, a list is a common and useful data structure.
%
In C, lists are usually encoded as linked list, which implies reasoning with
pointers (and potential memory aliasing, etc.).
%
Using a higher-level language can be useful to avoid this problem.

\paragraph{Ynot}

\paragraph{Pip}
%
MMU\,\cite{jomaa2016mmu}

\section{Interface Automata} % ================================================

\begin{itemize}
\item[--] In previous section, routine impact on state is ''more imporant'' than
  its result
\item[--] Same state, no matter how deep we go
\item[--] How to deal with ``outer'', distant environment?
\item[--] Coq.io makes hypothesis on outer environment result, but how to verify
  these hypothesis?
\item[--] Interface Automata provide an interesting formalism
\item[--] Alloy\,\cite{jackson2012alloy} is a very good example of what we want
  to achieve
\end{itemize}

%\section{Verified Software Component} % ========================================
%\label{sec:relatedwork:software}
%
%Verification of Systems Software is a longstanding, active research fields.
%%
%Even if our end goal is not to prove the correctness of one software component
%implementation, it is interesting to study how they represent the hardware
%architecture.
%%
%By formally specifying HSE mechanisms and verifying they correctly enforce a
%targeted security properties, our objective is to change the nature of proof of
%implementation correctness.
%%
%Rather than proving a given implementation enforce a security property, it
%should be shown that it complies to a verified HSE mechanism specification which
%targets this security property.
%
%\subsection{Verified Systems Software} % ---------------------------------------
%
%\begin{compactitem}
%\item[--] In this section, we list three different projects, which adopt three
%  different approach.
%\item[--] Our goal is not to be exhaustive, but rather to give insightful
%  examples.
%\end{compactitem}
%
%\paragraph{VirtCert}
%%
%\begin{compactitem}
%\item[--] Executable specification of a hardware-based hypervisor.
%%
%\item[--] Focus on x86 virtualisation technology features, with a simple memory
%  model.
%\item[--] Iterative works, focus on several security properties:
%  \begin{compactitem}
%  \item Isolation
%  \item Liveness properties
%  \item Constant time cryptography
%  \end{compactitem}
%\item[--] Note: Pip by another team of Inria is similar
%\end{compactitem}
%
%\paragraph{sel4}
%%
%\begin{compactitem}
%\item[--] ``First operating-system kernel with an end-to-end proof of
%  implementation correctness and security enforcement''
%\end{compactitem}
%
%\paragraph{CertiKOS}
%%
%\begin{compactitem}
%\item[--] Implemented in Coq the proof assistant
%\item[--] Target is CompCert AST for proof correspondance
%\item[--] Part of the DeepSpec project, whose purpose is to connect system of
%  proofs, from high level specifications to concrete implementations
%\item[--] Hardware model is relatively simple, but has been completed by XX in
%  order to take interrupt into account
%\end{compactitem}
%
%\subsection{Generic Software Specification Correctness}
%
%\paragraph{RockSalt}\,\cite{morrisett2012rocksalt}
%%
%\begin{compactitem}
%\item[--] Implementing SFI at a software level, that is verifying at load time
%  that a given arbitrary application is correctly sandboxed
%\item[--] Four step contribution
%  \begin{compactenum}
%  \item Modelling of the x86 ISA, model validation
%  \item Definition of software rules/guidelines
%  \item Proof that these rules enforces SFI
%  \item Extraction of the verified verifier
%  \end{compactenum}
%\end{compactitem}
%
%\paragraph{Moat}\,\cite{sinha2015moat}
%%
%\begin{compactitem}
%\item[--] The goal is to verify SGX1 specification, which partly includes
%  specifying software guidelines
%\item[--] Once again, the hardware model is pretty simple, but this can be
%  justified by the fact that the SGX trusted computing base is supposedly very
%  small (CPU only)
%\end{compactitem}
%
%\section{Hardware Component Verification} % ====================================
%\label{sec:relatedwork:hardware}
%
%\begin{compactitem}
%\item[--] In the previous section, the hardware model are often very simplified.
%\item[--] In the previous Chapter, we have explained in depth why such approach
%  is not enough.
%\item[--] These simplified hardware model are actually as many hypotheses to
%  latter verify.
%\item[--] To the best of our knowledge, there is no comprehensive formal
%  model/specification in terms of hardware components.
%\end{compactitem}
%
%\subsection{Formal Specification of CPU Architectures}
%
%\begin{compactitem}
%\item[--] The CPU is the main hardware component of a hardware architecture,
%  because it executes the main software stack
%\item[--] It should not be forgotten that it is not the only ``important'', or
%  ``privileged'' component.
%\end{compactitem}
%
%\paragraph{Intel}
%%
%\begin{compactitem}
%\item[--] Core Execution Cluster\,\cite{kaivola2009formalintel}
%\item[--] SGX\,\cite{leslie2015sgx}
%\item[--] The work seems unrelated, in terms of model, that is Intel is not
%  building a single, unified model for its architecture
%\end{compactitem}
%
%\paragraph{ARM}
%%
%\begin{compactitem}
%\item[--] Executable specification for ARM ISA
%\item[--] Several research projects for several versions of ARM
%  \begin{compactitem}
%  \item[--] v7\,\cite{fox2010armv7}
%  \item[--] v8\,\cite{reid2016armv8}
%  \end{compactitem}
%\end{compactitem}
%
%\paragraph{LEON3}
%%
%\begin{compactitem}
%\item[--] Formal Methods 2016
%\end{compactitem}
%
%\paragraph{XOM}
%%
%\begin{compactitem}
%\item[--] Security-focused architecture
%\item[--] Contrary to HSE mechanisms, the CPU alone implements a security policy
%\item[--] XOM\,\cite{lie2003xom}
%\item[--] Model checking, simplified ``rest of the system''
%\end{compactitem}
%
%\subsection{Verified Hardware Components}
%
%\begin{compactitem}
%\item[--] Cite Kami arguments here about use of formal methods in hardware
%  industry in general.
%\end{compactitem}
%
%\begin{compactitem}
%\item[--] Coquet\,\cite{braibant2011coquet}, is too much ``low-level''
%\item[--] Use Kami\,\cite{choi2017kami} as a transition for the next section
%\end{compactitem}
%
%\section{Formal Verification of Inter-connected Components} % ==================
%\label{sec:relatedwork:modular}
%
%\begin{compactitem}
%\item[--] Regarding the scale of our self-assigned task, modular verification is
%  a ``must-have'' (probably use the wording of the FreeSpec for introducing
%  here)
%\end{compactitem}
%
%\subsection{Interface Automata}
%
%\begin{compactitem}
%\item[--] Compared to regular automata, interface automata produce a result for
%  each (labeled) transition
%\item[--] The notion of contracts exist in this field
%\item[--] TODO: organize the papers
%\end{compactitem}
%
%\subsection{Program With Effects}
%
%\begin{compactitem}
%\item[--] This is reminiscent to the problematic language of large program with
%  effects
%\item[--] Alloy\,\cite{jackson2012alloy} is a very good example of what we want
%  to achieve
%\item[--] Frama-C and co. allows for modular reasoning, but there is still no
%  mature solution for reasoning for ``external effects'' (from the application
%  point of view), \emph{e.g.} system calls
%\item[--] Ynot suffers the same properties and limitation
%\item[--] Guillaume Claret allows for reasoning about program behaviour
%  according to certain hypothesis about the ``outer environment'', but not to
%  verify the latter
%\end{compactitem}
