%!TEX root = ../main.tex
\chapter{State of the Art of Formal Verification}
\label{chapter:relatedwork}

\endquote{``\emph{We build our computers the way we build our cities: over time,
    without a plan, on top of ruins.}''

  \hfill\footnotesize --- Ellen Ullman}

\vspace{1cm}\noindent
%
Formal verification consists of proving the correctness of a system ---the
\emph{implementation}--- with respect to certain properties.
%
To that end, a verifier
%
\begin{inparaenum}[(1)]
\item defines a formal description of the system ---the \emph{specification}---,
  %
\item exhibits a proof that a specification satisfies a statement (defined in an
  arbitrary logic) which encodes the property with respect to which the
  correctness shall be proven, and
  %
\item exhibits a proof of correspondence between the implementation and the
  specification.
\end{inparaenum}
%
In this context, the terms ``implementation'' and ``specification'' refer to a
subjective relation between two layers of abstraction: the specification is more
abstract than its implementation, and formal verification proofs can be
organized in an arbitrary number of abstraction layers.
%
The definition of a specification shall ease the construction of the proof of
correctness, while the correspondence proof allows for extending the properties
of the specification to the implementation.
%
The instantiation of the terms ``formal description,’’ ``correspondence proof,’’
``properties'' or ``correctness proof'' may considerably vary from one system to
another.
%
Similarly, the nature of the proofs and their construction greatly depend on the
tools used by the verifier.
%
For our part, we want to construct correctness proofs of a hardware architecture
specification, with respect to security properties, using the Coq theorem prover
(as explained in Chapter~\ref{chapter:introduction}).

The rest of this Chapter proceeds as follows.
%
First, we describe how transition systems can be leveraged in order to implement
the verification methodology we just described
(Section~\ref{sec:sota:formalisms}).
%
Then, we introduce the compositional verification approach, which enables the
``divide and conquer'' strategy to reduce the burden of verifying large and
complex systems (Section~\ref{section:sota:compsec}).
%
We conclude this Chapter by positioning our contributions with respect to
preceding research projects (Section~\ref{sec:sota:conclusion}).

\section{Formal Verification of Transition Systems}
\label{sec:sota:formalisms}

Transition systems have long been used to study the behavior of discrete
systems.
%
Over times, many different definitions of transition system have been
proposed, to address different classes of verification problems.
%
In this Section, we do not attempt to give a comprehensive overview of these
approaches.
%
On the contrary, we explain how a system can be specified using a generic
transition system (\ref{subsec:sota:ltsdef}).
%
We introduce the key concepts of formal methods which support the formal
verification process by providing tools to construct proofs
(\ref{subsec:sota:fm}).
%
Then, we focus on characterizing security policies in terms of properties of
transition systems (\ref{sec:sota:security}).
%
Finally, we describe how the concepts of this section have been used in order to
verify hardware and software systems (\ref{subsec:sota:ltsrelated}).

\subsection{Defining Specifications}
\label{subsec:sota:ltsdef}

The formal verification of discrete systems, such as computing systems, commonly
rely on some sort of \emph{transition systems} to describe the behavior of the
target.
%
More precisely, the system is characterized by a set of \emph{states} and by a
set of \emph{atomic} state transformation, called \emph{transitions}.
%
Transitions occur when the system interacts with its environment (\emph{e.g.} a
hardware circuit receives a clock signal, a hardware controller receives a
message from a bus, an operating system handles a syscall).

\emph{Labeled} transition systems distinguish between classes of transitions
\emph{via} the use of labels (\emph{e.g.} one label per syscall).
%
To the best of our knowledge, the more straightforward definition of a labeled
transition system, as used by Vijayaraghavan \emph{et al.} in their work on
modular verification of multiprocessor hardware
designs\,\cite{vijayaraghavan2015modular}, is a tuple
\( \langle S, L, R \rangle \), such that \( S \) is a set of states, \( L \) is
a set of labels, and \( R \subseteq S \times L \times S \) is the transition
relation.
%
In addition, there is often a subset of states which identifies acceptable
initial states.

\begin{example}[Airlock System]
  \label{example:sota:airlocklts}
  Figure~\ref{fig:sota:airlock-lts} illustrates an instantiation of this
  definition for a simple airlock system.
  %
  An airlock system is a device made of two doors, and an intermediary chamber.
  %
  To get across an airlock system, a user requests the opening of the first door,
  enters the chamber, waits for the system to close the first door and open the
  second door, and exits the chamber.

  \begin{itemize}
  \item A door of the system can be either \( \mathtt{open} \) or
    \( \mathtt{close} \).
    %
    The set of states of the airlock system reflects the combinatronics of the
    doors states.
  \item A transition is characterized by the opening (\( \mathtt{Open}_i\), with
    \( i \in \{1, 2\} \)) and closing (\( \mathtt{Close}_i \), with
    \( i \in \{1, 2\} \)) of a door of the system.
    %
  \item The system does not allow the simultaneous opening of both doors, as
    stated by the definition of \( R \) which does not contain a transition
    which leads to the state \( (\mathtt{open}, \mathtt{open}) \).
  \end{itemize}
\end{example}

\begin{figure}
  \begin{center}
    % the mathematical definition
    \begin{minipage}[c]{0.55\linewidth}
      \[
        \begin{array}{rcl}
          S & \triangleq & \{ \mathtt{open}, \mathtt{close} \}^2 \\
          L & \triangleq & \{ \mathtt{Open}_1, \mathtt{Close}_1, \mathtt{Open}_2,
                           \mathtt{Close}_2 \} \\
          R & \triangleq & \{ (\mathtt{close}, \mathtt{close}), \mathtt{Open_1},
                           (\mathtt{open}, \mathtt{close}), \\
            & & \ (\mathtt{close}, \mathtt{close}), \mathtt{Open_2},
                (\mathtt{close}, \mathtt{open}), \\
            & & \ (\mathtt{open}, \mathtt{close}), \mathtt{Close_1},
                (\mathtt{close}, \mathtt{close}), \\
            & & \ (\mathtt{close}, \mathtt{open}), \mathtt{Close_2},
                (\mathtt{close}, \mathtt{close}) \}
        \end{array}
      \]
    \end{minipage}
    \hfill
    % a tikzpicture to illustrate the resulting automata
    \begin{minipage}[c]{0.40\linewidth}
      \begin{center}
        \begin{tikzpicture}
          \node [draw, circle split, text width=30pt, text badly centered] (cc)
          {\( \mathtt{close} \) \nodepart{lower} \( \mathtt{close} \)};%
          \node [right=of cc] (x) {};%
          \node [draw, circle split, above=of x, text width=30pt, text badly
          centered] (oc) {\( \mathtt{open} \) \nodepart{lower}
            \( \mathtt{close} \)};%
          \node [draw, circle split, below=of x, text width=30pt, text badly
          centered] (co) {\( \mathtt{close} \) \nodepart{lower}
            \( \mathtt{open} \)};%
          \node [draw, circle split, right=of x, text width=30pt, text badly
          centered] (oo) {\( \mathtt{open} \) \nodepart{lower}
            \( \mathtt{open} \)};%

          \draw [-latex] (cc) edge [bend left] node [xshift=-5pt, left]
          {\( \mathtt{Open}_1 \)} (oc);%
          \draw [-latex] (oc) edge [bend left] node [xshift=5pt, right]
          {\( \mathtt{Close}_1 \)} (cc);%

          \draw [-latex] (cc) edge [bend left] node [xshift=5pt, right]
          {\( \mathtt{Open}_2 \)} (co);%
          \draw [-latex] (co) edge [bend left] node [xshift=-5pt, left]
          {\( \mathtt{Close}_2 \)} (cc);%

        \end{tikzpicture}
      \end{center}
    \end{minipage}

    \caption{A simple airlock system modeled as a labeled transition system}
    \label{fig:sota:airlock-lts}
  \end{center}
\end{figure}

There are many modeling structures one can use to characterize transition
systems, with each variant better suited to tackle a particular class of
systems.
%
For instance, the Kripke structure\,\cite{kripke1971semantical} is a notorious
variation of (labeled) transition systems used in model
checking\,\cite{clarke1999model}, while Petri net\,\cite{peterson1981petri},
process algebra\,\cite{bergstra1984process} or interface
automata\,\cite{de2001interface} are better suited to model concurrent systems.

\subsection{Introduction to Formal Methods}
\label{subsec:sota:fm}

In a formal system, formulas (also called
propositions) of a formal language represent statements which can either be true
or false.
%
A formal system relies on a set of axioms, that are formulas known to be true,
and inference rules which allow for deriving new formulas.

\paragraph{Propositions and Inference Rules.}
%
The statement that a proposition \( P \) is true is commonly denoted by
\( \vdash P \).
%
A proposition \( P \) may also be true on the condition that propositions
\( Q_0, Q_1, ..., \text{and} Q_n \) are also true.
%
This statement is denoted by \( Q_0, Q_1, ... Q_n \vdash P \).
%
A statement is proven true when it is part of the base of axioms or we use
inference rules to derive already proven statements.
%
By doing so, we construct a \emph{proof}.
%
For example, a notorious inference rule is the \emph{Modus ponens}, which states
that if a proposition \( P \) is true, and the proposition \( P \Rightarrow Q \)
is also true, then the proposition \( Q \) is true, that is
%
\[
  P\text{, }(P \Rightarrow Q) \vdash Q
\]
%
Using the \emph{Modus ponens}, it becomes possible to construct a proof of
\( \vdash Q \) from a proof of \( \vdash P \) and a proof of
\( \vdash P \Rightarrow Q \).
%
Figure~\ref{fig:sota:inference} gives a l list of common inference rules.
%
Conditional statements, once proven, become new inference rules to be used to
construct proofs.

Formally constructing a proof can quickly become cumbersome as propositions
become more complex.
%
They can be described in the form of carefully worded sentences.
%
Another popular approach is to write them as so-called proof trees.
%
Each node of the tree is a proof obligation.
%
The children of a given proof obligation or proofs which allows for concluding
about the node goal, by using an inference rule of the system.
%
By convention, a node goal and its children are separated by a line labeled with
the name of the inference rule.
%
The leaves of the trees are the statement known to be true, either because they
are part of the system axioms or because they have already been proven before.
%
Therefore, a proof which only consists in applying the \emph{Modus ponen} can be
represented as follows:
%
\begin{prooftree}
  \AxiomC{\( P \)} \AxiomC{\( P \Rightarrow Q \)} \RightLabel{\small {\scshape
      Modus Ponens}} \BinaryInfC{\( Q \)}
\end{prooftree}

\begin{figure}
  \begin{center}
    \begin{tabular}{ll}
      {\scshape Modus ponens} & \( P \Rightarrow Q\text{, }P \vdash Q \) \\
      {\scshape Modus tollens} &
                                 \( P \Rightarrow Q\text{, }\neg Q \vdash \neg P \) \\
      {\scshape Conjunction:} & \( P\text{, }Q \vdash P \wedge Q \) \\
      {\scshape Addition:} & \( P \vdash P \vee Q \) \\
      {\scshape Contradiction:} & \( P, \neg P \vdash Q \)
    \end{tabular}
  \end{center}

  \caption{List of common inference rules}
  \label{fig:sota:inference}
\end{figure}

Constructing a proof and verifying its correctness quickly becomes challenging.
%
Theorem provers such as Coq\,\cite{coq} or
Isabelle/HOL\,\cite{nipkow2002isabelle} provide facilities to write proofs, and
verify these proofs (supposedly in a more reliable way than humans).
%
Therefore, the quality of a theorem prover is measured by its capacity to reject
ill-formed proofs.
%
To avoid this pitfall, modern theorem provers are built as ``certified'' layers
around a certification as small and simple as possible.
%
The idea is that, as long as the kernel does not contain a bug, advanced
features implemented inside a certified layer cannot introduce inconsistency in
the proof-checking process.
%
This greatly diminishes the risk to have inconsistencies in the proof checker,
although this happened in the
past\,\cite{claret2015falso,griffioen1998comparison}.

Another common approach is to rely on an algorithm whose correctness has been
formally established to handle a well-defined class of problem.
%
This allows for automating the verification process.
%
Once the algorithm has been proven correct, it becomes possible to trust its
output.
%
Abstract interpretation\,\cite{cousot1977absint} and model
checking\,\cite{clarke2018modelc} are two notorious instances of this approach.

\paragraph{Formal Systems.}
%
Choosing a formal language is a key part of the verification process of a
system.
%
It decides the expressiveness of the statements that can be proven, and the
tools verifiers can leverage to construct their proofs.

The most common formal system is the first-order logic\,\cite{smullyan2012fol},
characterized by:
%
\begin{itemize}
\item \emph{Terms}, which represents objects.
\item \emph{Logical operators}, such as conjunction \( \wedge \), disjunction
  \( \vee \), implication \( \Rightarrow \), negation \( \neg \).
\item \emph{Predicates}, that is parameterized formulas that can be true or
  false with respect to the applied terms.
\item \emph{Quantifiers}, such as \( \forall \) (all values) or \( \exists \)
  (there exists a value).
\end{itemize}

First-order logic quantifiers can only be applied on sets of terms (\emph{e.g.}
natural numbers, booleans, states of a airlock system).
%
Higher-order logic\,\cite{leivant1994hol} does not suffer the same limitation,
so it becomes possible to express statements such as \emph{for all sets with a
  total order \( < \), for all pair of values \( \alpha, \beta \), then either
  \( \alpha < \beta \) or \( \beta < \alpha \) or \( \alpha = \beta \)}.
%
Therefore, higher order logic is more expressive than first-order logic, but
it comes at a cost in terms of automation.
%
On the one hand, \emph{interactive} theorem provers (\emph{e.g.}  Coq,
Isabelle/HOL, or more recently Lean\,\cite{de2015lean} are based on higher-order
logic.
%
On the other hand, \emph{automated} theorem provers (\emph{e.g.}
Vampire\,\cite{riazanov2002vampire}, Z3\,\cite{de2008z3}) are based on
first-order logic.

Finally, modal logic\,\cite{chagrov1997modal} is a formal system which extends
first-order logic with modal operators.
%
Temporal logic forms the most popular family of modal logic, such as Temporal
Linear Logic (LTL)\,\cite{sistla1985ltl}.
%
They allow for reasoning about propositions over time.
%
Examples of LTL modular operators are \( \square P \) (\( P \) is always true),
\( \Diamond P \) (\( P \) will eventually become true), \( \bigcirc P \)
(\( P \) will be true after the next transition of the system).
%
Another popular temporal logic is Computation Logic Tree
(CTL)\,\cite{clarke1981ctl}, which considers trees of possible futures (by
opposition to a \emph{linear} future).
%
CTL modal operator includes \( \mathbf{A} P \) (\( P \) is true for all possible
futures) and \( \mathbf{E} P \) (there exists at least one path where \( P \)
becomes true).
%
Temporal logic formulas are commonly verified thanks to model checkers,
\emph{e.g.}  NuSMV\,\cite{cimatti2002nusmv}, SPIN\,\cite{holzmann1997spin} or
TLA+\,\cite{lamport2002tla}.
%
Other approaches can be used to that end ---for instance Gilles Barthe \emph{et
  al.} have encoded \( \square \) and \( \Diamond \) in
Coq\,\cite{barthe2011virtcert1}--- yet model checkers have the benefit of
automation and counter-example generation.

\subsection{Specifying Security Policies}
\label{sec:sota:security}

The verification a system is \emph{always} relative to certain properties (in
our case, the correct enforcement of a security policy).
%
The definition of a specification of the system to allow for formally reasoning
about its behavior is a key step in the verification process.
%
The formalization of the targeted property is as important, if not more.
%
Indeed, the challenge posed by a potential gap between an implementation and its
specification can be abated by an appropriate correspondence proof.
%
As for the targeted properties, a gap between its characterization using a
particular logic and its semantics should not be understated.
%
For instance, Mathy Vanhoef \emph{et al.} disclosed a critical vulnerability
(KRACK) targeting the WPA2 protocol\,\cite{vanhoef2017key}, despite previous
formal verification results (\emph{e.g.} \cite{he2004analysis}).
%
The reason remains simple: KRACK does not violate the security properties proven
in the formal analysis of the protocol, only these security properties were not
strong enough.

The theory of properties of a transition system is now well understood, with an
intuitive classification of properties, such that:
%
\begin{itemize}
\item \emph{Safety properties}\,\cite{lamport1977proving,lamport1985logical}
  characterize that nothing ``bad'' shall \emph{never} happen.
\item \emph{Liveness properties}\,\cite{lamport1985logical,alpern1985liveness}
  characterize that something ``good'' shall \emph{eventually} happen.
\end{itemize}

We discussed in Subsection~\ref{subsec:usecase:targetedsec} the two classes of
security policies commonly targeted by x86 \ac{hse} mechanisms.
%
An access control policy is a safety property: unauthorized action by a
subject shall never happen.
%
An availability policy is a liveness property: the system shall eventually
satisfy the service

Safety and liveness properties are expressed against the transition systems
\emph{traces}.
%
The most generic definition of a trace of a transition system is a (potentially
infinite) sequence of states generated by successive transitions.
%
Each modeling structure has its own definition of traces, which takes into
account the specificities of the model.
%
For instance, traces labeled transition system will interleave a label between
each state\,\cite{vijayaraghavan2015modular}, to characterize the nature of the
transition which led to the transformation of a state of the sequence with its
successor.
%
Afterwards, we write \( \Sigma(M) \) for the set of traces of a specification
\( M \).

Simplest properties can be defined in terms of predicates on
traces\,\cite{alpern1987recognizing,schneider2000enforceable,basin2013enforceable}.
%
We assume a specification \( M \) whose set of states is \( S \) and whose
traces only contain states.
%
\( M \) is said to be correct with respect to a property modeled as a predicate
of traces \( P \) when,
%
\[
  \forall \rho \in \Sigma(M), P(\rho).
\]

On the one hand, safety properties are characterized by an invariant \( \iota \)
on trace elements (\emph{i.e.} on \( S \) in the case of the specification
\( M \)), and
%
\[
  P(\rho) \triangleq \iota(\rho_0) \wedge P(\rho_{[1..]}),
\]
%
where \( \rho_0 \) is the first element of the trace, and \( \rho_{[1..]} \) is
the trace obtained by removing the first element of \( \rho \).
%
On the other hand, liveness properties are characterized by a predicate
\( \eta \) on trace which has to be satisfied for at least a subtrace, that is
%
\[
  P(\rho) \triangleq \exists n > 0, \eta(\rho_{[..n]}) \vee P(\rho_{[1..]}),
\]
%
where \( \rho_{[..n]} \) is the substrace made with the \( n \) first elements
of \( \rho \).

\begin{example}[Airlock Safety and Liveness Properties]
  A typical \emph{safety} property (nothing `bad'' happens) for an airlock
  system is that at least one door shall be close at any time.
  %
  We formalize this property with the invariant \( \iota \), defined as follows:
  %
  \[
    \iota( d_1, d_2) \triangleq d_1 = \mathtt{close} \vee d_2 = \mathtt{close}
  \]
  %
  The specification of the airlock system is defined with a labeled transition
  system.
  %
  Assuming the airlock device is initialized in a correct state (\emph{e.g.}
  both doors are close), we verify this specification is correct with respect to
  the safety property characterized by \( \iota \) by exhibiting a proof that
  \( \iota \) is an invariant with respect to \( R \), that is
  %
  \[
    \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \iota(d_1, d_2) \Rightarrow
    \iota(d_1', d_2')
  \]
  %
  Such a proof is given in Figure~\ref{fig:sota:proofsafety}.

  In addition, we can also prove that both doors of the airlock will
  \emph{eventually} be close.
  %
  We can characterize this liveness property with the predicate \( \eta \) on
  subtraces of one element, such that
  %
  \[
    \eta(d_1, d_2) \triangleq d_1 = \mathtt{close} \wedge d_2 = \mathtt{close}
  \]
  %
  We verify the specification of the airlock system is correct with respect to
  the liveness property characterized by \( \eta \) by exhibiting a proof that
  for each transition of \( R \), one of the states satisfies \( \eta \), that is
  %
  \[
    \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \eta(d_1, d_2) \vee \eta(d_1',
    d_2')
  \]

\end{example}

\begin{figure}
  \bigcentering%
  {\footnotesize \AxiomC{} \RightLabel{\footnotesize
      \( \vee,\Rightarrow \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{close} = \mathtt{close} \\
        \vee \mathtt{close} = \mathtt{close}) \\
        \Rightarrow (\mathtt{open} = \mathtt{close} \\
        \qquad \vee \mathtt{close} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{close}, \mathtt{close}) \\
        \Rightarrow
        \iota(\mathtt{open}, \mathtt{close})
      \end{array} \)}%
    \AxiomC{}
    \RightLabel{\footnotesize \( \vee,\Rightarrow \){\scshape -Def}}
    \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{close} = \mathtt{close} \\
        \vee \mathtt{close} = \mathtt{close}) \\
        \Rightarrow (\mathtt{close} = \mathtt{close} \\
        \qquad \vee \mathtt{open} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{close}, \mathtt{close}) \\
        \Rightarrow
        \iota(\mathtt{close}, \mathtt{open})
      \end{array} \)}%
    \AxiomC{}
    \RightLabel{\footnotesize \( \vee,\Rightarrow \){\scshape -Def}}
    \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{open} = \mathtt{close} \\
        \vee \mathtt{close} = \mathtt{close}) \\
        \Rightarrow (\mathtt{close} = \mathtt{close} \\
        \qquad \vee \mathtt{close} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{open}, \mathtt{close}) \\
        \Rightarrow
        \iota(\mathtt{close}, \mathtt{close})
      \end{array} \)}%
    \AxiomC{See \( \square \)}
    \RightLabel{\footnotesize \( R \){\scshape -Def}}
    \QuaternaryInfC{\( \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \iota(d_1,
      d_2) \Rightarrow \iota(d_1', d_2') \)}%
    \DisplayProof}

  \vspace{2em}

  {\footnotesize \AxiomC{} \RightLabel{\footnotesize
      \( \vee,\Rightarrow \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{close} = \mathtt{close} \\
        \vee \mathtt{open} = \mathtt{close}) \\
        \Rightarrow (\mathtt{close} = \mathtt{close} \\
        \qquad \vee \mathtt{close} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{close}, \mathtt{open}) \\
        \Rightarrow
        \iota(\mathtt{close}, \mathtt{close})
      \end{array} \)}%
    \UnaryInfC{\( \square \)}
    \DisplayProof}

  \caption{Airlock system proof of correctness with respect to a safety
    property}
  \label{fig:sota:proofsafety}
\end{figure}

Not all security policies can be formalized with predicates on traces.
%
For instance, \emph{noninterference}\,\cite{goguen1982security} is a confidentiality policy
which requires that so-called public inputs handled by a given system always
produce the same output, regardless of concurrent secret inputs.
%
In this context, considering each trace independently does not make sense.
%
To witness a violation of the security policy requires to compare two traces
together.
%
Such properties are called \emph{hyperproperties}\,\cite{marr2002hypertheading},
and are characterized by sets of sets of traces.
%
Verifying a system with respect to a hyperproperty is harder in the general
case, but certain hyperproperties, called \( k \)-safety properties, can be
reduced to an invariant.
%
For instance, we assume \( M \) handles inputs which can be either secret or
public.
%
Let \( \equiv \) be the binary relation, such that two states \( s \) and
\( r \) satisfies this relation (\( s \equiv r \)) when they characterize two
instances of the system which have handled the same public inputs and produced
the same visible behavior.
%
Similarly to Gilles Barthe \emph{et al.}\,\cite{barthe2011virtcert1}, we can
prove \( M \) enforces noninterference if for any
public input \( l \) by constructing a proof that
%
\[
  \forall (s, r) \in S \times S, s \equiv r \Rightarrow (s \xrightarrow{l} s'
  \wedge r \xrightarrow{l} r') \Rightarrow s' \equiv r',
\]
where \( s \xrightarrow{l} s' \) is a transition of the system from a state
\( s \) to a state \( s' \) to handle the input \( l \).

% \subsection{Adversary Model}
%
% An \emph{adversary model} (or \emph{threat model}) characterizes what
% attackers can and cannot do inside a system.
%%
% Security guarantees shall always be defined with respect to a certain
% adversary model, to define the limits of the system security enforcement
% mechanisms.
%%
% That is, attackers which can leverage capabilities outside of the adversary
% model are likely to defeat the security policies.
%%
% Adversary model is a theoretical tool commonly used in the verification of
% cryptographic protocol, with a well-identified hierarchy of archetypes
% (\emph{e.g.} the Dolev–Yao model allows attackers to intercept, modify,
% generate any messages, but require necessary secret to encrypt and decrypt
% messages\,\thomasrk{ref}).

% \begin{itemize}
% \item Combinatronics of system actions (Pip, VirtCert)
% \item Additional rule to model more powerful attacker (Moat, XOM + bus
%   snooping)
% \end{itemize}

\subsection{Related Works}
\label{subsec:sota:ltsrelated}

Formal verification of hardware and software systems is a large and prolific
research field, with important applications in the industry.
%
The interest has grown in the use of formal methods to improve the security of
computer systems\,\cite{chong2016report}.
%
We give an overview of formal verification projects which
%
\begin{inparaenum}[(1)]
\item have a clear focus on security, and
\item target two domains related to \ac{hse} mechanisms, that is hardware
  architectures, and system software components.
\end{inparaenum}
%
For each project, we detail the modeling structure used to define the
specification of the targeted system, the verified properties and the
verification approach leveraged by the authors.

\paragraph{XOM.}
%
The \ac{xom} microprocessor architecture maintains separate so-called
\emph{compartments} for applications\,\cite{lie2000architectural}.
%
With mainstream microprocessor architectures, the system software is responsible
for both memory allocation and access control.
%
To do so, it implements one or more \ac{hse} mechanisms, which make use of
hardware features such as a \ac{mmu}.
%
On the contrary, a \ac{xom} \ac{cpu} keeps track of each memory location owner,
thanks to a tagging mechanism, and supposedly prevents an application to access
a memory location it does not own.
%
In 2003, David Lie \emph{et al.} have verified the \ac{xom}
architecture\,\cite{lie2003xom} using the Mur$\varphi$ model
checker\,\cite{murphi}.
%
The verification goal of the authors was to prove that the \ac{xom}
architecture fulfills its promise to be tamper-resistant, that is the
architecture forbids an attacker to modify the memory location owned by a given
application.
%
The verification proceeds as follows:
%
\begin{enumerate}
\item A first specification of the \ac{xom} architecture, called the ``actual
  model'', is defined.
  %
  States of this first model contain different hardware components of a
  \ac{xom} microprocessor, \emph{i.e.} registers, cache and volatile
  memory.
  %
  It also integrates the internal machinery of \ac{xom} to track ownership of
  memory locations.
  %
  Transitions can be divided into two categories: the normal execution of an
  application by the microprocessor, and active tampering from an adversary
  part.
  %
  That is, the actual model embeds a notion of adversary model.
  %
\item A second specification, called the ``idealized model'', abstracts away the
  memory hierarchy formed by the cache and the volatile memory.
  %
  This second model captures the execution of a single application, without an
  adversary.
  %
  From this perspective, it encodes the security property.
  %
\item To let Mur\( \varphi \) explore both models simultaneously, the authors
  have manually defined a third model.
  %
  Transitions which describe the execution of an application in the actual
  model also update the idealized model, whereas transitions which describe
  actions by the attacker only affect the actual model.
  %
\item The authors have defined a function which checks if an ``actual state'' is
  equivalent to an ``idealized state'', and let Mur\( \varphi \) verify that
  the state equivalence is an invariant of the third model.
\end{enumerate}
%
In the process of verifying \ac{xom}, the authors have been able to show with
their model that the \ac{xom} architecture was subject to several replay
attacks, and that their countermeasures were effectively effective.
%
However, the state explosion problem obliges the authors to simplify their
model, in order to reduce the state combinatory.

\paragraph{ARMv8.}
%
ARM Specification Language
%
\thomasrk[inline]{TODO}

\paragraph{VirtCert.}
%
Between 2011 and 2014, Gilles Barthe \emph{et al.} have worked on an idealized
model of a hypervisor.
%
This model is defined in terms of state, actions and the semantics of actions as
state trans\-formers.
%
The state mixes information about both hardware components (\ac{cpu} execution
mode, registers, memory content, etc.) and software components (list of guests,
the current active guest, memory mapping for the hypervisor and the guests, etc.).
%
The set of actions describes the events which can trigger a transformation of
the model states.
%
For instance, it includes various tasks that the hypervisor must carry out, such
as scheduling the OS guests, hypercalls handling, or memory management.
%
Certain actions also witness the execution of guests, for instance when the OS
currently running reads from or writes to memory.
%
The semantics of actions as state transformers, which describes the set of
possible transitions for the model, is defined in terms of pre and
postconditions, where
%
\begin{enumerate}
\item A precondition \( \mathrm{Pre} \) is a predicate on state and action, such
  that for a couple \( (s, a) \), if the precondition holds true, then the
  action \( a \) can occur from the state \( s \)
\item A postcondition \( \mathrm{Post} \) is a predicate on state, action and
  state, such that for a tuple \( (s, a, s') \), if the postcondition holds
  true, then the model state is updated from \( s \) to \( s' \) after an action
  \( a \).
\end{enumerate}
%
This means \( (s, a, s') \) is a transition of the model if and only if
%
\[
  \mathrm{Pre}(s, a) \wedge \mathrm{Post}(s, a, s')
\]

They implemented their model and their proofs in the Coq theorem prover.
%
First, they showed that the ideal hypervisor
%
\begin{inparaenum}[(1)]
\item ensures strong isolation between guests (two safety properties and
  2-safety property), and
%
\item eventually processes every request performed by the guests (one liveness
  property)\,\cite{barthe2011virtcert1}.
\end{inparaenum}
%
Then, they incorporated the \ac{cpu} cache to their hardware model, and a naive
countermeasure for preventing cache-timing attack to their hypervisor model.
%
They proved the effectiveness of the countermeasure\,\cite{barthe2012virtcert2}.
%
The authors have shown their ideal hypervisor could prevent such attack, at the
cost of flushing the cache before each context switch.
%
Finally, they have taken their approach a step further, by focusing on
constant-time cryptography as an effective countermeasure against cache-timing
attack\,\cite{barthe2014virtcert3}.
%
This last work also introduced a static analysis for C program, notably
implemented as an extension for CompCert, a certified C
compiler\,\cite{leroy2012compcert}.

The resulting project, called VirtCert, is fairly large.
%
The Coq development counts over 50\,000 lines of code.
%
The verification results focus on various isolation properties, from the most
natural and straightforward (\emph{i.e.} an OS guest cannot write to or read
from a page it does not own) up to non-interference variants, notoriously harder
to reason with.

\paragraph{seL4.}
%
Certified microkernel.
%
\thomasrk[inline]{TODO}

\paragraph{RockSalt.}
%
Thanks to the Google service called \ac{nacl}, it is possible for software
developers to distribute their web applications in the form of native executable
code.
%
These native applications are executed directly in the context of the browser.
%
\ac{nacl} uses \ac{sfi} to prevent arbitrary native applications to tamper with
the code and data of the browser.
%
\ac{sfi} comprises a set of rules native applications have to comply with, and
that together form a sandbox policy.
%
In practice, the \ac{nacl} checks that an arbitrary native applications respect
the \ac{sfi} rules before loading it to the browser context.
%
As a consequence, the browser is protected from malicious machine code.

From a security perspective, this means there are two requirements over the
\ac{nacl}:
%
\begin{inparaenum}[(1)]
\item verify that the rules indeed are sufficient to constrain the distrusted
  native applications with respect to the sandbox policy, and
%
\item the \ac{nacl} checker correctly verify that native applications respect
  these rules.
\end{inparaenum}
%
This is similar to the challenges faced by \ac{hse} mechanisms.
%
Because \ac{nacl} has been shown to have issues regarding these two
requirements, Greg Morrisett \emph{et al.} have specified the \ac{nacl} checker
in Coq, proven the rules it checks are correct and indeed enforce the targeted
sandbox policy, and then manually translated the checker in
C\,\cite{morrisett2012rocksalt}.
%
By doing so, they have addressed the two requirements listed above, as long as
their translation is correct.

\paragraph{Moat.}
%
Intel \ac{sgx} is a recent addition to certain x86 \acp{cpu}, whose purpose is
to provide so-called enclaves to user land
applications\,\cite{costan2016sgxexplained}.
%
These enclaves supposedly offer an execution environment isolated from the
system software.
%
The functioning of \ac{sgx} can be roughly summarized as follows:
\ac{sgx}-capable \acp{cpu} dedicate a special portion of the system memory, called
the \ac{epc}, to enclaves.
%
The system software is responsible for allocating and initializing memory pages
of the \ac{epc} (thanks to dedicated instructions), but it cannot read or write
to them once it is done.
%
This is enforced by the memory controller, which encrypts the content of the
\ac{epc} transparently from the \ac{cpu}.
%
Hence, the memory controller only decrypts an \ac{epc}'s page if it is accessed
by the enclave which owns it; it will also discard write accesses performed by
another software component than the page owner.

Rohit Sinha \emph{et al.} have modeled SGX instructions semantics, to complete
an existing model, and have developed an automated information flow analysis
tool called Moat, to verify whether or not a given application code may leak
secrets or not\,\cite{sinha2015moat}.
%
The work proceeds similarly to RockSalt, where instructions are treated as
labeled transition from one state to another.
%
However, Moat also consider an active and passive adversary, with additional
capabilities (meaning, additional transitions in the system).
%
The approach is similar to what David Lie \emph{et al.} have done for the
\ac{xom} architecture.

\section{Compositional Verification}
\label{section:sota:compsec}

Traditional transition systems, such as the ones presented in the previous
section, impose to model the complete system all at once.
%
This raises important challenges for complex systems.
%
Model checkers and similar automated tools remain subject to the so-called
\emph{state explosion problem}\,\cite{clarke2012model} despite improvements to
algorithms.
%
State explosion problem imposes modeling compromises, \emph{e.g.}  verification
of cache coherency protocols with a fixed number of cores and address spaces
limited in size (\emph{e.g.} in \cite{lie2003xom}, the model only considers
three cache locations).
%
Theorem provers allow for modeling \emph{parameterized} systems, so that it
becomes possible, for example, to construct a proof which holds for an arbitrary
number of similar components\,\cite{vijayaraghavan2015modular}.
%
This approach does not address all the challenges posed by the scale of complete
hardware architectures, built up from smaller ---yet complex--- components.
%
A comprehensive hardware model in terms of hardware components would undoubtedly
make the construction of the proof unbearable for any non-trivial properties,
yet is a requirement to uncover compositional attacks by the means of formal
methods.

Compositional verification is a promising (family of) approach(es) to overcome
the challenges posed by the scale of complex and large systems.
%
In this approach, the verification work is divided into two steps.
%
First, each component is verified in isolation.
%
Then, the composition of these components in order to ensure it does not create
compositional attacks.
%
This requires to use adapted modeling structures when it comes to defining a
specification (\ref{subsec:sota:compmod}).
%
It also requires dedicated verification approaches, which enable ``divide and
conquer'' strategies to reduce the burden of verifying the system
(\ref{subsec:sota:compverif}).

\subsection{Compositional Modeling Structures}
\label{subsec:sota:compmod}

\paragraph{Concurrent Automata.}
%
I/O automata\,\cite{lynch1988ioautomata} are labeled transition systems which
distinguish between three classes of transitions, modeled with three disjoints
sets of labels:
%
\begin{inparaenum}[(1)]
\item input actions (denoted by \( \mathrm{in}(S) \) for an automaton \( S \)),
  %
\item output actions (denoted by \( \mathrm{out}(S) \)), and
  %
\item internal actions (denoted by \( \mathrm{int}(S) \)).
  %
\end{inparaenum}
%
They together form the signature of a given automaton (denoted by
\( \mathrm{act}(S) \)).
%
Its transition relation \( R(S) \) is a subset of
\( \mathrm{state}(S) \times \mathrm{act}(S) \times state(S) \), where
\( \mathrm{state}(S) \) is the set of states of \( S \).
%
I/O automata are expected to be \emph{input enabled}, that is it cannot delay
the treatment of its inputs.
%
This translates as follows: for every state \( p \) and input actions \( \pi \),
it exists a state \( q \) such that \( (p, \pi, q) \in R(S) \).
%
Composition of I/O automaton is achieved \emph{via} input and output actions.
%
More precisely, when one automaton performs an output action \( \pi \) during a
transition, all automata having \( \pi \) as input action perform \( \pi \)
simultaneously.

Although by definition, I/O automata are required to be input enabled, in
practice the component they model will correctly behave (for a certain
definition of ``correct'') only if certain requirements are met regarding the
inputs they have to handle.
%
Interface automata\,\cite{de2001interfaceautomata} are similar to I/O automata,
except they do not require to be input enabled.
%
As a consequence, the definition of an interface automaton captures its
requirements over the rest of the system.
%
Another popular modeling structure is the Moore Machine.
%
Moore Machines play a key role in compositional model
checking\,\cite{mcmillan1989compositional}, because they can be translated into
Kripke structures.

\begin{example}[Airlock System as Interface Automata]
  \label{example:sota:airlockinterface}

  In order to illustrate how a system can be broken down into small component,
  we take once again the example of the airlock system.
  %
  In this context, the most obvious component is the door.
  %
  A door has two states: it can be either open or close.
  %
  It takes two input actions: \( \mathtt{Open} \) (the action to open the door)
  and \( \mathtt{Close} \) (the action to close the door).
  %
  It does not have any output action, which means a door does not interact
  actively with the rest of the system.
  %
  One possible specification for a door can be the following interface
  automaton:

  \begin{center}
    \begin{tikzpicture}
      \node [draw, circle] (o) {1};%
      \node [draw, circle, right=of o] (c) {2};%

      \draw [-latex] (o) edge [bend left] node [above] {\( \mathtt{Open}? \)}
      (c);%
      \draw [-latex] (c) edge [bend left] node [below] {\( \mathtt{Close}? \)}
      (o);%
      \draw [-latex] (c) edge [loop right] node {\( \mathtt{Open}? \)} (c);%
      \draw [-latex] (o) edge [loop left] node {\( \mathtt{Close}? \)} (o);%

      \node [draw, fit=(o) (c), inner sep=20pt, text width=130pt, text badly
      centered] (d1) {};%

      \node [yshift=10pt, left=35pt of d1.west] (open) {};%
      \draw [-latex] (open) to node [above] {\( \mathtt{Open} \)}
      ([yshift=10pt]d1.west);%
      \node [yshift=-10pt, left=35pt of d1] (close) {};%
      \draw [-latex] (close) to node [above] {\( \mathtt{Close} \)}
      ([yshift=-10pt]d1.west);%
    \end{tikzpicture}
  \end{center}

  In addition to two doors, an airlock system needs a controller, whose purpose
  is to handle users' requests and open and close doors in consequence.
  %
  We consider a slightly different situation than the specification given in
  Example~\ref{example:sota:airlocklts}.
  %
  Here, there are only two commands, modeled with two input actions:
  \( \mathtt{Req}_1 \) (one user wants the first door to be opened) and
  \( \mathtt{Req}_2 \) (one user wants the second door to be opened).
  %
  The controller does not embed the states of the doors, but has four output
  actions, two per doors (\( \mathtt{Open}_i \) and \( \mathtt{Close}_i\), for
  \( i \in \{1, 2\}\)).
  %
  We propose the following interface automaton:

  \begin{center}
    \begin{tikzpicture}
      \node [draw, circle] (s1) {2};%
      \node [draw, circle, right=50pt of s1] (s2) {3};%
      \node [draw, circle, right=50pt of s2] (s3) {4};%

      \draw [-latex] (s1) to node [above] {\( \mathtt{Close2}! \)} (s2);%
      \draw [-latex] (s2) to node [above] {\( \mathtt{Open1}! \)} (s3);%

      \node [draw, circle, below=60pt of s3] (s4) {5};%
      \node [draw, circle, left=50pt of s4] (s5) {6};%
      \node [draw, circle, left=50pt of s5] (s6) {7};%

      \draw [-latex] (s4) to node [below] {\( \mathtt{Close1}! \)} (s5);%
      \draw [-latex] (s5) to node [below] {\( \mathtt{Open2}! \)} (s6);%

      \node [draw, circle, below=21pt of s2] (s7) {1};%

      \draw [-latex] (s7) to node [left,yshift=-5pt] {\( \mathtt{Req1}? \)}
      (s1);%
      \draw [-latex] (s7) to node [right,yshift=5pt] {\( \mathtt{Req2}? \)}
      (s4);%

      \draw [-latex] (s3) edge [bend left] node [right] {\( \mathtt{Req2}? \)}
      (s4);%
      \draw [-latex] (s6) edge [bend left] node [left] {\( \mathtt{Req1}? \)}
      (s1);%

      \node [draw, fit=(s1) (s4), inner sep=20pt, text width=220pt] (ctrl) {};%

      \node [yshift=20pt, left=35pt of ctrl] (in_open1) {};%
      \draw [-latex] (in_open1) to node [above] {\( \mathtt{Req}_1 \)}
      ([yshift=20pt]ctrl.west);%
      \node [yshift=-20pt, left=35pt of ctrl] (in_open2) {};%
      \draw [-latex] (in_open2) to node [above] {\( \mathtt{Req}_2 \)}
      ([yshift=-20pt]ctrl.west);%

      \node [yshift=45pt, right=35pt of ctrl] (out_open1) {};%
      \draw [latex-] (out_open1) to node [above] {\( \mathtt{Open}_1 \)}
      ([yshift=45pt]ctrl.east);%
      \node [yshift=15pt, right=35pt of ctrl] (out_close1) {};%
      \draw [latex-] (out_close1) to node [above] {\( \mathtt{Close}_1 \)}
      ([yshift=15pt]ctrl.east);%

      \node [yshift=-15pt, right=35pt of ctrl] (out_open2) {};%
      \draw [latex-] (out_open2) to node [above] {\( \mathtt{Open}_2 \)}
      ([yshift=-15pt]ctrl.east);%
      \node [yshift=-45pt, right=35pt of ctrl] (out_close2) {};%
      \draw [latex-] (out_close2) to node [above] {\( \mathtt{Close}_2 \)}
      ([yshift=-45pt]ctrl.east);%

      \draw (s3) edge [loop right] node {\( \mathtt{Req1}? \)} (s3);%
      \draw (s6) edge [loop left] node {\( \mathtt{Req2}? \)} (s6);%
    \end{tikzpicture}
  \end{center}
\end{example}

\paragraph{Process Algebra.}
%
Another popular family of approaches which enable compositional modeling of
complex systems is process algebra.
%
Process algebra has been developed in order to reason about programs executed
in parallel.
%
It is a formal system to describe interacting systems, together with a semantic
theory for verifying them.
%
In process algebra such as Calculus of Communication
Systems\,\cite{milner1980ccs} or the Communicating Sequential
Processes\,\cite{hoare1978csp}, two concurrent threads can run in parallel, and
synchronization is achieved by sending and waiting for messages rather than
\emph{via} some shared memory.

\begin{example}[Airlock System in \( \pi \)-calculus]
  \label{example:sota:airlockprocess}

  We now try to give a specification of our airlock system using a process
  algebra called \( \pi \)-calculus.
  %
  Once again, we consider three components: two doors and a controller.
  %
  Our objective is to write a specification equivalent to our interface automata
  (although we do not provide a proof of that equivalence).

  We have used the following \( \pi \)-calculus construction to specify the
  airlock system:
  %
  \begin{itemize}
  \item \( c(x). P\) means receiving a value from the channel \( c \), bounding
    this value to the name \( x \), then executing the process \( P \).
  \item \( \bar{c} \langle x \rangle . P \) means sending the value bounded to
    name \( x \) through the channel \( c \), then executing the process
    \( P \).
  \item \( [x = \mathrm{OPEN}] . P \) is a guard, that is \( P \) is executed if
    \( x \) is equal to the value \( \mathrm{OPEN} \).
  \item \( P + Q \) is the nondeterministic choice operator, we use it here in
    conjunction with guards to implement a \texttt{if-then-else} construct. That
    is, considering the process
    %
    \[
      c(x) . ([x = 1] . P + [x = 2] . Q + R)
    \]
    %
    If the value received from \( c \) is \( 1 \), \( P \) is executed.
    %
    If it is \( 2 \), then \( Q \) is executed. Otherwise \( R \) is executed.
  \item \( \nu c. P \) means a new channel \( c \) is created, and available for
    \( P \) to use it.
  \item \( P || Q \) is the parallel execution of \( P \) and \( Q \).
  \end{itemize}

  \[
    \begin{array}{rcl}
      \mathrm{CloseDoor}(c)
      & \triangleq
      & c(x) . \ ([x = \mathrm{OPEN}] . \mathrm{OpenDoor}(c) \\
      &
      & \qquad + \mathrm{CloseDoor}(c)) \\
      & & \\
      \mathrm{OpenDoor}(c)
      & \triangleq
      & c(x) . \ ([x = \mathrm{CLOSE}] . \mathrm{CloseDoor}(c) \\
      &
      & \qquad + \mathrm{OpenDoor}(c)) \\
      & & \\
      \mathrm{Controller}(c, d_1, d_2)
      & \triangleq
      & c(x). \ ([x = \mathrm{OPEN}_1] . \bar{d_2} \langle
        \mathrm{CLOSE} \rangle . \bar{d_1} \langle \mathrm{OPEN} \rangle . 0 \\
      &
      & \qquad + [x = \mathrm{OPEN}_2] . \bar{d_1} \langle
        \mathrm{CLOSE} \rangle . \bar{d_2} \langle \mathrm{OPEN} \rangle.0 \\
      &
      & \qquad + 0) . \mathrm{Controller}(c, d_1, d_2) \\
      & & \\
      \mathrm{System}
      & \triangleq
      & \nu c. \nu d_1. \nu d_2. (\mathrm{Controller}(c, d_1, d_2) \\
      &
      & \quad\qquad\qquad || \mathrm{CloseDoor}(d_1) \\
      &
      & \quad\qquad\qquad || \mathrm{CloseDoor}(d_2))
    \end{array}
  \]

  The system, modeled with the process \( \mathrm{System} \) creates the
  channels used by its components to communicate, then starts their concurrent
  execution.
  %
  A door is either open or close, and we model this with two mutually recursive
  process \( \mathrm{CloseDoor} \) and \( \mathrm{OpenDoor} \).
  %
  They take one channel \( c \) as an argument, then wait for new inputs coming
  from \( c \).
  %
  A controller is a recursive process which takes three channels \( c \),
  \( d_1 \) and \( d_2 \) as arguments.
  %
  It waits for new requests coming from \( c \).
  %
  When it receives a new request to open the first (resp. second) door, it first
  close the second (resp. first) door, using the channel \( d_2 \) (resp. \( d_1
  \)).
  %
  Then, it opens the first (resp. second) door, using the channel \( d_1 \)
  (resp. \( d_2 \)).
\end{example}

\paragraph{Programs with Effects.}
%
The relation between one component and the rest of the system it is connected to
is reminiscent of the programming language to model and verify large programs
with side effects.
%
Modeling side effects in pure programming language, such as Haskell or {\scshape
  Gallina}, is usually achieved thanks to
Monads\,\cite{wadler1990comprehending,jones2005io}, \emph{e.g.} the State Monad
to seamlessly write computations which manipulates a global state, or the List
Monad to abstract non-determinism,
%
However, Monads have a reputation not to compose very
well\,\cite{hyland2006combining}, despite construction such as Monad
Transformers\,\cite{liang1995mtl}.
%
Algebraic effects and effect handlers are a generic approach overcoming this
challenge, with many different implementations (\emph{e.g.}
Eff\,\cite{bauer2015effects}, {\scshape Idris}\,\cite{brady2013idris}, or
Haskell\,\cite{kiselyov2013extensible}).
%
In this context, \emph{effects} are characterized by sets of operations,
\emph{e.g.} \texttt{get} and \texttt{set} for global state manipulation.
%
These operations are expected to produce a value whose type is known by
definition.
%
For instance, \texttt{get} produces a value of the same type as the global
state.

On the one hand, programs with effects are pure computations which compose
effects results together.
%
On the other hand, handlers model the environment which realizes these effects,
computes their results, and manipulates programs control flows.
%
One possible representation of the relation between programs with effects and
effect handlers is by the means of coroutines\,\cite{kiselyov2013extensible}.
%
When a program with effects requires the result of a given effect, it sends a
request to the handler, and waits for the result.

\subsection{Compositional Verification Approaches}
\label{subsec:sota:compverif}

Historically, compositional verification\,\cite{peng1998survey} is the answer of
model checking\,\cite{mcmillan1989compositional} and concurrent programs
verification\,\cite{jones1983tentative} communities to the state explosion
problem.
%
It can be divided into two complementary approaches: compositional minimization
and compositional reasoning.

\paragraph{Compositional Minimization.}
%
Components of a larger system are primarily identified by the interface they
expose to their pairs, that is the set of operations they can carry out for the
rest of the system.
%
They also ``hide'' the components they are connected to, and use in order to
handles their input.
%
In this context, two components which expose the same interface can be freely
interchange on the condition that they exhibit an equivalent behavior with
respect to their interface.
%
There are many different formalization of what ``equivalent behavior'' actually
means.
%
For instance, in the context of process algebra, trace equivalence or
bisimulation are two possible definitions of equivalent
behavior\,\cite{fokkink2013pa}.

Using a behavior equivalence approach, it becomes possible to reason about one
component by abstracting away the part of the systems it interacts with simpler
specifications.
%
This is referred to as compositional minimization in model checking.
%
The goal is to reduce the complexity of a model, with smaller yet provably
equivalent components, as pictured in Figure~\ref{fig:sota:minicomp}.

\begin{figure}
  \begin{minipage}{0.48\linewidth}
    \begin{center}
      \begin{tikzpicture}
        \node [draw, inner sep=10pt, minimum height=40pt] (p) {\( P \)};%
        \node [draw, inner sep=10pt, right=of p, minimum height=40pt] (q)
        {\( Q \)};%

        \draw ([yshift=5pt]p.east) -- ([yshift=5pt]q.west);%
        \draw ([yshift=-5pt]p.east) -- ([yshift=-5pt]q.west);%

        \draw ([yshift=10pt, xshift=-25pt]p.west) -- ([yshift=10pt]p.west);%
        \draw ([xshift=-25pt]p.west) -- (p.west);%
        \draw ([yshift=-10pt, xshift=-25pt]p.west) -- ([yshift=-10pt]p.west);%

        \draw ([yshift=15pt, xshift=25pt]q.east) -- ([yshift=15pt]q.east);%
        \draw ([yshift=5pt, xshift=25pt]q.east) -- ([yshift=5pt]q.east);%
        \draw ([yshift=-5pt, xshift=25pt]q.east) -- ([yshift=-5pt]q.east);%
        \draw ([yshift=-15pt, xshift=25pt]q.east) -- ([yshift=-15pt]q.east);%
      \end{tikzpicture}
    \end{center}
  \end{minipage}
  %
  \begin{minipage}{0.48\linewidth}
    \begin{center}
      \begin{tikzpicture}
        \node [draw, inner sep=10pt, minimum height=40pt] (p) {\( P \)};%
        \node [draw, inner sep=10pt, right=of p] (q) {\( Q' \)};%

        \draw ([yshift=5pt]p.east) -- ([yshift=5pt]q.west);%
        \draw ([yshift=-5pt]p.east) -- ([yshift=-5pt]q.west);%

        \draw ([yshift=10pt, xshift=-25pt]p.west) -- ([yshift=10pt]p.west);%
        \draw ([xshift=-25pt]p.west) -- (p.west);%
        \draw ([yshift=-10pt, xshift=-25pt]p.west) -- ([yshift=-10pt]p.west);%
      \end{tikzpicture}
    \end{center}
  \end{minipage}

  \caption{Illustration of the compositional minimization paradigm}
  \label{fig:sota:minicomp}
\end{figure}

\paragraph{Compositional Reasoning.}
%
At its simplest, assume-guarantee\,\cite{pnueli1985ag} ---or
rely-guarantee\,\cite{jones1983tentative}--- reasoning is about proving a
component \( C \) guarantees the property \( G \) under the assumptions that an
assumption \( A \) is satisfied, then proving the rest of the system \( S' \)
satisfies \( A \).
%
This allows for concluding about the correctness of the system as a whole, that
is the composition of \( C \) with \( S' \) (denoted by \( C || S' \))
guarantees \( G \).

First assume-guarantee systems have been developed for model checkers, where
assumptions and guarantees were defined in temporal logic formulas.
%
The main obstacle to the adoption of the assume-guarantee paradigm is the
necessity for the user to provide additional inputs to the checker, in addition
to the model and its properties to verify.
%
The \( L* \) learning algorithm, originally proposed by
Augluin\,\cite{angluin1987lstart}, addresses this issue by automatically
generating appropriate assumptions.
%
The \( L* \) algorithm has latterly been adapted to other modeling structure, for
instance for interface automata\,\cite{emmi2008assume}.

\subsection{Related Works}

\paragraph{{\scshape Kami}.}
%
In 2017, Joonwon Choi \emph{et al.} have released \,\cite{choi2017kami}, a
framework for Coq to model, verify hardware components.
%
The resulting hardware models can also be converted into
BlueSpec\,\cite{nikhil2004bluespec} programs, which can be compiled to Verilog,
a hardware description language.
%
This means it is possible to turn a {\scshape Kami} model into a concrete
implementation.

In in {\scshape Kami}, a model \( M \) is a particular labeled transition
system, whose transitions are of the form
%
\[
  p \xrightarrow[a]{i} (v, q)
\]
%
where \( p \) is the state of the component before an operation \( i \) which is
called by another component, \( a \) is a sequence of actions performed by the
component in order to compute the result of \( i \), \( v \) is the result of
\( i \), for the caller to use, and \( q \) is the modified state of the
component.
%
Actions, in this context, are either local manipulation of the component's
state or calls of operations.

To reason about \( M \) with respect to a specification \( M_S \), {\scshape
  Kami} introduces a refinement relation \( \sqsubseteq \).
%
A module \( M \) refines a module \( M_S \) (\emph{i.e.} \( M \) is an
implementation of \( M_S \)) if any traces of \( M \) can also be produced by
\( M_S \).
%
A component \( M \) can be composed with another component \( M' \) to form a
larger component \( M + M' \), for instance when the operations exposed by
\( M' \) are used by \( M \).
%
The authors introduced another ``modular'' refinement property, whose simplest
expression could be
%
\[
  M \sqsubseteq N \wedge R \sqsubseteq S \Rightarrow M + R \sqsubseteq N + S
\]
%
This approach is related to the compositional minimization, where one component
is reduced to a simpler, more abstract model, to reduce the complexity of the
proofs.

\paragraph{\texttt{Coq.io}.}
%
The \texttt{Coq.io} framework, developed and released by Guillaume Claret
\emph{et al.}\,\cite{claret2015coqiowww}, have been originally proposed in order
to allow the definition and verification of interactive programs in Coq by the
means of use cases\,\cite{claret2015coqio}.
%
Such programs are defined in a dedicated monad, with side effects (\emph{e.g.}
system calls to read from or write to a file) axiomatized as monadic operations
of this monad.
%
The proofs rely on scenarios which determine how an environment (\emph{e.g.} an
operating system) would react to the program requests.
%
Morally, the verification goal is to verify that, under the hypothesis that the
environment is correct with respect to a scenario, then a program with effects
is also correct with respect to the trace of side effects operations it
produces.

The approach used by \texttt{Coq.io} enables a beginning of compositional
approach reasoning.
%
A program with effects can be verified, but the verification of the composition
of this program with its environment is out of the scope of the project.


\paragraph{Interface-Confined Adversaries.}
%
Logic of Program, but to the best of our knowledge, no implementation.
%
\thomasrk[inline]{TODO}

\section{Conclusion: Where this Thesis Stands}
\label{sec:sota:conclusion}

\thomasrk[inline]{TODO}

\subsection{Specifying and Verifying Hardware-based Security Enforcement
  Mechanisms}

Formal verification consists in proving the correctness of a system,
characterized by a mathematical model, with respect to certain properties,
defined as logic formula.
%
By definition, \ac{hse} mechanisms fall between two domains that are hardware
design verification and low-level software components verification.

On the one hand, hardware design verification often focus on properties
transparent to the executed software components (\emph{e.g.} cache
coherency\,\cite{stern1995cachecoherence}, linearizability of SGX
instructions\,\cite{leslie2015sgx}, hardware-based memory
isolation\,\cite{lie2003xom}).
%
Security gap in interactions of multiple platform components are less subject to
formal verification, due to their increasing
complexity\,\cite{potlapally2011hardwaresecurity}.
%
Yet they are responsible for architectural attacks we want to avoid.
%
On the other hand, low-level software components such as
seL4\,\cite{klein2009sel4} or CertiKOS\,\cite{gu2016certikos} use the features
exposed by these components, and are verified against \emph{ad hoc} hardware
models, whose scope is often limited to necessary hardware features.
%
We steer a middle course between these approaches.
%
In Chapter~\ref{chapter:speccert}, we define \ac{hse} mechanisms as sets of
requirements over low-level software components, such that satisfying these
requirements is sufficient to ensure the hardware architecture enforces a
certain property\,\cite{letan2016speccert}.
%
In Chapter~\ref{chapter:speccert2}, we show how we can verify the correctness of
these requirements against a hardware model.
%
A desirable long-term goal of this approach would be to be able to verify the
correctness of low-level
software components with respect to these requirements, so we can conclude the
security property targeted by a \ac{hse} mechanism is effectively enforced.
%
As such, our approach relates to previous research works such as
RockSalt\,\cite{morrisett2012rocksalt} (validation of arbitrary programs against
a verified software-based fault isolation\,\cite{wahbe1994sfi} policy) or
Moat\,\cite{sinha2015moat} (verification of SGX
enclave\,\cite{costan2016sgxexplained} programs with respect to
confidentiality).

\subsection{Compositional Verification of Hardware Architecture}

Our formal definition of \ac{hse} mechanism assumes there exists a formal model
of the hardware architecture.
%
The development of our proof of concept, implemented in
Coq\,\cite{letan2016speccertcode}, convinced us that such a model cannot be
monolithic.
%
Otherwise, it would make the proof burden hard to bear.
%
Compositional verification is a very important domain research for the
verification of large, realistic model.
%
However, it is a discipline mostly dominated by automated verification, like
model checking for instance.

With FreeSpec\,\cite{letan2018freespeccode}, we aim to provide a generic
compositional reasoning framework for Coq.
%
As detailed in Chapter~\ref{chapter:freespec}, FreeSpec leverages programs with
effects and effect handlers to model component-based system, and introduces
so-called abstract specification in order to enable a verification methodology
inspired by the assume-guarantee paradigm.
%
In doing so, FreeSpec is at the intersection of several research domains.
%
Our work is in the continuity of \texttt{Coq.io}\,\cite{claret2015coqio}, but
our abstract specifications are more generic and expressive than the scenarios.
%
We have shown how programs with effects and effects handlers can be used to
modularly verify a complex system made of interconnected components, \emph{via}
the notion of interface as the rendezvous point.
%
The principle of our approach is similar to what {\scshape Kami} achieves, but
is not hardware specific.
%
In addition, our abstract specifications allow for compositional verification,
while {\scshape Kami} focus on refinement proofs.
%
To the best of our knowledge, the closest related research is the work of Deepak
Garg \emph{et al.}\,\cite{garg2010compositional}.
%
Probably the main difference between our two approaches is that they rely on a
dedicated programming language, while our programs with effects and effect
handlers are regular {\scshape Gallina} development.
%
As a consequence, we can use the full interactive proof development environment
of Coq in order to write and validate our proofs.
