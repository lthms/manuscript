\documentclass[oneside,a4paper]{memoir}
\setsecnumdepth{subsection}

\usepackage[chapter]{minted}
\usemintedstyle{bw}

% ABOUT THIS FILE
% ---------------
%
% The goal of this document is to prepare the next (and final?) version of the
% chapter 3.

\usepackage{bigcenter}
\usepackage{geometry}
\usepackage{paralist}
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{bussproofs}

\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{inconsolata}

\usepackage[dvipsnames]{xcolor}
\usepackage{xargs}
\usepackage{todonotes}
\newcommandx{\thomasrk}[2][1=]{\todo[linecolor=Plum,backgroundcolor=Plum!25,bordercolor=Plum,#1]{#2}}

\usepackage{mdframed} % or, "mdframed"
\usepackage[amsthm,framed]{ntheorem}
\newcommand{\powerset}{\raisebox{.15\baselineskip}{\Large\ensuremath{\wp}}}

\definecolor{statementline}{HTML}{b7e2d6}

\theoremstyle{break}
\theorembodyfont{\fontshape\rmdefault\selectfont}

\mdfdefinestyle{quoted}{
hidealllines=true,
leftmargin=-15pt,
rightmargin=-15pt,
leftline=true,
innertopmargin=10pt,
innerbottommargin=10pt,
innerrightmargin=15pt,
linewidth=5pt,
linecolor=gray!40,
backgroundcolor=gray!3,
usetwoside=false,
skipabove=\topsep,
skipbelow=\topsep}

\mdfdefinestyle{definition}{
style=quoted,
linecolor=Violet!20,
backgroundcolor=Violet!2}

\mdfdefinestyle{statement}{
style=quoted,
linecolor=PineGreen!30,
backgroundcolor=PineGreen!2}

\newmdtheoremenv[style=definition]{definition}{Definition}[chapter]
\newmdtheoremenv{notation}{Notation}[chapter]
\newmdtheoremenv[style=quoted]{example}{Example}[chapter]
\newmdtheoremenv[style=statement]{corollary}{Corollary}[chapter]
\newmdtheoremenv[style=statement]{lemma}{Lemma}[chapter]
\newmdtheoremenv[style=statement]{theorem}{Theorem}[chapter]

\usepackage{tikz}
\usetikzlibrary{shapes.geometric, positioning, arrows, intersections, fit,
  matrix, shapes, shapes.symbols}

\usepackage{acro}
\input{abbrev}

\begin{document}
\chapter{State of the Art of Formal Verification}

%
% The rest of this Chapter proceeds as follow.
%%
% First, we give an opinionated introduction to the formal verification of
% hardware and software components with respect to security properties, with
% respect to our objectives (Section~\ref{?}).
%%
% Then, we give a review of several industrial and academic projects which
% implements these approaches (Section~\ref{?}).
%%
% Finally,

Formal verification consists in proving the correctness of a system ---the
\emph{Implementation}--- with respect to certain properties.
%
To that end, a verifier
%
\begin{inparaenum}[(1)]
\item defines a formal description of the system ---the \emph{Specification}---,
  %
\item exhibits a proof that a formal description of the system satisfies a
  statement (defined in an arbitrary logic) which encodes the property with
  respect to which the correctness shall be proven, and
  %
\item exhibits a proof of correspondence between the implementation and the
  specification.
\end{inparaenum}
%
In this context, the terms ``implementation'' and ``specification'' refer to a
subjective relation between two layers of abstraction: the specification is more
abstract than its implementation, and formal verification proofs can be
organized in an arbitrary number of abstraction layers
%
The definition of a specification shall ease the construction of the proof of
correctness, while the correspondence proof allows for extending the properties
of the specification to the implementation.
%
The instantiation of the terms ``formal description'', ``correspondence proof'',
``properties'' or ``correctness proof'' may considerably vary from one system to
another.
%
Similarly, the nature of the proofs and their construction greatly depend on the
tools used by the verifier.
%
For our part, we want to construct correctness proofs of a hardware architecture
specification, with respect to security properties, and using the Coq theorem
prover (as explained in Chapter~\ref{chap:introduction}).
%
The rest of this Chapter is organized with this objective in mind

First, we describe popular formalisms used to define formal descriptions of
hardware specifications (Section~\ref{sec:sota:formalisms}).
%
Then, we focus on the encoding of security properties as logic statements
(Section~\ref{sec:sota:security}).
%
Finally, we give an overview of related works
(Section~\ref{sec:sota:relatedwork}).
% and we conclude this Chapter by positioning our contributions in that respect
% (Section~\ref{...}).

\section{Transition Systems}
\label{sec:sota:formalisms}

\subsection{Definition}

The formal verification of discrete systems, such as computing systems, commonly
rely on some sort of \emph{transition systems} to describe the behavior of the
target.
%
More precisely, the system is characterized by a set of \emph{states} and by a
set of \emph{atomic} state-transformation, called \emph{transitions}.
%
Transitions occur when the system interacts with its environment (\emph{e.g.} a
hardware circuit receives a clock signal, a hardware controller receives a
message from a bus, an operating system handles a syscall).
%
Additionally, \emph{labeled} transition systems distinguish between classes of
transitions \emph{via} the use of labels (\emph{e.g.} one label per syscall).

To the best of our knowledge, the more straightforward definition of a labeled
transition system, as used by Vijayaraghavan \emph{et al.} in their work on
modular verification of multiprocessor hardware
designs\,\cite{vijayaraghavan2015modular}, is a tuple
\( \langle S, L, R \rangle \), such that \( S \) is a set of states, \( L \) is
a set of labels, and \( R \subseteq S \times L \times S \) is the transition
relation.

\begin{example}[Airlock System]
  Figure~\ref{fig:sota:airlock-lts} illustrates an instantiation of this
  definition for a simple airlock system.
  %
  An airlock system is a device made of two doors, and an intermediary chamber.
  %
  To get across a airlock system, a user requests the opening of the first door,
  enters the chamber, waits for the system to close the first door and open the
  second door, and exits the chamber.

  \begin{itemize}
  \item A door of the system can be either \( \mathtt{open} \) or
    \( \mathtt{close} \).
    %
    The set of states of the airlock system reflects the combinatronics of the
    doors states.
  \item A transition is characterized by the opening (\( \mathtt{Open}_i\), with
    \( i \in \{1, 2\} \)) and closing (\( \mathtt{Close}_i \), with
    \( i \in \{1, 2\} \)) of a door of the system.
    %
  \item The system does not allow the simultaneous opening of both doors, as
    stated by the definition of \( R \) which does not contains a transition
    which leads to the state \( (\mathtt{open}, \mathtt{open}) \).
  \end{itemize}
\end{example}

\begin{figure}
  \begin{center}
    % the mathematical definition
    \begin{minipage}[c]{0.55\linewidth}
      \[
        \begin{array}{rcl}
          S & \triangleq & \{ \mathtt{open}, \mathtt{close} \}^2 \\
          L & \triangleq & \{ \mathtt{Open}_1, \mathtt{Close}_1, \mathtt{Open}_2,
                           \mathtt{Close}_2 \} \\
          R & \triangleq & \{ (\mathtt{close}, \mathtt{close}), \mathtt{Open_1},
                           (\mathtt{open}, \mathtt{close}), \\
            & & \ (\mathtt{close}, \mathtt{close}), \mathtt{Open_2},
                (\mathtt{close}, \mathtt{open}), \\
            & & \ (\mathtt{open}, \mathtt{close}), \mathtt{Close_1},
                (\mathtt{close}, \mathtt{close}), \\
            & & \ (\mathtt{close}, \mathtt{open}), \mathtt{Close_2},
                (\mathtt{close}, \mathtt{close}) \}
        \end{array}
      \]
    \end{minipage}
    \hfill
    % a tikzpicture to illustrate the resulting automata
    \begin{minipage}[c]{0.40\linewidth}
      \begin{center}
        \begin{tikzpicture}
          \node [draw, circle split, text width=30pt, text badly centered] (cc)
          {\( \mathtt{close} \) \nodepart{lower} \( \mathtt{close} \)};%
          \node [right=of cc] (x) {};%
          \node [draw, circle split, above=of x, text width=30pt, text badly
          centered] (oc) {\( \mathtt{open} \) \nodepart{lower}
            \( \mathtt{close} \)};%
          \node [draw, circle split, below=of x, text width=30pt, text badly
          centered] (co) {\( \mathtt{close} \) \nodepart{lower}
            \( \mathtt{open} \)};%
          \node [draw, circle split, right=of x, text width=30pt, text badly
          centered] (oo) {\( \mathtt{open} \) \nodepart{lower}
            \( \mathtt{open} \)};%

          \draw [-latex] (cc) edge [bend left] node [xshift=-5pt, left]
          {\( \mathtt{Open}_1 \)} (oc);%
          \draw [-latex] (oc) edge [bend left] node [xshift=5pt, right]
          {\( \mathtt{Close}_1 \)} (cc);%

          \draw [-latex] (cc) edge [bend left] node [xshift=5pt, right]
          {\( \mathtt{Open}_2 \)} (co);%
          \draw [-latex] (co) edge [bend left] node [xshift=-5pt, left]
          {\( \mathtt{Close}_2 \)} (cc);%

        \end{tikzpicture}
      \end{center}
    \end{minipage}

    \caption{An simple airlock system modeled as a labeled transition system}
    \label{fig:sota:airlock-lts}
  \end{center}
\end{figure}

There are many modeling structures one can use to characterize transition
systems, with each variant better suited to tackle a particular class of
systems.
%
For instance, the Kripke structure\,\cite{kripke1971semantical} is a notorious
variation of (labeled) transition systems used in model
checking\,\cite{clarke1999model}, while Petri net\,\cite{peterson1981petri},
process algebra\,\cite{bergstra1984process} or interface
automata\,\cite{de2001interface} are better suited to model concurrent systems.

\subsection{Introduction to Formal Methods}

Theorem prover rely on formal systems in which formulas (also called
propositions) of a formal language represent statements which can either be true
or false.
%
Each formal system (\emph{e.g.} higher-order logic\,\cite{leivant1994hol})
relies on a set of axioms, that are formulas known to be true, and inference
rules which allows for deriving new formulas.

\paragraph{Propositions and Inference Rules.}
%
The statement that a proposition \( P \) is true is commonly denoted by
\( \vdash P \).
%
A proposition \( P \) may also be true on the condition that propositions
\( Q_0, Q_1, ... Q_n \) is also true.
%
This statement is denoted by \( Q_0, Q_1, ... Q_n \vdash P \).
%
A statement is proven true when it is part of the base of axioms or we use
inference rules to derive already proven statements.
%
By doing so, we construct a \emph{proof}.
%
For example, a notorious inference rule is the \emph{Modus ponens}, which states
that if a proposition \( P \) is true, and the proposition \( P \Rightarrow Q \)
is also true, then the proposition \( Q \) is true, that is
%
\[
  P\text{, }(P \Rightarrow Q) \vdash Q
\]
%
Using the \emph{Modus ponens}, it becomes possible to construct a proof of
\( \vdash Q \) from a proof of \( \vdash P \) and a proof of
\( \vdash P \Rightarrow Q \).
%
Figure~\ref{fig:sota:inference} gives a l list of common inference rules.
%
Conditional statements, once proven, become new inference rules to be used to
construct proofs.

Formally constructing a proof can quickly become cumbersome as propositions
become more complex.
%
They can be described in the form of carefully worded sentences.
%
Another popular approach is to write them as so-called proof trees.
%
Each node of the tree is a proof obligation.
%
The children of a given proof obligation or proofs which allows for concluding
about the node goal, by using an inference rule of the system.
%
By convention, a node goal and its children are separated by a line labeled with
the name of the inference rule.
%
The leafs of the trees are the statement known to be true, either because they
are part the system axioms or because they have already been proven before.
%
Therefore, a proof which only consists in applying the \emph{Modus ponen} can be
represented as follows:
%
\begin{prooftree}
  \AxiomC{\( P \)} \AxiomC{\( P \Rightarrow Q \)} \RightLabel{\small {\scshape
      Modus Ponens}} \BinaryInfC{\( Q \)}
\end{prooftree}

\begin{figure}
  \begin{center}
    \begin{tabular}{ll}
      {\scshape Modus ponens} & \( P \Rightarrow Q\text{, }P \vdash Q \) \\
      {\scshape Modus tollens} &
                                 \( P \Rightarrow Q\text{, }\neg Q \vdash \neg P \) \\
      {\scshape Conjunction:} & \( P\text{, }Q \vdash P \wedge Q \) \\
      {\scshape Addition:} & \( P \vdash P \vee Q \)
    \end{tabular}
  \end{center}

  \caption{Examples of common inference rules}
  \label{fig:sota:inference}
\end{figure}

Constructing a proof and verifying its correctness quickly becomes challenging.
%
Theorem provers such as Coq\,\cite{coq} or Isabelle/HOL\,\cite{nipkow2002isabelle} provide
facilities to write proofs, and verify these proofs (supposedly in a more
reliable way than humans).
%
Therefore, the quality of a theorem prover is measured by its capacity to reject
ill-formed proofs.
%
To avoid this pitfall, modern theorem provers are built as ``certified'' layers
around a certification as small and simple as possible.
%
The idea is that, as long as the kernel does not contain a bug, advanced
features implemented inside a certified layer cannot introduce inconsistency in
the proof-checking process.
%
This greatly diminishes the risk to have inconsistencies in the proof checker,
although this happened in the
past\,\cite{claret2015falso,griffioen1998comparison}.
%
Another common approach is to rely on an algorithm whose correctness has been
formally established to handle a well-defined class of problem.
%
This allows for automating the verification process.
%
Abstract interpretation\,\cite{cousot1977absint} and model
checking\,\cite{clarke2018modelc} are two notorious instances of this approach.

\paragraph{Formal Systems.}
%
Choosing a formal language is a key part of the verification process of a
system.
%
It decides the expressiveness of the statements that can be proven, and the
tools verifiers can leverage to construct their proofs.

The most common formal system is the first-order logic\,\cite{smullyan2012fol},
characterized by:
%
\begin{itemize}
\item \emph{Terms}, which represents objects.
\item \emph{Logical operators}, such as conjunction \( \wedge \), disjunction
  \( \vee \), implication \( \Rightarrow \), negation \( \neg \).
\item \emph{Predicates}, that is parameterized formulas that can be true or
  false with respect to the applied terms.
\item \emph{Quantifiers}, such as \( \forall \) (all values) or \( \exists \)
  (there exists a value).
\end{itemize}

First-order logic quantifiers can only be applied on sets of terms (\emph{e.g.}
natural numbers, booleans, states of a airlock system).
%
Higher-order logic\,\cite{leivant1994hol} does not suffer the same limitation,
so it becomes possible to express statements such as \emph{for all sets with a
  total order \( < \), for all pair of values \( \alpha, \beta \), then either
  \( \alpha < \beta \) or \( \beta < \alpha \) or \( \alpha = \beta \)}.
%
Therefore, higher order logics are more expressive than first-order logic, but
they come with a cost in terms of automation.
%
On the one hand, \emph{Interactive} theorem provers (\emph{e.g.}  Coq,
Isabelle/HOL, or more recently Lean\,\cite{de2015lean} are based on higher-order
logic.
%
\emph{Automated} theorem provers (\emph{e.g.}
Vampire\,\cite{riazanov2002vampire}, Z3\,\cite{de2008z3}) are based on
first-order logic.

Finally, modal logic\,\cite{chagrov1997modal} is a formal system which extends
first-order logic with modal operators.
%
Temporal logics form the most popular family of modal logics, such as Temporal
Linear Logic (LTL)\,\cite{sistla1985ltl}.
%
They allow for reasoning about propositions over time.
%
Examples of LTL modular operators are \( \square P \) (\( P \) is always true),
\( \Diamond P \) (\( P \) will eventually become true), \( \bigcirc P \)
(\( P \) will be true after the next transition of the system).
%
Another popular temporal logic is Computation Logic Tree
(CTL)\,\cite{clarke1981ctl}, which considers trees of possible futures (by
opposition to a \emph{linear} future).
%
CTL modal operator includes \( \mathbf{A} P \) (\( P \) is true for all possible
futures) and \( \mathbf{E} P \) (there exists at least one path where \( P \)
becomes true).
%
Temporal logic formulas are commonly verified thanks to model checkers,
\emph{e.g.}  NuSMV\,\cite{cimatti2002nusmv}, SPIN\,\cite{holzmann1997spin} or
TLA+\,\cite{lamport2002tla}.
%
Other approaches can be used to that end ---for instance Gilles Barthe \emph{et
  al.} have encoded \( \square \) and \( \Diamond \) in
Coq\,\cite{barthe2011virtcert1})--- model checkers have the benefit of
automation and counter-example generation.


\subsection{Specifying Security Policies}
\label{sec:sota:security}

The verification a system is \emph{always} relative to certain properties (in
our case, the correct enforcement of a security policy).
%
The definition of a specification of the system to allow for formally reasoning
about its behavior is a key step of the verification process.
%
The formalization of the targeted property is as important, if not more.
%
Indeed, the challenge posed by a potential gap between an implementation and its
specification can be abated by an appropriate correspondence proof.
%
As for the targeted properties, a gap between its characterization using a
particular logic and its semantics should not be understated.
%
For instance, Mathy Vanhoef \emph{et al.} disclosed a critical vulnerability
(KRACK) targeting the WPA2 protocol\,\cite{vanhoef2017key}, despite previous
formal verification results (\emph{e.g.} \cite{he2004analysis}).
%
The reason remains simple: KRACK does not violate the security properties proven
in the formal analysis of the protocol, only these security properties were not
strong enough.

The theory of properties of a transition system is now well understood, with an
intuitive classification of properties, such that:
%
\begin{itemize}
\item \emph{Safety properties}\,\cite{lamport1977proving,lamport1985logical}
  characterize that nothing ``bad'' shall \emph{never} happens.
\item \emph{Liveness properties}\,\cite{lamport1985logical,alpern1985liveness}
  characterize that something ``good'' shall \emph{eventually} happens.
\end{itemize}

We discussed in Subsection~\ref{subsec:usecase:targetedsec} the two classes of
security policies commonly targeted by x86 \ac{hse} mechanisms.
%
An access control policy is a safety property: no unauthorized action by a
subject targeting on object shall never happen.
%
An availability policy is a liveness property: the system shall eventually
satisfy the service

Safety and liveness properties are expressed against the transition systems
\emph{traces}.
%
The most generic definition of a trace of a transition system is a (potentially
infinite) sequence of states generated by successive transitions.
%
Each modeling structure has its own definition of traces, which takes into
account the specificities of the model.
%
For instance, traces labeled transition system will interleave a label between
each state\,\cite{vijayaraghavan2015modular}, to characterize the nature of the
transition which led to the transformation of a state of the sequence with its
successor.
%
Afterwards, we write \( \Sigma(M) \) for the set of traces of a specification
\( M \).

Simplest properties can be defined in terms of sets of
traces\,\cite{schneider2000enforceable,basin2013enforceable}\,\thomasrk{cite
  ``Recognizing Safety and Liveness'' by Alpern}.
%
We assume a specification \( M \) whose set of states is \( S \) and whose
traces only contain states.
%
On the one hand, a safety property \( P \in \powerset(\Sigma(M)) \) is
formalized with an invariant \( \iota \) on trace element (\emph{i.e.} on
\( S \) in the case of the specification \( M \)).
%
\( M \) is correct with respect to \( P \) when
%
\[
  \forall \rho \in \Sigma(M)\text{, } \iota(\rho_0) \wedge \rho_{[1..]} \in P,
\]
%
where \( \rho_0 \) is the first element of the trace, and \( \rho_{[1..]} \) is
the trace obtained by removing the first element of \( \rho \).
%
On the other hand, a liveness property is formalized by a predicate \( \eta \)
on trace element which has to be satisfied at least once.
%
This time, \( M \) is correct with respect to \( P \) when
%
\[
  \rho \in \Sigma(M)\text{, } \eta(\rho_0) \vee \rho_{[1..]} \in P.
\]
%

\begin{example}[Airlock Safety and Liveness Properties]
  A typical \emph{safety} property (nothing `bad'' happens) for an airlock
  system is that at least one door shall be close at any time.
  %
  We formalize this property with the invariant \( \iota \), defined as follows:
  %
  \[
    \iota( d_1, d_2) \triangleq d_1 = \mathtt{close} \vee d_2 = \mathtt{close}
  \]
  %
  The specification of the airlock system is defined with a labeled transition
  system.
  %
  Assuming the airlock device is initialized in a correct state (\emph{e.g.}
  both doors are close), we verify this specification is correct with respect to
  the safety property characterized by \( \iota \) by exhibiting a proof that
  \( \iota \) is an invariant with respect to \( R \), that is
  %
  \[
    \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \iota(d_1, d_2) \Rightarrow
    \iota(d_1', d_2')
  \]
  %
  Such a proof is given in Figure~\ref{fig:sota:proofsafety}.

  In addition, we can also prove that both doors of the airlock will
  \emph{eventually} be close.
  %
  We can characterize this liveness property with the predicate \( \eta \), such
  that
  %
  \[
    \eta(d_1, d_2) \triangleq d_1 = \mathtt{close} \wedge d_2 = \mathtt{close}
  \]
  %
  We verify the specification of the airlock system is correct with respect to
  the liveness property characterized by \( \eta \) by exhibiting a proof that
  for each transition of \( R \), one of the state satisfies \( \eta \), that is
  %
  \[
    \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \eta(d_1, d_2) \vee
    \eta(d_1', d_2')
  \]

\end{example}

\begin{figure}
  \bigcentering%
  {\footnotesize \AxiomC{} \RightLabel{\footnotesize
      \( \vee,\Rightarrow \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{close} = \mathtt{close} \\
        \vee \mathtt{close} = \mathtt{close}) \\
        \Rightarrow (\mathtt{open} = \mathtt{close} \\
        \qquad \vee \mathtt{close} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{close}, \mathtt{close}) \\
        \Rightarrow
        \iota(\mathtt{open}, \mathtt{close})
      \end{array} \)}%
    \AxiomC{}
    \RightLabel{\footnotesize \( \vee,\Rightarrow \){\scshape -Def}}
    \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{close} = \mathtt{close} \\
        \vee \mathtt{close} = \mathtt{close}) \\
        \Rightarrow (\mathtt{close} = \mathtt{close} \\
        \qquad \vee \mathtt{open} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{close}, \mathtt{close}) \\
        \Rightarrow
        \iota(\mathtt{close}, \mathtt{open})
      \end{array} \)}%
    \AxiomC{}
    \RightLabel{\footnotesize \( \vee,\Rightarrow \){\scshape -Def}}
    \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{open} = \mathtt{close} \\
        \vee \mathtt{close} = \mathtt{close}) \\
        \Rightarrow (\mathtt{close} = \mathtt{close} \\
        \qquad \vee \mathtt{close} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{open}, \mathtt{close}) \\
        \Rightarrow
        \iota(\mathtt{close}, \mathtt{close})
      \end{array} \)}%
    \AxiomC{See \( \square \)}
    \RightLabel{\footnotesize \( R \){\scshape -Def}}
    \QuaternaryInfC{\( \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \iota(d_1,
      d_2) \Rightarrow \iota(d_1', d_2') \)}%
    \DisplayProof}

  \vspace{2em}

  {\footnotesize \AxiomC{} \RightLabel{\footnotesize
      \( \vee,\Rightarrow \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{close} = \mathtt{close} \\
        \vee \mathtt{open} = \mathtt{close}) \\
        \Rightarrow (\mathtt{close} = \mathtt{close} \\
        \qquad \vee \mathtt{close} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{close}, \mathtt{open}) \\
        \Rightarrow
        \iota(\mathtt{close}, \mathtt{close})
      \end{array} \)}%
    \UnaryInfC{\( \square \)}
    \DisplayProof}

  \caption{Airlock system proof of correctness with respect to a safety
    property}
  \label{fig:sota:proofsafety}
\end{figure}

Not all security policies can be formalized with a predicate on traces.
%
For instance, \emph{noninterference} \thomasrk{ref} is a confidentiality policy
which requires that so-called public inputs handled by a given system always
produce the same output, regardless of concurrent secret inputs.
%
In this context, considering each trace independently does not make sense.
%
To witness a violation of the security policy requires to compare two traces
together.
%
Such properties are called \emph{hyperproperties}\,\cite{marr2002hypertheading},
and are characterized by sets of sets of traces.
%
Verifying a system with respect to a hyperproperty is harder in the general
case, but certain hyperproperties, called \( k \)-safety properties, can be
reduced to an invariant.
%
For instance, we assume \( M \) handles inputs which can be either secret or
public.
%
Let \( \equiv \) be the binary relation, such that two states \( s \) and
\( r \) satisfies this relation (\( s \equiv r \)) when they characterize two
instances of the system which have handled the same public inputs and produced
the same visible behavior.
%
Similarly to Banerjee \emph{et al.} \thomasrk{Stack-based access control for
  secure information flow} or Barthe \emph{et al.}\,\cite{barthe2011virtcert1},
we can prove \( M \) enforces noninterference if for any public input \( l \) by
constructing a proof that
%
\[
  \forall (s, r) \in S \times S, s \equiv r \Rightarrow (s \xrightarrow{l} s'
  \wedge r \xrightarrow{l} r') \Rightarrow s' \equiv r',
\]
where \( s \xrightarrow{l} s' \) is a transition of the system from a state
\( s \) to a state \( s' \) to handle the input \( l \).

\subsection{Adversary}
%
\begin{itemize}
\item Combinatronics of system actions (Pip, VirtCert)
\item Additional rule to model more powerful attacker (Moat, XOM + bus snooping)
\end{itemize}

\subsection{Related Works}

Formal verification of hardware and software systems is a large and prolific
research field, with important applications in the industry.
%
The interest has grown in the use of formal methods to improve the security of
computer systems\,\cite{chong2016report}.
%
We give an overview of formal verification projects which
%
\begin{inparaenum}[(1)]
\item have a clear focus on security, and
\item target two domains related to \ac{hse} mechanisms, that is hardware
  architectures (XOM\,\cite{lie2003xom}, ARMv8\,\cite{reid2016armv8}), and
  system software components (VirtCert, seL4).
\end{inparaenum}
%
For each project, we detail the modeling structure used to define the
specification of the targeted system, the verified properties and the
verification approach leveraged by the authors.

\paragraph{XOM}
%
The \ac{xom} microprocessor architecture maintains separate so-called
\emph{compartments} for applications\,\thomasrk{ref xom}.
%
With mainstream microprocessor architectures, the system software is responsible
for both memory allocation and access control.
%
It relies on configurable \ac{cpu} mechanisms, such as a \ac{mmu}, to implement
the latter.
%
On the contrary, a \ac{xom} \ac{cpu} keeps track of each memory location owner,
thanks to a tagging mechanism, and prevents an application to access a memory
location it does not own.

In 2003, David Lie \emph{et al.} have modelled the \ac{xom}
architecture\,\cite{lie2003xom} using the Mur$\varphi$ model
checker\thomasrk{ref murphi}.
%
This model is a transition systems defined in terms of states and rules to
update these states.
%
There are two kinds of rules: the \ac{xom} instructions set, and some additional
capabilities given to the attacker.
%
As for the transitions set, it is defined in terms of pre and postconditions.
%
On the one hand, the precondition is parameterized by the current state and the
labeled event.
%
If the pre-condition is satisfied for a given hardware state and labeled events,
then it means that event can occur in this state.
%
On the other hand, the post condition is parameterized by the initial state, the
labeled event and the resulting state.
%
It determines the consequences of that event, in terms of state update.

The security properties targeted by the \ac{xom} architecture are enforceable
security properties, and the authors rely on Mur$\varphi$ to perform the state
exploration of their model.
%
The main advantage of a model checker, in this context, is to be able to print a
counter-example, that is a trace it has found not to satisfy the targeted
security property, in case of failure.
%
From a security perspective, a counter-example describes an attack path, that is
the execution steps to reproduce in order to defeat the security enforcement.
%
Hence, the authors have been able to show with their model that the \ac{xom}
architecture was subject to several replay attacks, and they leveraged their
model to validate their countermeasures.
%
However, the state explosion problem obliges the authors to simplify their
model, in order to reduce the state combinatory.

\paragraph{ARMv8}
%
ARM Specification Language

\paragraph{VirtCert}
%
Between 2011 and 2014, Gilles Barthe \emph{et al.} have worked on an idealized
model of a hypervisor.
%
This model is defined in terms of state, actions and a semantics of actions as
state-trans\-formers.
%
In their context, the state mixes information about both hardware components
(\ac{cpu} execution mode, registers, memory content, etc.) and software
components (list of guests, current active guest, memory mapping for the
hypervisor and the guests, etc.).
%
The actions are the hypercalls exposed by the hypervisor for the guests to use.
%
The semantics of actions as state-transformers, that is the set of possible
transitions for the modelled system, is defined in terms of pre and
postconditions.

First, they have shown that their ideal hypervisor was
%
\begin{inparaenum}[(1)]
\item ensuring strong isolation between guests, and
%
\item eventually processing every request performed by the
  guests\,\cite{barthe2011virtcert1}.
\end{inparaenum}
%
Then, they have incorporated the \ac{cpu} cache to their
model\,\cite{barthe2012virtcert2}.
%
Cache-based attacks, where attackers are able to infer information they should
not have access to by leveraging their knowledge of micro-architectural
implementation specificity, are a very important threat to virtualization
platforms.
%
The authors have shown their ideal hypervisor could prevent such attack, at the
cost of flushing the cache before each context switch.
%
They have taken their approach a step further, by focusing on constant-time
cryptography\,\cite{barthe2014virtcert3}.

The verification scope of VirtCert is large, and cover many security aspects
primordial for virtualization platforms.
%
Moreover, there have been an important specification and formalization effort
required to take into consideration the different security properties.
%
Some of them, like constant-time cryptography implementations, are
hyperpoperties, notably harder to reason with.

\paragraph{seL4}
%
Certified microkernel.

\paragraph{RockSalt}
%
Application checker

\paragraph{Moat}
%
Application checker

\section{Beyond Transition Systems}

\subsection{Sequential versus Concurrent Systems}

\begin{itemize}
\item Airlock System problem
\item Hoare Logic
\end{itemize}

\subsection{Compositional Modeling}

\subsection{Assume-Guarantee Reasoning}

\subsection{Related Works}

\section{Conclusion: Where this Thesis Stands}

\subsection{Specifying and Verifying Hardware-based Security Enforcement
  Mechanisms}

Formal verification consists in proving the correctness of a system,
characterized by a mathematical model, with respect to certain properties,
defined as logic formula.
%
By definition, \ac{hse} mechanisms fall between two domains that are hardware
design verification and low-level software components verification.

On the one hand, hardware designs verification often focus on properties
transparent to the executed software components (\emph{e.g.} cache
coherency\,\cite{stern1995cachecoherence}, linearizability of SGX
instructions\,\cite{leslie2015sgx}, hardware-based memory
isolation\,\cite{lie2003xom}).
%
Security gap in interactions of multiple platform components are less subject to
formal verification, due to their increasing
complexity\,\cite{potlapally2011hardwaresecurity}.
%
Yet they are responsible for architectural attacks we want to avoid.
%
On the other hand, low-level software components such as
seL4\,\cite{klein2009sel4} or CertiKOS\,\cite{gu2016certikos} use the features
exposed by these components, and are verified against \emph{ad hoc} hardware
models, whose scope is often limited to necessary hardware features.
%
We steer a middle course between these approaches.
%
We would rather characterize sets of requirements over low-level software
components, such that satisfying these requirements is sufficient to ensure the
hardware architecture enforces a certain property.
%
As a first step, we can verify the correctness of these requirements against a
hardware model.
%
The long term goal of this approach is to focus the verification of low-level
software components on proving they satisfy these requirements.
%
As such, our approach relates to previous research works such as
RockSalt\,\cite{morrisett2012rocksalt} (validation of arbitrary programs against
a verified software-based fault isolation\,\cite{wahbe1994sfi} policy) or
Moat\,\cite{sinha2015moat} (verification of SGX
enclave\,\cite{costan2016sgxexplained} programs with respect to
confidentiality).

\subsection{Compositional Verification of Hardware Architecture}

\bibliographystyle{unsrt}%
\bibliography{manuscript}
\end{document}