\chapter{State of the Art of Formal Verification}
\label{chapter:relatedwork}

\endquote{``\emph{Walking on water and developing software from a specification
    are easy if both are frozen.}''

  \hfill\footnotesize --- Edward V. Berard}

\vspace{1cm}\noindent
%
Our interest in formally verify hardware architecture in order to improve their
security is in line with an ongoing effort.
%
In 2011, Nachiketh Potlapally\,\cite{potlapally2011hardwaresecurity}, who was
working at Intel at the time, suggested that formal methods for security
validation is one of the possible solutions to uncover architectural attacks
ahead of time.
%
In 2016, Stephen Chong \emph{et al.} cite ``Hardware Architectures'' as area of
interest regarding the use of formal methods for
security\,\cite{chong2016report}.

The rest of this Chapter proceeds as follows.
%
First, we give primer on formal verification of hardware or software systems,
with a focus on security (Section~\ref{sec:related:review}).
%
Then, we focus on design methods which can be leveraged to ease the verification
process, in particular in regards to the model scale
(Section~\ref{sec:related:ease}).

\section{Formal Verification for Security}
\label{sec:related:review}

Formal verification consists in rigorously proving the correctness of a system
with respect to certain properties.
%
It is achieved \emph{via} the use of formal methods to exhibit a proof on an
abstract model (\ref{subsec:state:reason}).
%
Therefore, the formal definition of targeted security properties against the
model is therefore an important step of the process (\ref{subsec:state:secu}).
%
Many approaches have been proposed for formally verifying systems of varying
sizes and natures (\ref{subsec:state:approaches}).

\subsection{Reasoning about Systems}
\label{subsec:state:reason}

We are interested in hardware or software systems primarily identified by
%
\begin{inparaenum}[(1)]
\item their mutable state, and
%
\item their interface, that is a set of operations available for external
  components to use.
\end{inparaenum}
%
For instance, the state of a \ac{cpu} is characterized by the value of its
internal registers, while its interface is a instructions set.
%
Modelling such a system $C$ is usually done by defining a \ac{lts}
$M \triangleq \langle S, L, \rightarrow \rangle$.
%
$S$ is a set of abstract states which describe the concrete states of $C$.
%
$L$ is a set of labels to distinguish between transitions caused by different
operations of $C$.
%
Finally, $\rightarrow$ is a transition relation, such that for
$(p, q) \in S \times S$ and $l \in L$,
%
\[ p \xrightarrow{l} q \]
%
means it is possible for the system whose state corresponds to $p$ to shift in a
new state which corresponds to $q$ if the operation $l$ is invoked.

The structure of $M$ is given as an example, and its exact definition often vary
from one formalism to another.
%
In the meantime, the underlying principles remain the same.

\subsection{Specifying Security Properties}
\label{subsec:state:secu}

Once a system $C$ is modelled with a model $M$, we can reason about the
correctness of $C$ with respect to certain properties, by formalizing these
properties as a statement about $M$, then we exhibit a proof that this statement
is true.
%
This statement is based on the system executions, modelled as sequences of
transitions of $M$.
%
We denote $\Sigma(M)$ the set of all the possible executions of $C$, as modelled
in $M$.

\paragraph{Properties and Hyperproperties}
%
Certain security properties can be modelled \emph{via} a predicate $P$ on
executions.
%
In such a condition, the statement describing the security property is of the
forms
%
\[
  \forall \rho \in \Sigma(M), P(\rho)
\]
%
It is the case of safety properties (nothing ``bad'' happens) and liveness
properties (something ``good'' eventually happens).
%
For safety properties, a common approach is to distinguish between secure states
and insecure states, secure transitions and insecure transitions, and to require
that for an execution which starts from a secure state put the system in an
insecure state and no insecure transition occurs.
%
For instance, the BIOS Integrity security property
(Definition~\ref{def:usecase:biosint}) is a safety property security property.
%
As for liveness properties, they usually require to use a temporal logic which
provides a modal operator to reason about ``eventually''.
%
For instance, the BIOS Availability security property
(Definition~\ref{def:usecase:biosav}) is a liveness property

Other security (hyper)properties cannot be defined using such a predicate, and
requires to consider the set of executions as a whole. As a consequence, the
security statement is of the form
executions\,\cite{clarkson2010hyperproperties}, that is
%
\[
  P(\Sigma(M))
\]
%
A notable security property whose definition requires to consider couple of
executions is noninterference\,\cite{goguen1982security} of information flow
analysis.
%
A system enforces noninterference if its observable behaviour does not depends
on secret inputs, which informally translates to ``a system enforces
noninterference if, given two arbitrary executions with the same public inputs,
the system's observable behaviour remains the same''.

\paragraph{Modelling for Security}
%
The definition of a security property might be based on information that are not
available to the system $C$.
%
For instance, a x86 hardware architecture does not track information flows, but
it is supposed to enforce the BIOS Integrity security property, whose definition
requires to be able to tell which software components has been the source of the
result of a read access by the SMM code.
%
As a consequence, if we want to verify the x86 hardware architecture correctness
with respect to the BIOS Integrity security property, we need a ``information
flow aware'' model.

This raises questions about model reusability.
%
The x86 hardware architecture includes many different \ac{hse} mechanisms.
%
Defining one model for each is not an option, yet the security properties they
aim to enforce may heavily differ in terms of model requirements.

\subsection{Verification Approaches}
\label{subsec:state:approaches}

The last step of the formal verification is exhibiting a proof.
%
There are two main approaches to achieve this: model checking and theorem
proving.
%
For each approach, we give a small overview of its core principles.
%
In addition, we illustrate their verification process \emph{via} a common,
minimal example: an airlock system.
%
A airlock system is a device made of two doors, and an intermediary chamber
(Figure~\ref{fig:related:airlock}).
%
To pass through the airlock system, it is necessary to open the first door,
enter the chamber, wait for the first door to close, then open the second door.
%
The security property of a airlock system is a safety property: at any time,
there is at least one door closed.

\begin{figure}
  \centering \includestandalone[width=.4\textwidth]{Figures/Airlock}
  \caption{Design of a ``cascade airlock''}
  \label{fig:related:airlock}
\end{figure}

\paragraph{Model Checking}
%
Model checkers exhaustively and automatically explore a transition system in
order to verify it satisfies a specified properties.
%
These properties are defined it terms of predicate on the system's executions,
usually thanks to a temporal logic.
%
A temporal logic includes a set of modal operators, such as \emph{globally} (the
property is always true), or \emph{eventually} (the property becomes true in at
one point in the future).
%
The main advantage of model checkers is automation.
%
They take a model and a property as input, and output a result: a confirmation
that the property is verified, or a particular execution which does not satisfy
the property.
%
This execution is called a counterexample.
%
From a security perspective, a counterexample is very interesting, because it
potentially describes an attack path.

\begin{example}[Airlock System Verification in NuSMV]
  We use NuSMV\,\cite{cimatti2002nusmv} to model our simple airlock system.
  %
  We define a single module (called \texttt{main} according to the NuSMV
  convention).

  \inputminted[firstline=1,lastline=1]{coq}{Listings/Airlock1.nusmv}

  This module will contains three sections: \texttt{VAR} to define the state of
  the transition system, \texttt{ASSIGN} to define the transition relation, and
  \texttt{LTLSPEC} to define the airlock security property in terms of linear
  temporal logic.

  We begin with the \texttt{VAR} section.

  \inputminted[firstline=3,lastline=7]{coq}{Listings/Airlock1.nusmv}

  The state of our airlock system comprises two variables, \texttt{door1} and
  \texttt{door2}, which can be either \texttt{open} or \texttt{close}.
  %
  Because NuSMV does not a native support for labelled transitions, we embed the
  labels inside the state.
  %
  The value of the variable \texttt{action} at the beginning of the transition
  determines the effect on this transition to the variables \texttt{door1} and
  \texttt{door2}.

  We now continue with the \texttt{ASSIGN} section.

  \inputminted[firstline=9,lastline=31]{coq}{Listings/Airlock1.nusmv}

  This section can be broken down into two parts: the \texttt{init} statements,
  and the \texttt{next} statements.
  %
  Using \texttt{init}, we can specify the initial values of our state (in this
  case, both doors are close).
  %
  Using \texttt{next}, we can specify the new values of our state variables,
  after a given transition.
  %
  This is in this statement that we specify a given door cannot be opened unless
  both doors are close.

  Our airlock system is now completely modelled.
  %
  We can specify the safety property we are interested in using the
  \emph{globally} modal operator, denoted \texttt{G} in NuSMV.

  \inputminted[firstline=33,lastline=33]{coq}{Listings/Airlock1.nusmv}

  The task to exhibit a proof that the model satisfies the linear temporal logic
  formula lies with the model checker, so the user only needs to wait its
  verdict.
  %
  Unsurprisingly, the computation is favourable in our case.

  \inputminted[linenos=false]{coq}{Listings/Airlock-out.nusmv}

  An important feature of model checkers is that they generate a counter-example
  when they find a sequence of transitions which does not satisfy the
  specification.
  %
  For instance, if we slightly modify the NuSMV model of our airlock system so
  that it is no longer require for the second door to be close in order to open
  the first door, then the model checker generates the following
  counter-example:

  \inputminted[linenos=false]{coq}{Listings/Airlock-counter.nusmv}
\end{example}

\paragraph{Theorem Proving}
%
A theorem prover is a computer program to write machine-checked proofs in a
particular formal logic, that is a formal language, to express statement, a set
of axioms, and a collection of inference rules to derive new formulas from the
axioms.
%
A theorem prover' underlying logic is more expressive than what model checkers
offer, but they lack automation for nontrivial problems.
%
They do not excuse users from \emph{writing proofs}, which can be very important
in terms of effort for real world systems.

\begin{example}[Airlock System Verification in Coq]
  The \index{Coq} theorem prover\,\cite{coq} includes two languages: a rich
  functional language to write specifications ({\sc Gallina}) and a tactic
  language to write proofs ({\sc Ltac}).
  %
  We can {\sc Gallina} to describe the system in terms of states and actions to
  update this state.

  \inputminted[firstline=1,lastline=14]{coq}{Listings/Airlock.v}

  This reads as follows: a door is either open or close; a airlock system is
  made of two doors; we consider four actions which imply an update of the
  airlock system's state (opening the first or second door, closing the first or
  second door).

  {\sc Gallina} includes a special type, called \texttt{Prop}, to write logical
  propositions which can be either true or false.
  %
  We can define the transition relation of our airlock system using
  \texttt{Prop.}
  %
  In practice, this is done by enumerating the cases where the statement is
  true, and the remaining cases are considered false.

  \inputminted[firstline=16,lastline=33]{coq}{Listings/Airlock.v}

  This reads as follows: we distinguish between four classes of transitions, one
  per actions.
  %
  On the one hand, a transition which implies to open a door (case one and
  three) requires the both doors to be closed.
  %
  On the other hand, a transition which implies to close a door (case two and
  four) requires the door to be closed.

  The security property of our airlock system is a safety property: at any time,
  at least one door is close.
  %
  This property is a predicate on the system state, which we can define in {\sc
    Gallina} \emph{via} the \texttt{Prop} type.

  \inputminted[firstline=35,lastline=38]{coq}{Listings/Airlock.v}

  For the airlock to be secure, this means the \texttt{secure\_airlock}
  predicate must hold true before and after each transition.
  %
  We can express that in the form of a \emph{lemma}, that is a logical statement
  for each we exhibit a proof.
  %
  We write the proof with {\sc Ltac}, and trust \index{Coq} to refuse it in case
  it is incorrect.
  %
  The proof is written in terms of {\sc Ltac} tactics.
  %
  Each tactic corresponds to a reasoning rule.
  %
  For instance, the \texttt{right} tactic refers to the fact that given two
  statements $P$ and $Q$, then if $Q$ is true, then $P \vee Q$ is also
  true. Tactics updates the proof obligation (initially the lemma statement),
  and the goal of a \index{Coq} user is to bring back this proof obligation to
  something that has already been proven.

  \inputminted[firstline=40,lastline=57]{coq}{Listings/Airlock.v}

  This reads as follows: we prove that, given any ``secure state'', that is a
  airlock for which the \texttt{secure\_airlock} holds true, any action which
  implies a system's state update, the \texttt{secure\_airlock} also holds true
  for the system's state after the transition.
  %
  The proof is conducted by enumeration of possible actions
  (\texttt{induction}), and by definition of \texttt{Transition}
  (\texttt{inversion}).
\end{example}

\section{Design Methods Easing the Verification}
\label{sec:related:ease}

At some point, the line between a large model and a software program becomes
very thin.
%
We have identified three complementary approaches which can help writing large
models.
%
First, we advocate for the use of a monadic programming style to define a model
(\ref{subsec:related:ease:monad}).
%
Then, we discuss how component-based modelling allows for a modular reasoning
essential to deal with large systems (\ref{subsec:related:ease:component}).
%
Finally, we detail the advantages of executable models
(\ref{subsec:related:ease:exec}).

\subsection{Monadic Modelling}
\label{subsec:related:ease:monad}

When the system becomes more complex, so does the model.
%
In particular, the use of a theorem prover requires to define the model in a
pure functional language.
%
Contrary to imperative programming, where the program is written as a sequences
of steps which manipulate an underlying state, ``pure'' functions are stateless.
%
As a consequences, functions used to construct the model a system are often of
the form $S \rightarrow (A \times S)$, where $S$ is the type which describes the
state, and $A$ the actual result of the function.
%
Manipulating such a function manually is error-prone and hard to read for those
more familiar with imperative programming.
%
For instance, if we consider a simple bytecode interpreter manipulating a stack
of natural numbers, then the semantics of a \texttt{ADD} instruction could be
specified as follows:
%
\[\begin{array}{rcl}
    \func{add}(s) &\triangleq& \text{let }(x, s') = \func{pop}(s) \text{ in} \\
                  &          & \text{let }(y, s'') = \func{pop}(s) \text{ in} \\
                  &          & \func{push}(x + y)(s'')
  \end{array}\]

The sharp-eyes reader will have noticed the error in the definition of
$\func{add}$, that is the second call to $\func{pop}$ is using the initial state
$s$, rather than $s'$.
%
However, we can agree that it is subtle, and easy to miss even in a three-lines
function.

\paragraph{Monads}
%
The usual approach to ease the definition of computations which manipulate a
mutable state in addition to return a result in functional programming language
is to use a monadic programming
style\,\cite{wadler1990comprehending,jones2005io}.
%
Monads are a convenient formalism to model computations of all sorts \emph{via}
a similar interface.
%
Let $M$ be a monad, we denote $M(A)$ the type of computations ``within the
monad'' whose result is of type $A$.
%
The two fundamental monadic operations (which every monads share) are
%
\begin{align*}
  \func{pure} : A \rightarrow M(A)
  &
  & \func{bind} : M(A) \rightarrow (A \rightarrow M(B)) \rightarrow M(B)
\end{align*}
%
On the one hand, $\func{pure}$ represents the simplest computation possible,
whose consists solely into returning a given value.
%
On the other hand, $\func{bind}$ (denoted $\bind$ by convention) composes
computations: it takes the result of a first monadic computation and passes it
to another.

\paragraph{State Monad}
%
Functions of the form $S \rightarrow (A \times S)$ form the state monad, whose
main benefit is to allow for writing pure functions in an imperative style.
%
The $\func{pure}$ is defined as follows:
%
\[
  \func{pure}(x) \triangleq \lambda s. (x, s)
\]
%
That is, $\func{pure}(x)$, where $x$ is of type $A$, is a function of type
$S \rightarrow (A \times S)$ which does not modify the computation state, and
just returns $x$ as a result.
%
In addition, the $\func{bind}$ function is defined as follows:
\[
  p \bind f \triangleq \lambda s. \text{let } (x, s') = p(s) \text{ in }
  f(x)(s')
\]
%
That is, the $\func{bind}$ function of the state monad deals with passing the
computation state around from one computation to another.
%
Contrary to a tired programmers, $\func{bind}$ does not mix intermediary states.

As a consequence, it is possible to rewrite the semantics of a \texttt{ADD}
instruction as follows
%
\[
  \func{add} \triangleq \func{pop} \bind (\lambda x. \func{pop} \bind (\lambda
  y. \func{push}(x + y)))
\]
%
which is arguably not really readable.
%
Fortunately, the \textbf{do} notation, notably used in Haskell, completely hides
the $\func{bind}$ functions.
%
Monadic functions written with the \textbf{do} notation furiously look like
imperative code.
%
\[
  \begin{array}{rcl}
    \func{add} &\triangleq& x \leftarrow \func{pop} \\
               &          & y \leftarrow \func{pop} \\
               &          & \func{push}(x + y)
  \end{array}
\]

The state monad has been leveraged to model several \ac{cpu}'s instruction sets,
including Intel x86\,\cite{morrisett2012rocksalt} and
ARMv7\,\cite{fox2010armv7}.
%
As it stands, it does not ease the verification process, but reduces the
potential of errors arising from the use of a too cumbersome style.

\paragraph{Hoare Monad}
%
Hoare logic (also known as the Floyd-Hoare logic) is a popular formal system for
reasoning about the correctness of imperative computer programs.
%
Using Hoare logic, it becomes possible to formally determine the consequences of
a code snippet on the program state, using a so-called Hoare triple of the form
%
\[ \{P\}\ C\ \{Q\} \]
%
where $P$ and $Q$ are two predicates (a pre and a postcondition) on the program
state, and $C$ is the code snippet.
%
Hoare logic allows for modular reasoning.
%
Once a couple of pre and postconditions is proven for a given code snippet,
further reasoning wherein this code appears can be based solely on its pre and
postcondition.
%
For instance, Hoare logic has a rule of composition to sequentially execute two
code snippets $C$ and $C'$, that is

\begin{prooftree}
  \AxiomC{$\{P\}\ C\ \{Q\}$} \AxiomC{$\{Q\}\ C'\ \{R\}$}
  \BinaryInfC{$\{P\}\ C\text{; }C'\ \{R\}$}
\end{prooftree}

It has been shown in various occasions that the state monad not only allow for
writing a system's model in an imperative style, but it can also be leveraged to
enable a Hoare-like reasoning\,\cite{chlipala2009ynot,jomaa2016mmu}.
%
As a consequence, a model written with a so-called Hoare monad is potentially
easier to read (\emph{e.g.} for people not familiar with functional
programming), closer to the actual implementation, and easier to reason with.

\subsection{Component-based Modelling}
\label{subsec:related:ease:component}

Real world systems tend to be made of many components.
%
In such a case, the state of the system can be modelled as the scalar product of
its components' state.
%
This design choice has two important consequences:
%
\begin{inparaenum}[(1)]
%
\item it reduces modularity by explicitly coupling all the system components
  together, and
%
\item it encourages reducing the scope of the model to only take into account
  the hardware features which are directly required.
%
\end{inparaenum}

Process algebra is the study of distributed systems, by specifying separately
each of its components and verifying the properties of their composition.
%
Hardware architectures with several \ac{cpu} and active peripherals easily
qualify as ``distributed''.
%
Joonwon Choi \emph{et al.} have adapted ideas from process algebra to hardware
verification with Kami\,\cite{choi2017kami}.
%
We present here a simplified formalism, heavily inspired by their work.

An interface is modelled as a set of labels.
%
A component is modelled in terms of its state, the interface it exposes, the
interface it uses, and a transition relation, that is
$M \triangleq \langle S, I, O, \rightarrow \rangle$.
%
A transition of $M$ is denoted
%
\[ p \xrightarrow[a]{i} (v, q) \]
%
where $p \in S$ is the state of the component before the operation $i \in I$ is
called by an other component;
%
$a$ is a sequence of actions performed by the component in order to compute the
result of $i$;
%
$v$ is the result of this call, for the other component to use, and $q$ is the
modified state of the component.
%
Actions, in this context, are either local manipulations of the component's
state or calls of operations of the interface $O$.

A component $M$ can be composed with another component $M'$ to form a larger
component $M + M'$, for instance when the interface exposed by $M'$ is the
interface used by $M$.
%
To reason about $M + M'$, it is possible to define an abstract module $M''$,
verify $M + M''$ with respect to a given property, then prove that $M'$ is
equivalent to $M''$.

Reasoning about $M + M'$ can also be done using a two-steps methodology, where
$M$ is firstly verified under hypotheses about operations' results of $M'$, then
these hypotheses are proven to be true.
%
We have found a good illustration of this approach in the work of Thomas Heyman
\emph{et al.}\,\cite{heyman2012securemodel}.
%
They have presented a component-based modelling technique for
Alloy\,\cite{jackson2012alloy}, where components are primarily defined as
semantics for sets of operations.
%
One component is connected to another when it leverages its operations.
%
The goal of the analysis is to reason about component composition, in particular
with respects with security requirements.
%
These requirements are defined in terms of predicates on operation results.
%
One very interesting feature of Alloy is that it allows for reasoning about
partial models.
%
This is done by specifying a set of requirements over the operations results, in
place of a complete implementation.
%
From our perspective, this is useful for at least two situations:
%
\begin{inparaenum}[(1)]
\item it enables incremental verification, where the system is specified
  component by component
%
\item it can be leveraged to ``fill the gap'' of a system where certain
  components are under-specified, or their implementations are proprietary.
%
\end{inparaenum}
%
Because of the scale of a hardware architecture, incremental modelling and
verification is a game changer.
%
At the same time, being able to model completely and accurately each hardware
component is unlikely, as proprietary components are the norm, while open
hardware remains a niche market.
%
At least, it becomes possible to clearly define the assumptions that are made
about these black boxes

\subsection{Executable Models}
\label{subsec:related:ease:exec}
%
Over the years, \emph{executable} models have gained in popularity, and
verification approaches which were previously specific to software program
verification have been applied to them.
%
For instance, the ARM v8 specifications have been written in a dedicated
language called the ARM Specification Language (ASL)\,\cite{reid2016armv8},
whose semantics was formally established.
%
These executable specifications have been notably leveraged in order to perform
an information flow analysis for v8-M, a novel ARM feature to ``enable secure
Internet of Things applications.''

Executable models have another advantage in comparison to, for instance, what
the two models we have defined in~\ref{subsec:state:approaches} enable: they can
potentially be leveraged in a validation process.
%
Comparing the execution of a model against the real system may help uncovering
inconsistencies which otherwise could damage the value of the verification
process.

From this perspective, it is interesting to emphasis that, if not all model
defined in {\sc Gallina} within the \index{Coq} proof assistant are executable, it is
possible to leverage the extraction mechanism to that end.
%
That is, a model which can be extracted can also be executed.

\section{A Tour of Large Verified Systems}

\subsection{Hardware Systems}

\paragraph{Intel}
%

\paragraph{ARM}
%

\paragraph{\ac{xom}.}
%
The \ac{xom} microprocessor architecture maintains separate so-called
\emph{compartments} for applications.
%
With mainstream microprocessor architectures, the system software is responsible
for both memory allocation and access control.
%
It relies on configurable \ac{cpu} mechanisms, such as a \ac{mmu}, to implement
the latter.
%
On the contrary, a \ac{xom} \ac{cpu} keeps track of each memory location owner,
thanks to a tagging mechanism, and prevents an application to access a memory
location it does not own.

In 2003, David Lie \emph{et al.} have modelled the \ac{xom} architecture using
the Mur$\varphi$ model checker.
%
This model follows the principle of a \ac{lts}: a set of states, a set of
labelled transitions (called \emph{rules} in the context of this work), and a
set of transitions.
%
There are two kinds of rules: the \ac{xom} instructions set, and some additional
capabilities given to the attacker.
%
As for the transitions set, it is defined in terms of pre and postconditions.
%
On the one hand, the precondition is parameterized by the current state and the
labelled event.
%
If the pre-condition is satisfied for a given hardware state and labelled
events, then it means that event can occur in this state.
%
On the other hand, the post condition is parameterized by the initial state, the
labelled event and the resulting state.
%
It determines the consequences of that event, in terms of state update.

The security properties targeted by the \ac{xom} architecture are enforceable
security properties, and the authors rely on Mur$\varphi$ to perform the state
exploration of their model.
%
The main advantage of a model checker, in this context, is to be able to print
the trace it has found not to satisfy the targeted security property.
%
This trace describes an attack path, that is the execution steps to reproduce in
order to defeat the security enforcement.
%
Hence, the authors have been able to show with their model that the \ac{xom}
architecture was subject to several replay attacks, and they leveraged their
model to validate their countermeasures.
%
However, the state explosion problem obliges the authors to simplify their
model, in order to reduce the state combinatory.

%\paragraph{Kami}
%%
%As part of the DeepSpec project\,\cite{appel2017deepspec}, Joonwon Choi \emph{et
%  al.} have released Kami\,\cite{choi2017kami}.
%%
%Kami's main objective is to bring software formal verification technique based
%on proof assistants to hardware conception; a world that is still dominated by
%model checking approaches.
%%
%The result is a framework for the \index{Coq} proof assistant, to implement and verify
%hardware components.
%%
%Pushing the \texttt{Notation} feature of \index{Coq}, which let the developer extend the
%proof assistant parser with its own construction, to its maximum, they offer a
%development environment very close to BlueSpec\,\cite{nikhil2004bluespec}.
%%
%Kami's hardware component is specified as labelled transition systems, whose set
%of transition labels forms its interface.
%%
%A transition is defined in terms of actions, which can be local to a component,
%or consists of interacting with another component.
%%
%Finally, Kami enables modularity, by allowing for substituting one module $m$ by
%another module $m'$, if the latter is proven to be a refinement of the former.
%%
%For a given component of the computing platform, it becomes possible to reason
%about the rest of the system in terms of high-level, specification modules.
%%
%These modules are as many hypotheses which can be confirmed by proving the
%related subsystems effectively refine them.
%
%BlueSpec is a target for Kami's models extraction.
%%
%Therefore, it s possible to generate FPGA bitstream from a Kami module, using
%the BlueSpec compiler.
%%
%Although Kami allows for more components’ connection patterns than what we
%eventually propose in the context of this thesis, it is hardware-specific, thus
%is not suitable for reasoning about systems which also contain software
%components.
%%
%In addition, its purpose is to verify hardware component implementation, while
%we rather stay at the specification level.

\subsection{Software Systems}

\paragraph{sel4}

\paragraph{CertiKOS}

\paragraph{VirtCert}
%
Between 2011 and 2014, Gilles Barthe \emph{et al.} have worked on an idealized
model of a hypervisor.
%
This model is defined in terms of state, actions and a semantics of actions as
state-transformers.
%
That is, even if the authors are not using the terms \ac{lts}, their model
follows the same principles.
%
In their context, the state mixes information about both hardware components
(\ac{cpu} execution mode, registers, memory content, etc.) and software
components (list of guests, current active guest, memory mapping for the
hypervisor and the guests, etc.).
%
The actions are the hypercalls, exposed by the hypervisor for the guests to use.
%
The semantics of actions as state-transformers, that is the set of possible
transitions for the modelled system, is defined in terms of pre and
postconditions.

First, they have shown that their ideal hypervisor was
%
\begin{inparaenum}[(1)]
\item ensuring strong isolation between guests, and
%
\item eventually processing every request performed by the
  guests\,\cite{barthe2011virtcert1}.
\end{inparaenum}
%
Then, they have incorporated the \ac{cpu} cache to their
model\,\cite{barthe2012virtcert2}.
%
Cache-based attacks, where attackers are able to infer information they should
not have access to by leveraging their knowledge of micro-architectural
implementation specificity, are a very important threat to virtualization
platforms.
%
The authors have shown their ideal hypervisor could prevent such attack, at the
cost of flushing the cache before each context switch.
%
They have taken their approach a step further, by focusing on constant-time
cryptography\,\cite{barthe2014virtcert3}.

The scope of this hypervisor model is large, and cover many security aspects
primordial for virtualization platforms.
%
Moreover, there have been an important specification and formalization effort
required to take into consideration the different security properties.
%
Some of them, like constant-time cryptography implementations, are not
enforceable security properties.
%
Indeed, it is not possible, only with the trace of one execution, to know
whether a given implemantion is constant time.
%
It is required to consider all the possible traces.

\paragraph{Pip}
%
Pip is a minimal kernel whose reference implementation is written in {\sc
  Gallina}, the specification language of \index{Coq}.
%
The authors have verified their reference implementation correctly configures a
\ac{mmu} in order to isolate the applications it manages\,\cite{jomaa2016mmu}.
%
The objective is similar to the first iteration of
VirtCert\,\cite{barthe2011virtcert1}, However their approach to specify the
system software is closer to what Ynot has proposed.
%
The Pip system calls are defined in terms of a dedicated monad, which allows for
manipulating a mix of hardware state (notably including the \ac{mmu} current
configuration) and Pip internal state (\emph{e.g.} shadow \ac{mmu} tables with
additional information).
%
The correct isolation of applications is defined as a predicate on this state,
and they prove this predicate is an invariant during Pip execution:
%
from a ``secure'' state, the new state resulting of the execution of any Pip
system call is ``secure.’’

\subsection{Perspectives on HSE Mechanisms Verification}

%\begin{table}
%  \centerline{%
%    \begin{tabular}{lcp{7cm}}
%      \multicolumn{1}{c}{\bf Target}
%      & \bf Approach
%      & \multicolumn{1}{c}{\bf Hypotheses} \\
%      \hline
%      \hline
%      \ac{xom}
%      & Model Checking
%      & \\
%      \hline
%      VirtCert
%      & Theorem Proving
%      & \begin{asparaitem}
%      \item Simplified hardware model
%      \end{asparaitem} \\
%    \end{tabular}}
%\end{table}

The main characteristic of \ac{hse} mechanisms is that they are the result of
both hardware and software components, in presence of a larger system with
untrusted actors.
%
Hardware and software components are not of the same nature.
%
Hardware components are physical devices which accept inputs and compute
outputs.
%
Software components are pieces of data scattered into memory spaces, whose
semantics are determined by the processor unit that executes them.
%
While both hardware and software components have been subject to formal
verification in the past, these verification works tend to rely on different
representations.
%
Florian Lugou \emph{et al.} explain this in depth while they introduce SMASHUP,
a toolchain for unified verification of hardware-software
co-designs\,\cite{lugou2017smashup}.
%
This is why we have decided to focus on the specification level in the context
of this thesis.
%
Refining our potential conclusions up to a concrete implementation is necessary
in the long term.
%
Fortunately, it is also a very active field, with impressive flagship projects
such as DeepSpec\,\cite{appel2017deepspec}.

\section{Conclusion}