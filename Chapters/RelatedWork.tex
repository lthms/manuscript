%!TEX root = ../main.tex
\chapter{State of the Art}
\label{chapter:relatedwork}

\PC{tu annonce un état de l'art complet, mais en pratique il est plus limité aux
  transition systems - titre à revoir ?}

\endquote{``\emph{We build our computers the way we build our cities: over time,
    without a plan, on top of ruins.}''

  \hfill\footnotesize --- Ellen Ullman}

% \GH{Se pose ensuite la question de l'adéquation entre ce modèle et
% l'implémentation (code exécutable, code exécuté (ce qui suppose que le
% matériel se comporte comme prévu), circuit logique, VHDL...)  Cette adéquation
% peut-être garantie par extraction automatique du modèle (c'est le cas
% lorsqu'on dispose d'une sémantique formelle du langage source et que le
% compilateur a été prouvé) ou au contraire génération automatique de
% l'implémentation (génération automatique de code dans CoQ), par test (si la
% spec est exécutable), par insertion de pré/post condition, etc. Quels sont les
% termes utilisé par ton bouquin en référence?}
%
\noindent
%
The formal verification of a system consists of proving its correctness with
respect to a \emph{specification}\,\cite{gupta1992formal}, that is a description
of properties targeted by the system.
%
To that end, a model of the system is defined, to allow a formal reasoning of
the system behavior by means of formal methods.
%
% We distinguish between \emph{functional} specifications, which describe
% expected behaviors of their implementations, and \emph{non-functional}
% specifications, which notably include security policies.
%
In this thesis, our objective is to give a formal definition of \ac{hse}
mechanisms in the form of requirements trusted software components have to
satisfy, and to verify that these requirements do effectively provide the
enforcement of targeted security policies.
%
We steer a middle course between two domains: hardware verification and system
software verification.
%
Generally, hardware verification focus on properties which are transparent to
the executed software (\emph{e.g.} \emph{e.g.} cache
coherency\,\cite{stern1995cachecoherence}, linearizability of SGX
instructions\,\cite{leslie2015linsgx}, or hardware-based memory
isolation\,\cite{lie2003xom}), and system software verification relies on
hardware models which abstracts as much as possible of the architecture
complexity.
%
To the extent of our knowledge, the closest related project research is the work
of Jomaa \emph{et al.}\,\cite{jomaa2016mmu}, who specified what are the
requirement a microkernel must satisfy in order for a \ac{mmu} to enforce memory
isolation at all times, but this remains an isolated initiative.
%
As a consequence, the interactions of the numerous configurable hardware
features is less subject to formal verification.
%
In Chapter~\ref{chapter:speccert}, we propose a more general-purpose approach.

The rest of this Chapter proceeds as follows.
%
We detail how transition systems have been widely and successfully used in order
to verify hardware and software systems, and where does our formal definition of
\ac{hse} mechanisms stands with respect to previous work
(Section~\ref{sec:sota:formalisms})
%
Then, we introduce and justify our interest in compositional verification
approaches, which enable the ``divide and conquer'' strategy to reduce the
burden of verifying large and complex systems, and compare our compositional
framework for Coq with existing solutions (Section~\ref{section:sota:compsec}).

\section{Formal Verification of Transition Systems}
\label{sec:sota:formalisms}

Transition systems have long been used to study the behavior of discrete
systems. \GH{ref}
%
Over time, many different definitions of transition system have been proposed,
to address different classes of verification problems.
%
We explain how it is possible to model a system with transition systems
(\ref{subsec:sota:ltsdef}).
%
Then, we focus on characterizing security policies in terms of properties of
transition systems (\ref{subsec:sota:security}).
%
Finally, we describe how the concepts of this section have been used in the
literature in order to verify hardware and software systems
(\ref{subsec:sota:ltsrelated}).
%
We conclude with a summary of our motivations for implementing an ad-hoc x86
model for our experiments (\ref{subsec:sota:ltsconclusion}).

\subsection{Transition System as a Modeling Structure}
\label{subsec:sota:ltsdef}

The formal verification of discrete systems, such as computing systems, commonly
rely on some sort of \emph{transition systems} to describe the behavior of the
subject of study.
%
\GH{Ref}
%
\GH{Il faudrait en outre insister sur ton contexte. Est-ce que ces systèmes sont
  très utilisé pour modéliser les architectures hardware et pourquoi?}
%
More precisely, the system is characterized by a set of \emph{states} and by a
set of state transformation, called \emph{transitions}.
%
Transitions occur when the system interacts with its environment (\emph{e.g.} a
hardware circuit receives a clock signal, a hardware controller receives a
message from a bus, or an operating system handles a syscall).

\GH{Il faut que tu définisse un peu mieux ce qu'est un LTS et surtout la forme
  de LTS que tu va utiliser et pourquoi. (approche entonnoire). ENSUITE tu peux
  nous parler de ton exemple. Actuellement, il vient comme un cheveux sur la
  soupe...}

Throughout this Chapter, we will use the airlock system in order to act as a
running example to illustrate the introduced definitions, since it is both
simple ---our examples remain of manageable size--- and rich ---our examples do
not feel far-fetched \GH{je ne sais pas si cette expression est bien appropriée
  dans un manuscrit de thèse. Je dirai que cet exemple est suffisamment simple
  (manageable size) tout en étant suffisamment riche pour illustrer les
  différentes problématiques que tu souhaite aborder.}.
%
An airlock system is a device made of two doors, and an intermediary chamber.
%
To get across an airlock system, a user requests the opening of the first door,
enters the chamber, waits for the system to close the first door and open the
second door, and exits the chamber.

\begin{example}[Airlock System]
  \label{example:sota:airlocklts}

  \emph{Labeled} transition systems distinguish between classes of transitions
  \emph{via} the use of labels\,\cite{loiseaux1995lts} (\emph{e.g.} one label
  per syscall).
%
  A labeled transition system is a tuple \( \langle S, L, R \rangle \), such
  that \( S \) is a set of states, \( L \) is a set of labels, and
  \( R \subseteq S \times L \times S \) is the transition relation.
  %
  \GH{Cette définition ne devrait pas être dans l'exemple!}
  %
  Figure~\ref{fig:sota:airlock-lts} gives a definition of an idealized airlock
  system, modeled as a labeled transition system.

  \begin{itemize}
  \item A door of the system can be either \( \mathtt{open} \) or
    \( \mathtt{close} \).
    %
    The set of states of the airlock system reflects the Cartesian product of
    the doors states.
  \item A transition is characterized by the opening (\( \mathtt{Open}_i\), with
    \( i \in \{1, 2\} \)) and closing (\( \mathtt{Close}_i \), with
    \( i \in \{1, 2\} \)) of a door of the system.
    %
  \item The model does not allow the simultaneous opening of both doors, as
    stated by the definition of \( R \) which does not contain a transition
    which leads to the state \( (\mathtt{open}, \mathtt{open}) \).
  \end{itemize}
\end{example}

\begin{figure}
  \begin{center}
    % the mathematical definition
    \begin{minipage}[c]{0.55\linewidth}
      \[
        \begin{array}{rcl}
          S & \triangleq & \{ \mathtt{open}, \mathtt{close} \}^2 \\
          L & \triangleq & \{ \mathtt{Open}_1, \mathtt{Close}_1, \mathtt{Open}_2,
                           \mathtt{Close}_2 \} \\
          R & \triangleq & \{ (\mathtt{close}, \mathtt{close}), \mathtt{Open_1},
                           (\mathtt{open}, \mathtt{close}), \\
            & & \ (\mathtt{close}, \mathtt{close}), \mathtt{Open_2},
                (\mathtt{close}, \mathtt{open}), \\
            & & \ (\mathtt{open}, \mathtt{close}), \mathtt{Close_1},
                (\mathtt{close}, \mathtt{close}), \\
            & & \ (\mathtt{close}, \mathtt{open}), \mathtt{Close_2},
                (\mathtt{close}, \mathtt{close}) \}
        \end{array}
      \]
    \end{minipage}
    \hfill
    % a tikzpicture to illustrate the resulting automata
    \begin{minipage}[c]{0.40\linewidth}
      \begin{center}
        \begin{tikzpicture}
          \node [draw, circle split, text width=30pt, text badly centered] (cc)
          {\( \mathtt{close} \) \nodepart{lower} \( \mathtt{close} \)};%
          \node [right=of cc] (x) {};%
          \node [draw, circle split, above=of x, text width=30pt, text badly
          centered] (oc) {\( \mathtt{open} \) \nodepart{lower}
            \( \mathtt{close} \)};%
          \node [draw, circle split, below=of x, text width=30pt, text badly
          centered] (co) {\( \mathtt{close} \) \nodepart{lower}
            \( \mathtt{open} \)};%
          \node [draw, circle split, right=of x, text width=30pt, text badly
          centered] (oo) {\( \mathtt{open} \) \nodepart{lower}
            \( \mathtt{open} \)};%

          \draw [-latex] (cc) edge [bend left] node [xshift=-5pt, left]
          {\( \mathtt{Open}_1 \)} (oc);%
          \draw [-latex] (oc) edge [bend left] node [xshift=5pt, right]
          {\( \mathtt{Close}_1 \)} (cc);%

          \draw [-latex] (cc) edge [bend left] node [xshift=5pt, right]
          {\( \mathtt{Open}_2 \)} (co);%
          \draw [-latex] (co) edge [bend left] node [xshift=-5pt, left]
          {\( \mathtt{Close}_2 \)} (cc);%

        \end{tikzpicture}
      \end{center}
    \end{minipage}

    \caption{A simple airlock system modeled as a labeled transition system}
    \label{fig:sota:airlock-lts}
  \end{center}
\end{figure}

There are many modeling structures for characterizing transition systems, with
each variant better suited to tackle a particular class of systems.
%
For instance, the Kripke structure\,\cite{kripke1971semantical} is a prominent
definition of transition systems used in model checking\,\cite{clarke1999model}.
%%
% Besides, Petri net\,\cite{peterson1981petri}, process
% algebra\,\cite{bergstra1984process} or interface
% automata\,\cite{de2001interface} are better suited to model concurrent
% systems. \GH{et? Quelle structure vas-tu utiliser dans ton approche?
% Pourquoi?}

\GH{Tel quel, cette sous-section est un peu vague. Elle gagnerait à être un peu
  plus étoffée et surtout présentée de manière plus rigoureuse, carré. On ne
  comprend pas vraiment pourquoi tu nous parles de LTS sinon que d'autres le
  fond alors çà a l'air d'être une bonne idée...}

\paragraph{Model Prerequisites.}
%
Our objective is to apply these concepts in order to verify \ac{hse} mechanisms,
with the hope to uncover compositional attacks.
%
To that end, it is important to consider that
%
\begin{inparaenum}[(1)]
\item \label{needreuse}%
  hardware architectures often allow for implementing several \ac{hse}
  mechanisms, and
  %
\item \label{needreduce}%
  hardware features involved in \ac{hse} mechanisms are not safe by default,
  hence the role played by trusted software components to configure them.
\end{inparaenum}
%
In this thesis, we advocate for defining \ac{hse} mechanisms of a given hardware
architecture against a generic functional specification of this architecture,
rather than relying on ad-hoc models dedicated to specific \ac{hse} mechanisms.
%
Our hypothesis is that a pre-existing model which is comprehensive in terms of
hardware features is a prerequisite to address the threat posed by compositional
attacks.
%
Besides, this means the same model can be reused for several \ac{hse}
mechanisms, reducing the overall verification effort induced by
(\ref{needreuse}).
%
However, (\ref{needreduce}) means models of hardware architectures necessarily
contains traces which are legitimate with respect to the functional
specifications, but violate the security policy.

As a consequence, a formal definition of \ac{hse} mechanisms, like the one we
present in Chapter~\ref{chapter:speccert}, shall allow for identifying the
subset of traces wherein the mechanism is correctly implemented by the trusted
software components.
%
In this context, verifying a \ac{hse} mechanism consists of proving this set of
traces satisfies the predicate which characterizes the targeted security policy.

\subsection{Specifying Security Policies}
\label{subsec:sota:security}

The theory of properties of a transition system is now well understood, with an
intuitive classification of properties, such that:
%
\begin{itemize}
\item \emph{Safety properties}\,\cite{lamport1977proving,lamport1985logical}
  characterize that nothing ``bad'' shall \emph{never} happen.
\item \emph{Liveness properties}\,\cite{lamport1985logical,alpern1985liveness}
  characterize that something ``good'' shall \emph{eventually} happen.
\end{itemize}

We discussed in Subsection~\ref{subsec:usecase:targetedsec} the two classes of
security policies commonly targeted by x86 \ac{hse} mechanisms.
%
An access control policy is a safety property: unauthorized action by a subject
shall never happen.
%
An availability policy is a liveness property: the system shall eventually
satisfy the service.

Safety and liveness properties are expressed against the transition systems
\emph{traces}.
%
The most generic definition of a trace of a transition system is a (potentially
infinite) sequence of states generated by successive transitions.
%
Each modeling structure has its own definition of traces, which takes into
account the specificities of the model. \GH{Cette phrase est vague. Plutôt que
  de viser la généricité et rester vague, il faudrait mieux dès le départ se
  focaliser sur un cadre, en justifiant ce choix et ensuite décrire plus
  précisemment les notions pour ce cadre}
%
For instance, traces of labeled transition system will interleave a label
between each state\,\cite{vijayaraghavan2015modular}, to characterize the nature
of the transition which led to the transformation of a state of the sequence
with its successor.
%
\GH{J'ai l'impression que tu décris les LTS ici, alors qu'ils devraient être
  décris dans la sous-section précédente}
%
Afterwards, we write \( \Sigma(M) \) for the set of traces of a specification
\( M \).

Simplest properties can be defined in terms of predicates on
traces\,\cite{alpern1987recognizing,schneider2000enforceable,basin2013enforceable}.
%
\( M \) is said to be correct with respect to a property modeled as a predicate
on traces \( P \) when
%
\[
  \forall \rho \in \Sigma(M), P(\rho).
\]

On the one hand, safety properties are characterized by an invariant \( \iota \)
on trace elements (\emph{i.e.} on \( S \) in the case of the specification
\( M \)), and
%
\[
  P(\rho) \triangleq \iota(\rho_0) \wedge P(\rho_{[1..]}),
\]
%
where \( \rho_0 \) is the first element of the trace, and \( \rho_{[1..]} \) is
the trace obtained by removing the first element of \( \rho \).
%
On the other hand, liveness properties are characterized by a predicate
\( \eta \) on trace which has to be satisfied for at least a subtrace, that is
%
\[
  P(\rho) \triangleq \exists n > 0, \eta(\rho_{[..n]}) \vee P(\rho_{[1..]}),
\]
%
where \( \rho_{[..n]} \) is the subtrace made with the \( n \) first elements of
\( \rho \).

\begin{example}[Airlock Safety and Liveness Properties]
  A typical \emph{safety} property for an airlock system is that at least one
  door shall be close at any time.
  %
  We formalize this property with the invariant \( \iota \), defined as follows:
  %
  \[
    \iota( d_1, d_2) \triangleq d_1 = \mathtt{close} \vee d_2 = \mathtt{close}
  \]
  %
  The specification of the airlock system is defined with a labeled transition
  system.
  %
  Assuming the airlock device is initialized in a correct state (\emph{e.g.}
  both doors are close), we verify this specification is correct with respect to
  the safety property characterized by \( \iota \) by exhibiting a proof that
  \( \iota \) is an invariant with respect to \( R \), that is
  %
  \[
    \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \iota(d_1, d_2) \Rightarrow
    \iota(d_1', d_2')
  \]

  \begin{proof}
    By definition of \( R \), there are four transitions to consider, and our
    proof consists in an enumeration of these cases.
    %
    Case 1, both doors are close, that is \( d_1 = d_2 = \mathtt{close} \).  The
    system opens the first door, that is \( l = \mathtt{Open}_1 \). At the end
    of the transition, only the first door is open, that is
    \( d_1' = \mathtt{open} \) and \( d_2' = \mathtt{close} \).
      %
    By definition of \( \iota \), the statement to prove becomes
      %
    \[
      \mathtt{close} = \mathtt{close} \vee \mathtt{close} = \mathtt{close}
      \Rightarrow \mathtt{open} = \mathtt{close} \vee \mathtt{close} =
      \mathtt{close}
    \]
      %
    By definition of the disjunction \( \vee \), the statement reduces to
    \( \mathrm{True} \Rightarrow \mathrm{True} \), which is \( \mathrm{True} \)
    by definition of the implication \( \Rightarrow \).
    %
    The three other cases follow the exact same procedure.
    %
    \hfill \( \square \)
  \end{proof}

  In addition, we can also prove that both doors of the airlock will
  \emph{eventually} be close.
  %
  We can characterize this liveness property with the predicate \( \eta \) on
  subtraces of one element, such that
  %
  \[
    \eta(d_1, d_2) \triangleq d_1 = \mathtt{close} \wedge d_2 = \mathtt{close}
  \]
  %
  We verify the specification of the airlock system is correct with respect to
  the liveness property characterized by \( \eta \) by exhibiting a proof that
  for each transition of \( R \), one of the states satisfies \( \eta \), that
  is
  %
  \[
    \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \eta(d_1, d_2) \vee \eta(d_1',
    d_2')
  \]

  \begin{proof}
    Again, the proof proceeds by case enumeration with respect to the definition
    of \( R \), and after unfolding \( \eta \), we conclude thanks to the
    definition of \( \wedge \) and \( \vee \).
    %
    \hfill \( \square \)
  \end{proof}
\end{example}

Not all security policies can be formalized with predicates on traces.
%
For instance, \emph{noninterference}\,\cite{goguen1982security} is a
confidentiality policy which requires that so-called public inputs handled by a
given system always produce the same output, regardless of concurrent secret
inputs.
%
In this context, considering each trace independently does not make sense.
%
To witness a violation of the security policy requires to compare two traces
together.
%
As a consequence, such policies are characterized by sets of sets of traces;
they are called \emph{hyperproperties}\,\cite{marr2002hypertheading}.
%
Verifying a system with respect to a hyperproperty is harder in the general
case, but certain hyperproperties, called \( k \)-safety
properties\,\cite{marr2002hypertheading}, can be reduced to an invariant
enforcement which is more manageable to prove.
%
% For instance, we assume \( M \) handles inputs which can be either secret or
% public.
%%
% Let \( \equiv \) be the binary relation, such that two states \( s \) and
% \( r \) satisfies this relation (\( s \equiv r \)) if and only if they
% characterize two instances of the system which have handled the same public
% inputs and produced the same visible behavior.
%%
% Similarly to Gilles Barthe \emph{et al.}\,\cite{barthe2011virtcert1}, we can
% prove \( M \) \GH{Je n'aime pas cette formulation ambigue "we can
% prove". Est-ce que tu es en train de dire que Barthe a utilisé cette technique
% pour prouver le résultat? Dans ce cas, utilise la troisième personne : Barthe
% prove....} enforces noninterference if for any public input \( l \), then
%%
% \[
%   \forall (s, r) \in S \times S, s \equiv r \Rightarrow (s \xrightarrow{l} s'
%   \wedge r \xrightarrow{l} r') \Rightarrow s' \equiv r',
% \]
% where \( s \xrightarrow{l} s' \) is a transition of the system from a state
% \( s \) to a state \( s' \) wherein the input \( l \) is handled. \GH{et? Tu
% donnes des détails sur la non-interférence mais pas assez pour qu'on voit ou
% tu veux en venir. Donc soit tu t'en tiens à "certain hyperproperties ... can
% be reduced to an invariant" (avec une ref). Soit tu expliques un peu plus ce
% que tu veux nous faire comprendre...}

% \subsection{Adversary Model}
%
% An \emph{adversary model} (or \emph{threat model}) characterizes what
% attackers can and cannot do inside a system.
%%
% Security guarantees shall always be defined with respect to a certain
% adversary model, to define the limits of the system security enforcement
% mechanisms.
%%
% That is, attackers which can leverage capabilities outside of the adversary
% model are likely to defeat the security policies.
%%
% Adversary model is a theoretical tool commonly used in the verification of
% cryptographic protocol, with a well-identified hierarchy of archetypes
% (\emph{e.g.} the Dolev–Yao model allows attackers to intercept, modify,
% generate any messages, but require necessary secret to encrypt and decrypt
% messages\,\thomasrk{ref}).

% \begin{itemize}
% \item Combinatronics of system actions (Pip, VirtCert)
% \item Additional rule to model more powerful attacker (Moat, XOM + bus
%   snooping)
% \end{itemize}

\subsection{Approaches and Tools (TODO: Find better name)}

\GH{Je trouve que ce tour d'horizon des méthodes formelles est un peu rapide. Il
  gagnerait à être plus complet et mieux structuré.}
%
\GH{Il me semble que tu rentres assez vite dans des détails, certes (trop)
  facilement compréhensibles, mais qui sont spécifiques à la preuve de
  théorème. Je préfererais que tu abordes l'ensemble des méthodes formelles
  disponibles puis que tu sélectionnes assez rapidement, en le justifiant, (par
  une approche "entonoire", le type de méthode formelle que tu va utiliser dans
  ton approche. Ensuite, tu pourras faire un état de l'art plus détaillé sur ce
  type de méthode.}
%
\thomasrk[inline]{Suite à notre conversation téléphonique, j’ai changé mon fusil
  d’épaule. J’ai enlevé la partie sur la construction de la preuve (sans doute
  intéressante, mais pas forcément utile), et j'ai changé la mentalité de la
  présentation des différentes logiques pour en faire une présentation des
  outils dispo et pourquoi on a choisit Coq.}

Formal verification leverages two classes of approaches with their dedicated
tools.
%
On the one hand, the most generic approach is the construction a proof, that is
a succession of inference rules to derive the statement to be proven from
formulas known to be true.
%
Theorem provers such as Coq\,\cite{coq} or
Isabelle/HOL\,\cite{nipkow2002isabelle} provide facilities to write proofs, and
a checker to automatically verify these proofs.
%
On the other hand, it is possible to rely on algorithms whose correctness have
been formally established to handle a well-defined class of problems.
%
Model checking\,\cite{clarke2018modelc}, SAT and SMT solvers\thomasrk{ref} are
two classical instances of this approach.

The choice of one approach over another for a given verification problem is a
compromise constrained by requirements in terms of expressiveness, automation
and applicability.
%
More expressiveness for formal language increase the scope of verification
problem it can cover, but it also reduces the level of automation of the tools
used to verify its statements.
%
Fully automated procedures rely on algorithms whose computational complexity
impair their applicability for more complex problems, \emph{e.g.}  model
checking and the \emph{state explosion problem}.

We now give an overview of state of the art tools which are commonly leveraged
for formal verification of hardware and software components.
%
We have organized it according to the formal language they rely on.

\paragraph{Propositional and First-Order Logic.}
%
Propositional logic is characterized by \emph{terms}, which represents objects,
and \emph{logical operators}, such as conjunction \( \wedge \), disjunction
\( \vee \), implication \( \Rightarrow \), negation \( \neg \).
%
First-order logic\,\cite{smullyan2012fol} extends propositional logic with
\emph{predicates}, that is parameterized formulas that can be true or false with
respect to the applied terms, and \emph{quantifier}, such as \( \forall \) (all
values) or \( \exists \) (there exists a value).
%
SAT solvers (REF) form a class of tools whose purpose is to determine whether a
given propositional formula with boolean variables is satisfiable, by finding
appropriate instances for these variables.

SMT solvers have a similar purpose, but they target first-order logic formula
---without quantifiers--- and are not limited to boolean variables (SMT stands
for satisfiability modulo theories).
%
Hence, in the theory of natural numbers, a SMT solver will find that the formula
\( x > y \wedge x + y = 5 \) is satisfiable with \( \{ x = 3, y = 2 \} \), but
the formula \( x - y = 0 \wedge x \neq y \) is not.
%
The lack of quantifiers has a significant impact on formulas expressiveness
which reduces its applicability when it comes to formal verification,
\emph{e.g.} we cannot express an invariant of the form ``at any point in a
trace, a predicate \( P \) is satisfied'' if we consider a system can operate
during an infinitely.

% Finally, automated theorem provers (\emph{e.g.}
% Vampire\,\cite{riazanov2002vampire}, Z3\,\cite{de2008z3}) construct proofs of
% first-order logic formulas with quantifiers.

\paragraph{Temporal Logic.}
%
Modal logic\,\cite{chagrov1997modal} is a formal system which extends
first-order logic with modal operators.
%
Temporal logic forms a family of modal logic systems, including \emph{e.g.}
Linear Temporal Logic (LTL)\,\cite{sistla1985ltl} and Computation Logic Tree
(CTL)\,\cite{clarke1981ctl}.
%
Examples of LTL modular operators are \( \square P \) (\( P \) is always true),
\( \Diamond P \) (\( P \) will eventually become true), \( \bigcirc P \)
(\( P \) will be true after the next transition of the system).
%
CTL considers trees of possible futures (by opposition to a \emph{linear}
future).
%
CTL modal operator includes \( \mathbf{A} P \) (\( P \) is true for all possible
futures) and \( \mathbf{E} P \) (there exists at least one path where \( P \)
becomes true).
%
Temporal logic operators allow for reasoning about propositions over time on
infinite traces.
%
Temporal logic formulas are commonly verified thanks to model checkers,
\emph{e.g.}  NuSMV\,\cite{cimatti2002nusmv}, SPIN\,\cite{holzmann1997spin} or
TLA+\,\cite{lamport2002tla}.

Despite improvements in algorithms, model checkers remains subject to the
\emph{state explosion problem}, which imposes modeling compromises, \emph{e.g.}
verification of cache coherency protocols with a fixed number of cores and
address spaces limited in size (\emph{e.g.} in \cite{lie2003xom}, the model only
considers three cache locations).
%
% Other approaches can be used to that end ---for instance Gilles Barthe
% \emph{et al.} have encoded \( \square \) and \( \Diamond \) in
% Coq\,\cite{barthe2011virtcert1}--- yet model checkers have the benefit of
% automation and counter-example generation.
%
Bounded model checkers (REF) overcome this limitation by considering only finite
traces.
%
As a consequence, temporal logic formula can be translated into acceptable
inputs for SMT solvers, but this can abate the verification results, in
particular if the chosen maximum length of traces is too low.

\paragraph{Higher-order Logic.}
%
First-order logic quantifiers can only be applied on sets of terms (\emph{e.g.}
natural numbers, booleans, states of an airlock system).
%
Higher-order logic\,\cite{leivant1994hol} does not suffer the same limitation,
since they allow quantification over sets of sets, functions and predicates.
%
Hence, it becomes possible to express statements such as \emph{for all sets with
  a total order \( < \), for all pair of values \( \alpha, \beta \), then either
  \( \alpha < \beta \) or \( \beta < \alpha \) or \( \alpha = \beta \)}.
%
Therefore, higher order logic is more expressive than first-order logic, but it
comes at a cost in terms of automation.
%
Interactive theorem provers (\emph{e.g.}  Coq, Isabelle/HOL, or more recently
Lean\,\cite{de2015lean}) are based on higher-order logic.

\paragraph*{}
%
In the context of this thesis, our initial goal is to propose a formal
definition of \ac{hse} mechanisms.
%
In this context, we need higher-order logic to prove generic statements not
related to a given hardware architecture.
%
For instance, in Section~\ref{subsec:speccert2:coop}, we reason about the
composition of two \ac{hse} mechanisms whose only the targeted security policies
are known ---even the hardware model is left as a parameter of the proof--- and
such a statement is out of the scope of any first-order logic.
%
To increase our confidence in our results, we systemically wrote our proofs in
the Coq theorem prover, and we made the resulting projects available under free
software license\,\cite{letan2016speccertcode,letan2018freespeccode}.

To verify a specific \ac{hse} mechanism which can be implemented on a specific
hardware architecture, the need for higher-logic is less prominent.
%
As a consequence, if someone wants to leverage our formal definition of \ac{hse}
mechanism to verify guide its verification process, they can consider a large
class of tools, including model checkers which has the benefit of automation.
%
TODO suite

\subsection{Related Work}
\label{subsec:sota:ltsrelated}

\GH{Je n'aime pas le titre Related Work, qui est trop vague. Je préfère un titre
  explicite. Quel est (sont) le(s) point(s) commun(s) des travaux que tu vas
  présenter par la suite?}
%
Throughout this Section, we have detailed how we can model a target of
verification as a transition system in order to verify its correctness with
respect to security policies specified as predicates on set of model traces.
%
\GH{Je ne comprend pas trop cette phrase. Est-ce que tu fais un résumé de ce qui
  a été présenté avant (ce que suggère l'emplois du passé)?  Dans ce cas, il
  faudrait la faire suivre pas une phrase indiquant ce que tu va présenter
  maintenant dans cette sous-section.}


\GH{A ce stage, on ne sait pas trop sur quoi va porter le reste de l'état de
  l'art : les modèles hardware? des techniques de vérification? des politiques?
}
\paragraph{x86 Models by Intel.}
%
The trustworthiness of a verification result depends to a large extent on the
model.
%
As such, because x86 is a proprietary product, Intel remains in the best
position to produce a detailed, trustworthy model of its architecture. \GH{Je
  supprimerais ces deux premières phrases qui sont subjectives et n'apportent
  pas grand chose.}

Intel has integrated formal verification in its processors design process for
more than a decade now.
%
Intel engineers first verified arithmetic operations performed by the
processors\,\cite{harrison2000x86}, then increased the verification scope to
cover the complete execution unit\,\cite{kaivola2009formalintel}.
%
More recently, the SGX instructions ---which allow system software components to
create and manage enclaves\,\cite{costan2016sgxexplained}--- have been verified
with respect to security properties, rather than functional
specification\,\cite{leslie2015linsgx}.
%
Each project focused on one aspect of the x86 architecture and led to uncover
logic errors and inconsistencies in processor designs.
%
However, the models and tools used by Intel are rarely publicly available,
making it difficult to formally specify and verify \ac{hse}
mechanisms. \GH{Phrase à reformuler de manière simple. Si les modèles et les
  outils ne sont pas disponibles, on ne peut pas les réutiliser pour ton
  approche. point}
%
Besides, to the extend of our knowledge, Intel has not advertised about a
``global'' model of its architecture, even though Nachiketh Potlapally, who was
working at Intel at the time, discussed the benefits of such a model in
2011\,\cite{potlapally2011hardwaresecurity}. \GH{J'enfoncerait un peu plus le
  clou en précisant que chaque modèle a été réalisé indépendamment des autres et
  ne couvre qu'un aspect très réduit de l'architecture (voir seulement du
  processeur). A l'inverse, nous avons besoins d'un modèle dont le périmètre est
  large (même si tous les composants ne sont pas nécessairement décrit avec un
  niveau de détail important)}

\paragraph{x86 ISA Models.}
%
Additionally, several x86 model have been proposed by academic researchers over
the years for purposes of formally reasoning about machine-code programs.
%
To that end, they have modeled the x86 instructions set semantics, often
referred to as x86 ISA.

Probably the most mature projects include RockSalt by Morissett \emph{et
  al.}\,\cite{morrisett2012rocksalt}, Goel \emph{et al.}
framework\,\cite{goel2014x86}, and CompCert x86 assembly
model\,\cite{leroy2012compcert}.
%
These models have in common to focus on the execution of one particular software
component \GH{il serait bien de préciser quel software component pour chacun des
  travaux.}. They also remain focused on the semantics of the x86 instructions
set and abstract away as many hardware details as possible to increase the
applicability of the model, \emph{e.g.} are limited to the \ac{dram}.
%
This approach works well when software components use a limited amount of
hardware features, as applications typically do, and to reason about correction
with respect to functional specifications.
%
It has been shown in the past that it is possible to extend them, when their
abstraction is too strong and hides crucial \GH{crucial quoi? il manque un nom?}
of concrete code execution.
%
For instance, Chen \emph{et al.} have extended the hardware model of CompCertX,
a variant of CompCert used in the development of formally verified
kernels\,\cite{gu2016certikos}, with a notion of input devices and
interrupts\,\cite{chen2018interrupt}.

However the primarily focus of these projects is to reason about software
components, not the underlying hardware architecture.

\paragraph{Ad-hoc x86 Models}
%
Finally,\GH{finally ne me semble pas adéquat, puisqu'il reste une dernière
  catégorie (Other Hardware Architecture Models)} a last category of existing
x86 models is ad-hoc models, specially developed to verify a dedicated system
software component.
%
As such, they focus on hardware features used by the target of verification,
\emph{e.g.} the \ac{mmu} or the interrupt handlers. The objective of these
approaches is to verify the software component and so they suppose the hardware
will behave as expected. \GH{il faudrait en rajoutant une couche en disant que
  de notre côté c'est l'inverse, on fait des hypothèse sur le software et on
  vérifier que le comportement du hard satisfait une propriétés de sécurité sous
  ces hypothèses}

The seL4 microkernel \GH{ref ou url vers le projet en footnote} is, to date, the
most advanced and mature verified implementation of a microkernel.
%
A C implementation of the kernel is proven correct with respect to a functional
implementation modeled in the Isabelle/HOL theorem prover, and they \GH{a qui
  renvoie "they"?} have show that this model correctly enforces security
policies including information flow control, integrity and
confidentiality\,\cite{klein2009sel4}.
%
In practice, the hardware model focus on \ac{mmu}, cache and interrupt handling,
and in large parts the exact behavior of hardware devices is left
non-deterministic, in order to reduce the assumptions made by the model about
the hardware.
%
In 2016, Jomaa \emph{et al.} have proposed a formal machine-checked proof (in
Coq) of guests isolation by an idealized protokernel based on a
\ac{mmu}\,\cite{jomaa2016mmu}.
%
Similarly to seL4, their hardware model focus on \ac{mmu} and interrupt
handling.
%
In both cases, there is a clear separation between the software component model
and the hardware model, and it may be possible to extract the hardware model and
reuse it.
%
However, their scope does not include the hardware features involved in the
\ac{hse} mechanisms implemented by the \ac{bios} and described in
Section~\ref{subsec:usecase:hse:smm}.

Between 2011 and 2014, Gilles Barthe \emph{et al.} have worked on an idealized
model of a
hypervisor\,\cite{barthe2011virtcert1,barthe2012virtcert2,barthe2014virtcert3}.
%
This model is defined in terms of states, actions and the semantics of actions
as state trans\-formers.
%
The state mixes information about both hardware components (\ac{cpu} execution
mode, registers, memory content, etc.) and software components (list of guests,
the current active guest, memory mapping for the hypervisor and the guests,
etc.).
%
The set of actions describes the events which can trigger a transformation of
the model states.
%
For instance, it includes various tasks that the hypervisor must carry out, such
as scheduling the guests OS, hypercalls handling, or memory management.
%
Certain actions also witness the execution of guests, for instance when the
currently running OS reads from or writes to memory.
%
The resulting project, called VirtCert and implemented in the Coq theorem
prover, is fairly large, with over 50\,000 lines of code.
%
The verification results focus on various isolation properties, from the most
natural and straightforward (\emph{i.e.} an OS guest cannot write to or read
from a page it does not own) up to non-interference variants including
protection against cache-timing attacks, notoriously harder to reason with.
%
However, the model combines hardware and software components behavior and we
would have to make significant changes prior to using it.

%
% First, they showed that the ideal hypervisor
%%
% \begin{inparaenum}[(1)]
% \item ensures strong isolation between guests (two safety properties and one
%   2-safety property\PC{c'est quoi une ``2-safety property''?}), and
%%
% \item eventually processes every request performed by the guests (one liveness
%   property)\,\cite{barthe2011virtcert1}.
% \end{inparaenum}
%%
% Then, they incorporated the \ac{cpu} cache to their hardware model, and a
% countermeasure for preventing cache-timing attack to their hypervisor model.
%%
% They proved the effectiveness of the countermeasure.
%%
% The authors have shown their ideal hypervisor could prevent such attack, at
% the cost of flushing the cache before each context switch.
%%
% Finally, they have taken their approach a step further, by focusing on
% constant-time cryptography as an effective countermeasure against cache-timing
% attack\,\cite{barthe2014virtcert3}.
%%
% This last work also introduced a static analysis for C program, notably
% implemented as an extension for CompCert, a certified C
% compiler\,\cite{leroy2012compcert}.
%%
% \PC{trop générique/vague: ``une analyse statique ?'' laquelle ? pour faire
% quoi}


\paragraph{Other Hardware Architecture Models.}
%
The x86 architecture is not the only hardware architecture which has been the
object of formal verification projects.
%
The two latest versions of the ARM processors have been formally
specified\,\cite{fox2010armv7,reid2016armv8}.
%
It is important to emphasize that the specification of the ARMv8
architectures\footnote{There are three variants of the ARM Architecture, for as
  many use cases: the A-class architecture provides the necessary features to
  allow an operating system to manage applications, the R-class processors are
  dedicated to real-time systems, and the M-class are used in microcontrollers.}
is the result of an important 5 year effort by ARM Ltd to integrate formal
specification definition to their regular specification process. \GH{ref!}
%
The formal specification of ARMv8 architectures is written in a dedicated
language called ARM Specification Language, and has been intensively validated
against the ARM internal conformance testsuit.
%
Once the level of trustworthiness of the ASL specifications have been asserted,
they have been able to leverage them to formally verify properties of the
hardware architectures, \emph{e.g.} by compiling them to a subset of Verilog
accepted by commercial Verilog model checkers\,\cite{reid2016end}.
%
The result of these efforts is being made available on the ARM website, in
addition to regular informal specifications\,\cite{arm2018aspec}.
%
This represent an exciting opportunity for research targeting ARM architectures,
and we can only hope that it eventually becomes a standard in the industry.
%
However, it would not make sense to use the ASL language ourselves to specify
the x86 architecture. \GH{Pourquoi? Il est trop spécifique à l'architecture ARM?
  Il faudrait le dire explicitement. En outre, même si on ne peut pas le
  réutiliser tel quel, peut-on s'en inspirer? Ou pas?}
%
Indeed, ASL is used to \emph{describe} the architecture in an unambiguous
fashion, but it cannot be used as it to reason about the correctness of this
architecture. \GH{Cette phrase n'est pas très claire. Et surtout, on ne comprend
  pas en quoi ASL (ou quelque chose s'en inspirant) n'est pas adapté à ton
  approche.}

The \ac{xom} microprocessor architecture maintains separate so-called
\emph{compartments} for applications\,\cite{lie2000architectural}.
%
A \ac{xom} \ac{cpu} keeps track of each memory location owner, thanks to a
tagging mechanism, and supposedly prevents an application from accessing a
memory location it does not own.
%
In 2003, David Lie \emph{et al.} have verified the \ac{xom}
architecture\,\cite{lie2003xom} using the Mur$\varphi$ model
checker\,\cite{murphi}.
%
The verification objective of the authors was to prove that the \ac{xom}
architecture fulfills its promise to be tamper-resistant, by forbidding an
attacker to modify the memory location owned by a given application.
%
The verification proceeds as follows:
%
\begin{enumerate}
\item A first specification of the \ac{xom} architecture, called the ``actual
  model'', is defined.
  %
  States of this first model contain different hardware components of a \ac{xom}
  microprocessor, \emph{i.e.} registers, cache, volatile memory, and the
  internal machinery of \ac{xom} to track ownership of memory locations.
  %
  Transitions can be divided into two categories: the normal execution of an
  application by the microprocessor, and active tampering from an adversary
  part, leading the actual model to embed an adversary model.
  %
\item A second specification, called the ``idealized model'', abstracts away the
  memory hierarchy formed by the cache and the volatile memory, and models the
  execution of a single application, without an adversary.
  %
  From this perspective, it encodes the security property.
  %
\item To let Mur\( \varphi \) explore both models simultaneously, the authors
  have manually defined a third model.
  %
  Transitions which describe the execution of an application in the actual model
  also update the idealized model, whereas transitions which describe actions by
  the attacker only affect the actual model.
  %
\item The authors have defined a function which checks if an ``actual state'' is
  equivalent to an ``idealized state'', and let Mur\( \varphi \) verify that the
  state equivalence is an invariant of the third model.
\end{enumerate}
%
In the process of verifying \ac{xom}, the authors have been able to show with
their model that the \ac{xom} architecture was subject to several replay
attacks, and that their countermeasures \GH{plutôt "the countermeasures they
  proposed"? } were effective.

\GH{Il faudrait placer ici un commentaire plutot positif en disant que c'est le
  travaux qui se rapproche le plus du tient et que tu penses que les concepts x
  et y sont intéressants. Ensuite tu peux parler des limites qui justifie tes
  travaux.}  We believe the necessity to manually maintain a merge of two
transition systems reduces its applicability in the long run, as new
architecture versions are released frequently.
%
This is why our formal definition of \ac{hse} mechanism is characterized by a
subset of traces of a model, rather than an additional, idealized model.
%
Besides, the state explosion problem forces the authors to simplify their model,
in order to reduce the state combinatory.
%
From a security perspective, simplifying the model comes with the risk to hide
an attack path.
%
\subsection{Conclusion}
%
\label{subsec:sota:ltsconclusion}

Transition systems are a popular formalism to reason about the correctness of
computing system, and have been successfully applied to model and reason about
(part of) hardware architectures.
%
In order to specify and verify \ac{hse} mechanisms, we need a comprehensive
model of the related hardware architecture.
%
On the one hand, hardware design verification often focus on properties
transparent to the executed software components (\emph{e.g.} cache
coherency\,\cite{stern1995cachecoherence}, linearizability of SGX
instructions\,\cite{leslie2015linsgx}, or hardware-based memory
isolation\,\cite{lie2003xom}).
%
Security gap in interactions \GH{Que veut dire "security gap in interaction"?}
of multiple platform components are less subject to formal verification, due to
their increasing complexity\,\cite{potlapally2011hardwaresecurity}, and we are
not aware of any x86 hardware model comprehensive in terms of hardware
components and hardware features exposed by these components
%
On the other hand, low-level software components such as
seL4\,\cite{klein2009sel4} or CertiKOS\,\cite{gu2016certikos} use the features
exposed by these components, and are verified against \emph{ad hoc} hardware
models, whose scope is driven by their target of verification.
%
As a consequence, we would need to make significant changes prior to using them.

Thus, we face a 'chicken-and-egg' problem: we need a detailed hardware model to
reason about \ac{hse} mechanisms, yet such a model does not exist and requires a
tremendous amount of efforts to be developed, reviewed and validated; which
means we need to be reasonably certain of our modeling choices for those efforts
not going to waste. \GH{Je trouve cet argumentaire un peu casse-gueule... Tu
  laisse entendre que les modèles existants sont incomplet et spécifique à un
  mécanisme. Or tu as développé un modèle largement incomplet et dédié à la
  vérification d'un seul mécanisme (même s'il pourrait sans doute être
  étendu). }
%
We decided to develop an ad-hoc, simplified x86 hardware model which includes
the necessary hardware components abstracted away in related work.
%
Using this model, we demonstrate in Chapter~\ref{chapter:speccert2} how it is
possible to leverage our formal definition of \ac{hse} mechanisms presented in
Chapter~\ref{chapter:speccert} in order to specify and verify a \ac{hse}
mechanism implemented by the \ac{bios}.
%
This experiment allowed us to learn a lot with regard to desirable properties a
detailed hardware model could have.

\section{Compositional Verification}
\label{section:sota:compsec}

Traditional transition systems, such as the ones presented in the previous
section, impose to model the complete system all at once.
%
This raises important challenges for complex systems.
%
Theorem provers allow for leveraging parameterized models to generalize similar
components (\emph{e.g.} a memory of arbitrary size, an arbitrary number of
core), but this approach does not address the challenges posed by the
composition of many different ---and complex--- components.
%
A comprehensive hardware model in terms of hardware components would undoubtedly
make the construction of the proof unbearable for any non-trivial properties,
yet is a requirement to uncover compositional attacks by the means of formal
methods.
%
% \PC{il manque aussi l'argument de la difficulté à maintenir / faire évoluer le
% modèle si un composant change - or c'est le cas en pratique: de nombreuses
% archis sont similaires, mais avec quelques différences dans les composants}

Compositional verification is a promising family of approaches to overcome the
challenges posed by the scale of complex and large systems, as it enables to
locally abstract a subpart of the problem \emph{via} a specification.
%
Traditional compositional approaches in the programming language communities
---that the Coq community is part of--- include type
systems %\,\cite{knowles2008compositional}
(specifications for values manipulated by a program) \GH{ref sur composition
  dans les types system}, and Hoare logic systems (specifications for the state
updates provoked by the execution of a program) \GH{composition sur la logic de
  Hoare (que tu n'a pas évoqué avant..., tu devrais le mentionner dans ta
  première section)}.
%
The model checking communities take a different approach, and rather breakdown a
complex system in several stateful and interacting components \GH{ref sur
  composition dans Model Checking }.
%
The verification process proceeds as follow: components are verified in
isolation, then their composition is verified in order to ensure that local
properties remain true in the complete system.

We believe component-based verification is a particularly well-suited solution
to address the scale of hardware architectures verification, notably because it
mimic their concrete implementations.
%
The rest of the section proceeds as follows.
%
We first give an overview of compositional verification approaches which can be
leveraged to enable ``divide and conquer'' strategies to reason about a
component-based system (\ref{subsec:sota:compverif}).
%
Then, we describe the modeling structures that have been proposed to model
components and their interactions (\ref{subsec:sota:compverif}).
%
We discuss the already existing approaches which have been proposed to enable
component-based verification in theorem prover (\ref{subsec:sota:comprelated}),
and summarize our motivations to propose our own framework for the Coq proof
assistant (\ref{subsec:sota:compconclu}).

\subsection{Compositional Verification Approaches}
\label{subsec:sota:compverif}

Historically, compositional verification\,\cite{peng1998survey} is the answer of
model checking\,\cite{mcmillan1989compositional} and concurrent programs
verification\,\cite{jones1983tentative} communities to the state explosion
problem.
%
It can be divided into two complementary approaches: compositional minimization
and compositional reasoning.

\paragraph{Compositional Minimization.}
%
Components of a larger system are primarily identified by the interface they
expose to their pairs, that is the set of operations they can carry out for the
rest of the system.
%
They \GH{A quoi renvoie "they"? "Components"? "Interfaces"? "operations"?} also
``hide'' the components they are connected to, and use in order to handle their
input.
%
In this context, two components which expose the same interface can be freely
interchange on the condition that they exhibit an equivalent behavior with
respect to their interface, where the meaning ``equivalent behavior'' is really
specific to each verification problem.
%
For instance, in the context of process algebra, trace equivalence or
bisimulation are two possible definitions of equivalent
behavior\,\cite{fokkink2013pa}.

Using a behavior equivalence approach, it becomes possible to reason about one
component by abstracting away the part of the systems it interacts with
functional specifications \GH{la phrase n'est pas très claire. Je ne suis pas
  sur que "abstract away ... with" soit correct. La construction habituelle est
  "the model abstract away something from details"}.
%
This is referred to as compositional minimization in model checking.
%
The goal is to reduce the complexity of a model, with smaller \GH{que veut dire
  "smaller" ici? Simpler?} yet provably equivalent components, as pictured in
Figure~\ref{fig:sota:minicomp}. \GH{Je ne comprends pas la figure et surtout je
  ne vois pas en quoi elle illustre la réduction de la complexité par des
  composants plus petit et équivalent. Je propose de la supprimer.}
%
\GH{et? que devons nous penser de ces approches? Sont-elles adapté a ton
  approche? Quelles sont les "bonnes" idées que tu voudrais reprendre? Quelles
  sont les limitations?}


\begin{figure}
  \begin{minipage}{0.48\linewidth}
    \begin{center}
      \begin{tikzpicture}
        \node [draw, inner sep=10pt, minimum height=40pt] (p) {\( P \)};%
        \node [draw, inner sep=10pt, right=of p, minimum height=40pt] (q)
        {\( Q \)};%

        \draw ([yshift=5pt]p.east) -- ([yshift=5pt]q.west);%
        \draw ([yshift=-5pt]p.east) -- ([yshift=-5pt]q.west);%

        \draw ([yshift=10pt, xshift=-25pt]p.west) -- ([yshift=10pt]p.west);%
        \draw ([xshift=-25pt]p.west) -- (p.west);%
        \draw ([yshift=-10pt, xshift=-25pt]p.west) -- ([yshift=-10pt]p.west);%

        \draw ([yshift=15pt, xshift=25pt]q.east) -- ([yshift=15pt]q.east);%
        \draw ([yshift=5pt, xshift=25pt]q.east) -- ([yshift=5pt]q.east);%
        \draw ([yshift=-5pt, xshift=25pt]q.east) -- ([yshift=-5pt]q.east);%
        \draw ([yshift=-15pt, xshift=25pt]q.east) -- ([yshift=-15pt]q.east);%
      \end{tikzpicture}
    \end{center}
  \end{minipage}
  %
  \begin{minipage}{0.48\linewidth}
    \begin{center}
      \begin{tikzpicture}
        \node [draw, inner sep=10pt, minimum height=40pt] (p) {\( P \)};%
        \node [draw, inner sep=10pt, right=of p] (q) {\( Q' \)};%

        \draw ([yshift=5pt]p.east) -- ([yshift=5pt]q.west);%
        \draw ([yshift=-5pt]p.east) -- ([yshift=-5pt]q.west);%

        \draw ([yshift=10pt, xshift=-25pt]p.west) -- ([yshift=10pt]p.west);%
        \draw ([xshift=-25pt]p.west) -- (p.west);%
        \draw ([yshift=-10pt, xshift=-25pt]p.west) -- ([yshift=-10pt]p.west);%
      \end{tikzpicture}
    \end{center}
  \end{minipage}

  \caption{Illustration of the compositional minimization paradigm}
  \label{fig:sota:minicomp}
\end{figure}

\GH{Il manque une transition avec "compositional Reasoning". Il faudriait
  notamment bien faire ressortir les différences entre les deux concepts
  (actuellement, ce n'est pas très claire).}
\paragraph{Compositional Reasoning.}
%
Assume-guarantee\,\cite{pnueli1985ag} and
rely-guarantee\,\cite{jones1983tentative} reasoning are about proving a
component \( C \) guarantees the property \( G \) under the assumptions that a
property \( A \) is satisfied, and then proving that the rest of the system
\( S' \) satisfies \( A \).
%
This allows for concluding about the correctness of the system as a whole, that
is the composition of \( C \) with \( S' \) (denoted by \( C || S' \))
guarantees \( G \).
%
Assume-guarantee systems have been developed for model checkers, where
assumptions and guarantees are defined in temporal logic formulas \GH{ref}.

%%
% The main obstacle to the adoption of the assume-guarantee paradigm is the
% necessity for the user to provide additional inputs to the checker, in
% addition to the model and the properties to verify.
%%
% \GH{A quoi correspondent ces "additional inputs"?}
%%
% The \( L* \) learning algorithm, originally proposed by
% Angluin\,\cite{angluin1987lstart}, addresses this issue by automatically
% generating appropriate assumptions.
%%
% \GH{de ce que je connais, L* est un algorithme permettant d'apprendre
% automatiquement un automate de manière active, en requêtant une implémentation
% et en observant les réponses. Je ne vois pas le lien avec ce qui est présenté
% ici. Il faut expliquer un peu plus ce que permet cet algorithme dans ce
% contexte.}
%%
% The \( L* \) algorithm has latterly been adapted to other modeling structure,
% for instance for interface automata\,\cite{emmi2008assume}.

\paragraph*{}
%
We believe assume-guarantee contracts encodes a well-suited reasoning to work
with \ac{hse} mechanisms, and formally express the definition we gave in the
Introduction of this manuscript (Definition \ref{def:intro:hse}).
%
Conceptually, a trusted software component interacts with some hardware
components, which provide the hardware features of the \ac{hse}, \emph{via}
their interfaces, \emph{e.g.} CPU instruction sets.
%
As long as the trusted software component correctly implements the \ac{hse}
mechanism, it satisfies the assumption of the hardware components, and therefore
is guaranteed that the hardware architecture enforces the targeted security
policy.
%
\GH{J'ai un peu remanié ce paragraphe en le rendant plus générique. Peux-tu
  vérifier?}

\subsection{Compositional Modeling Structures}
\label{subsec:sota:compmod}

We now detail the popular formalisms which have been used to model components in
isolation for the purpose of compositional verification, an in particular
compositional reasoning.
%
Because our long-term objective is to apply a component-based modeling approach
to a complex hardware architecture, we focus on their applicability \GH{to such context?}.
%
A component model should be easy to write, read and exploit in the context of a
verification problem.

\paragraph{Concurrent Automata.}
%
I/O automata\,\cite{lynch1988ioautomata} are labeled transition systems which
distinguish between three classes of transitions, modeled with three disjoints
sets of labels:
%
\begin{inparaenum}[(1)]
\item input actions (denoted by \( \mathrm{in}(S) \) for an automaton \( S \)),
  %
\item output actions (denoted by \( \mathrm{out}(S) \)), and
  %
\item internal actions (denoted by \( \mathrm{int}(S) \)).
  %
\end{inparaenum}
%
They form the signature of a given automaton (denoted by \( \mathrm{act}(S) \)).
%
Its transition relation \( R(S) \) is a subset of
\( \mathrm{state}(S) \times \mathrm{act}(S) \times \mathrm{state}(S) \), where
\( \mathrm{state}(S) \) is the set of states of \( S \).
%
I/O automata are expected to be \emph{input enabled}, that is it cannot delay
the treatment of its inputs.
%
This translates as follows: for every state \( p \) and input actions \( \pi \),
it exists a state \( q \) such that \( (p, \pi, q) \in R(S) \).
%
Composition of I/O automaton is achieved \emph{via} input and output actions.
%
More precisely, when one automaton performs an output action \( \pi \) during a
transition, all automata having \( \pi \) as input action perform \( \pi \)
simultaneously.

Although by definition, I/O automata are required to be input enabled, in
practice the component they model will correctly behave (for a certain
definition of ``correct'') only if certain requirements are met regarding the
inputs they have to handle.
%
Interface automata\,\cite{de2001interfaceautomata} are similar to I/O automata,
except they do not require to be input enabled.
%
As a consequence, the definition of an interface automaton captures its
requirements over the rest of the system. \GH{Je ne comprends pas cette dernière phrase}

Another popular modeling structure is the Moore Machine, as they play a key role
in compositional model checking\,\cite{mcmillan1989compositional}, because they
can be translated into Kripke structures.

\begin{example}[Airlock System as Interface Automata]
  \label{example:sota:airlockinterface}

  In order to illustrate how a system can be broken down into small components,
  we take once again the example of the airlock system.
  %
  In this context, the most obvious component is the door.
  %
  A door has two states: it can be either open or close.
  %
  It takes two input actions: \( \mathtt{Open} \) (the action to open the door)
  and \( \mathtt{Close} \) (the action to close the door).
  %
  It does not have any output action, which means a door does not interact
  actively with the rest of the system.
  %
  One possible specification for a door can be the following interface
  automaton:

  \begin{center}
    \begin{tikzpicture}
      \node [draw, circle] (o) {1};%
      \node [draw, circle, right=of o] (c) {2};%

      \draw [-latex] (o) edge [bend left] node [above] {\( \mathtt{Open}? \)}
      (c);%
      \draw [-latex] (c) edge [bend left] node [below] {\( \mathtt{Close}? \)}
      (o);%
      \draw [-latex] (c) edge [loop right] node {\( \mathtt{Open}? \)} (c);%
      \draw [-latex] (o) edge [loop left] node {\( \mathtt{Close}? \)} (o);%

      \node [draw, fit=(o) (c), inner sep=20pt, text width=130pt, text badly
      centered] (d1) {};%

      \node [yshift=10pt, left=35pt of d1.west] (open) {};%
      \draw [-latex] (open) to node [above] {\( \mathtt{Open} \)}
      ([yshift=10pt]d1.west);%
      \node [yshift=-10pt, left=35pt of d1] (close) {};%
      \draw [-latex] (close) to node [above] {\( \mathtt{Close} \)}
      ([yshift=-10pt]d1.west);%
    \end{tikzpicture}
  \end{center}

  In addition to two doors, an airlock system needs a controller, whose purpose
  is to handle users' requests and open and close doors in consequence.
  %
  We consider a slightly different situation than the specification given in
  Example~\ref{example:sota:airlocklts}.
  %
  Here, there are only two commands, modeled with two input actions:
  \( \mathtt{Req}_1 \) (one user wants the first door to be opened) and
  \( \mathtt{Req}_2 \) (one user wants the second door to be opened).
  %
  The controller does not embed the states of the doors, but has four output
  actions, two per doors (\( \mathtt{Open}_i \) and \( \mathtt{Close}_i\), for
  \( i \in \{1, 2\}\)).
  %
  We propose the following interface automaton:

  \begin{center}
    \begin{tikzpicture}
      \node [draw, circle] (s1) {2};%
      \node [draw, circle, right=50pt of s1] (s2) {3};%
      \node [draw, circle, right=50pt of s2] (s3) {4};%

      \draw [-latex] (s1) to node [above] {\( \mathtt{Close2}! \)} (s2);%
      \draw [-latex] (s2) to node [above] {\( \mathtt{Open1}! \)} (s3);%

      \node [draw, circle, below=60pt of s3] (s4) {5};%
      \node [draw, circle, left=50pt of s4] (s5) {6};%
      \node [draw, circle, left=50pt of s5] (s6) {7};%

      \draw [-latex] (s4) to node [below] {\( \mathtt{Close1}! \)} (s5);%
      \draw [-latex] (s5) to node [below] {\( \mathtt{Open2}! \)} (s6);%

      \node [draw, circle, below=21pt of s2] (s7) {1};%

      \draw [-latex] (s7) to node [left,yshift=-5pt] {\( \mathtt{Req1}? \)}
      (s1);%
      \draw [-latex] (s7) to node [right,yshift=5pt] {\( \mathtt{Req2}? \)}
      (s4);%

      \draw [-latex] (s3) edge [bend left] node [right] {\( \mathtt{Req2}? \)}
      (s4);%
      \draw [-latex] (s6) edge [bend left] node [left] {\( \mathtt{Req1}? \)}
      (s1);%

      \node [draw, fit=(s1) (s4), inner sep=20pt, text width=220pt] (ctrl) {};%

      \node [yshift=20pt, left=35pt of ctrl] (in_open1) {};%
      \draw [-latex] (in_open1) to node [above] {\( \mathtt{Req}_1 \)}
      ([yshift=20pt]ctrl.west);%
      \node [yshift=-20pt, left=35pt of ctrl] (in_open2) {};%
      \draw [-latex] (in_open2) to node [above] {\( \mathtt{Req}_2 \)}
      ([yshift=-20pt]ctrl.west);%

      \node [yshift=45pt, right=35pt of ctrl] (out_open1) {};%
      \draw [latex-] (out_open1) to node [above] {\( \mathtt{Open}_1 \)}
      ([yshift=45pt]ctrl.east);%
      \node [yshift=15pt, right=35pt of ctrl] (out_close1) {};%
      \draw [latex-] (out_close1) to node [above] {\( \mathtt{Close}_1 \)}
      ([yshift=15pt]ctrl.east);%

      \node [yshift=-15pt, right=35pt of ctrl] (out_open2) {};%
      \draw [latex-] (out_open2) to node [above] {\( \mathtt{Open}_2 \)}
      ([yshift=-15pt]ctrl.east);%
      \node [yshift=-45pt, right=35pt of ctrl] (out_close2) {};%
      \draw [latex-] (out_close2) to node [above] {\( \mathtt{Close}_2 \)}
      ([yshift=-45pt]ctrl.east);%

      \draw (s3) edge [loop right] node {\( \mathtt{Req1}? \)} (s3);%
      \draw (s6) edge [loop left] node {\( \mathtt{Req2}? \)} (s6);%
    \end{tikzpicture}
  \end{center}
\end{example}

Labels of interface automata allows for composing together several transition
systems by synchronizing their shared transitions.
%
However, the manual definition of these components to specify sequences of input
and output transitions can quickly become cumbersome, as we our experiences \GH{"as we our experiences" à revoir} with
the definition of the airlock system controller in
Example~\ref{example:sota:airlockinterface} \GH{peut-être que définir cet example n'a pas été facile pour toi mais tel qu'il est présenté, il ne semble pas difficile. Du coup, pas sur qu'il illustre bien ce que tu veux dire ici.}.
%
Besides, interactions between components are often motivated by the need to
exchange data, \emph{e.g.} the processor interacts with the \ac{pch} to read
from or write to peripherals memories. \GH{et? que veux tu dire? Que les I/O automata ne permettent pas de modéliser ces échanges de données? Il faut que tu développes et que tu dises explicitement l'idée que tu veux exprimer.}

\paragraph{Process Algebra.}
%
Another popular family of approaches which enable compositional modeling of
complex systems is process algebra.
%
Process algebra has been developed to reason about programs executed in
parallel.
%
It is a formal system to describe interacting systems \GH{répétition sur system}, together with a proof
system for verifying them.
%
In process algebra such as Calculus of Communication
Systems\,\cite{milner1980ccs} or the Communicating Sequential
Processes\,\cite{hoare1978csp}, concurrent threads run in parallel, and
synchronization is achieved by sending and waiting for messages, as specified by
a dedicated language.

\begin{example}[Airlock System in \( \pi \)-calculus]
  \label{example:sota:airlockprocess}

  We now try to give a specification of our airlock system using a process
  algebra called \( \pi \)-calculus.
  %
  Once again, we consider three components: two doors and a controller.
  %
  Our objective is to write a specification equivalent to our interface automata
  (although we do not provide a proof of that equivalence).

  We have used the following \( \pi \)-calculus construction to specify the
  airlock system:
  %
  \begin{itemize}
  \item \( c(x). P\) means receiving a value from the channel \( c \), bounding
    this value to the name \( x \), then executing the process \( P \).
  \item \( \bar{c} \langle x \rangle . P \) means sending the value bounded to
    name \( x \) through the channel \( c \), then executing the process
    \( P \).
  \item \( [x = \mathrm{OPEN}] . P \) is a guard, that is \( P \) is executed if
    \( x \) is equal to the value \( \mathrm{OPEN} \).
  \item \( P + Q \) is the nondeterministic choice operator, we use it here in
    conjunction with guards to implement a \texttt{if-then-else} construct. That
    is, considering the process
    %
    \[
      c(x) . ([x = 1] . P + [x = 2] . Q + R)
    \]
    %
    If the value received from \( c \) is \( 1 \), \( P \) is executed.
    %
    If it is \( 2 \), then \( Q \) is executed. Otherwise \( R \) is executed.
  \item \( \nu c. P \) means a new channel \( c \) is created, and available for
    \( P \) to use it.
  \item \( P || Q \) is the parallel execution of \( P \) and \( Q \).
  \end{itemize}

  \[
    \begin{array}{rcl}
      \mathrm{CloseDoor}(c)
      & \triangleq
      & c(x) . \ ([x = \mathrm{OPEN}] . \mathrm{OpenDoor}(c) \\
      &
      & \qquad + \mathrm{CloseDoor}(c)) \\
      & & \\
      \mathrm{OpenDoor}(c)
      & \triangleq
      & c(x) . \ ([x = \mathrm{CLOSE}] . \mathrm{CloseDoor}(c) \\
      &
      & \qquad + \mathrm{OpenDoor}(c)) \\
      & & \\
      \mathrm{Controller}(c, d_1, d_2)
      & \triangleq
      & c(x). \ \ [x = \mathrm{OPEN}_1] . \bar{d_2} \langle
        \mathrm{CLOSE} \rangle . \bar{d_1} \langle \mathrm{OPEN} \rangle . \mathrm{Controller}(c, d_1, d_2) \\
      &
      & \qquad + [x = \mathrm{OPEN}_2] . \bar{d_1} \langle
        \mathrm{CLOSE} \rangle . \bar{d_2} \langle \mathrm{OPEN} \rangle. \mathrm{Controller}(c, d_1, d_2) \\
      & & \\
      \mathrm{System}
      & \triangleq
      & \nu c. \nu d_1. \nu d_2. (\mathrm{Controller}(c, d_1, d_2) \\
      &
      & \quad\qquad\qquad ||\ \mathrm{CloseDoor}(d_1) \\
      &
      & \quad\qquad\qquad ||\ \mathrm{CloseDoor}(d_2))
    \end{array}
  \]

  The system, modeled with the process \( \mathrm{System} \) creates the
  channels used by its components to communicate, then starts their concurrent
  executions.
  %
  A door is either open or close, and we model this with two mutually recursive
  processes \( \mathrm{CloseDoor} \) and \( \mathrm{OpenDoor} \).
  %
  They take one channel \( c \) as an argument, then wait for new inputs coming
  from \( c \).
  %
  A controller is a recursive process which takes three channels \( c \),
  \( d_1 \) and \( d_2 \) as arguments.
  %
  It waits for new requests coming from \( c \).
  %
  When it receives a new request to open the first (resp. second) door, it first
  close the second (resp. first) door, using the channel \( d_2 \) (resp.
  \( d_1 \)).
  %
  Then, it opens the first (resp. second) door, using the channel \( d_1 \)
  (resp. \( d_2 \)).
\end{example}

Process algebras such as \( \pi \)-calculus are well suited formalisms for
describing component interactions.
%
However, their applicability is limited by the low-level description of the used
languages and their minimalistic semantic. \GH{Cette conclusion est un peu rapide et minimaliste. Difficile à comprendre en outre. Que veux dire "low-level description" et "minimalist semantic"? Si on remet dans le context de ton approche, en quoi sont-ils peu adaptés?}

\paragraph{Programs with Effects.}
%
The relation between one component and the rest of the system it is connected to
is reminiscent of the programming language to model and verify large programs
with side effects realized by an outer environment (\emph{e.g.} an operating
system). \GH{phrase trop longue et difficile à comprendre}
\GH{Ce paragraph est plus difficile à suivre que les autres. Tu enchaînes beaucoup de notions assez nouvelles (Monad, Effect, Effect Handler...) par rapport au reste et trop rapidement. En outre, tu nous parles brusquement de langage pure et fonctionnel et on ne voit pas le rapport avec ce qui a été présenté jusqu'à maintenant. Il faut à mon avis mieux introduire cette partie et mieux faire comprendre pourquoi tu t'y intéresse, d'autant plus que c'est l'approche que tu vas utiliser!}
%
Modeling side effects in pure programming language, such as Haskell or {\scshape
  Gallina}, is usually achieved thanks to
Monads\,\cite{wadler1990comprehending,jones2005io}, \emph{e.g.} the State Monad \GH{n'utilise pas de majuscule pour des noms communs! D'ailleurs, plus loin, tu n'utilises plus de majuscule pour "monad"} to seamlessly write computations which manipulate a global state, or the List
Monad to abstract non-determinism,
%
However, Monads have a reputation not to compose very
well\,\cite{hyland2006combining}, despite construction such as Monad
Transformers\,\cite{liang1995mtl}.
%
Algebraic effects and effect handlers are a generic approach overcoming this
challenge, with many different implementations (\emph{e.g.}
Eff\,\cite{bauer2015effects}, {\scshape Idris}\,\cite{brady2013idris}, or
Haskell\,\cite{kiselyov2013extensible}).
%
In this context, \emph{effects} are characterized by sets of operations,
\emph{e.g.} \texttt{get} and \texttt{set} for global state manipulation.
%
These operations are expected to produce a value whose type is known by
definition.
%
For instance, \texttt{get} produces a value of the same type as the global
state.

On the one hand, programs with effects are pure computations which compose
effects results together.
%
On the other hand, handlers model the environment which realizes these effects,
computes their results, and manipulates programs control flows.
%
One possible representation of the relation between programs with effects and
effect handlers is by the means of coroutines\,\cite{kiselyov2013extensible}.
%
When a program with effects requires the result of a given effect, it sends a
request to the handler, and waits for the result.

\GH{et? que doit-on penser de tout çà? Est-ce intéressant pour ton problème? Quelles sont les éventuelles limitations?}

\subsection{Related Work}
\label{subsec:sota:comprelated}

\GH{Sur quoi porte cet état de l'art? Il faudrait un titre de sous-section plus précis.}

In Chapter~\ref{chapter:freespec}, we show how it is possible to model a
hierarchy of components which interacts \emph{via} their interfaces by means of
programs with effects and effect handlers. \GH{Référence en avant. Beurk. En gros tu dis : "j'ai utilisé telle technique, donc je vais vous en parler dans l'état de l'art". Il faudrait plutôt que ta manière de présenter l'état de l'art amène naturellement le lecteur à se persuader que cette technique est la bonne pour le problème que tu adresses. Il sera alors beaucoup plus enclin à lire un état de l'art détaillé sur la technique en question. Il faut revoir la fin de la sous-section précédente et l'introduction de cette sous-section en ce sens.}
%
The main idea is that a component can be modeled as a handler for the interface
it exposes, in terms of program with effects of the interface it uses.
%
To our surprise, we did not find any generic project to write and verify
programs with effects and effect handlers for {\scshape Gallina}, but
several related approaches exist.

\paragraph{{\scshape Kami}.}
%
In 2017, Joonwon Choi \emph{et al.} have released {\scshape
  Kami}\,\cite{choi2017kami}, a framework for Coq to design, verify and extract
(in the form of BlueSpec\,\cite{nikhil2004bluespec} programs) hardware
components implementations.
%
In {\scshape Kami}, components are defined as modules \( M \). Each module is a
particular labeled transition system, whose transitions are of the form
%
\[
  p \xrightarrow[a]{i} (v, q)
\]
%
where  \( i \)  is an operation called by another component, \( p \) is the state of the component before the operation \( i \), \( a \) is a program of actions performed by the
component in order to compute the result of \( i \), \( v \) is the result of
\( i \) that is returned to the caller, and \( q \) is the modified state of the
component.
%
Actions, in this context, are either local manipulation of the component's state
or calls of operations handled by other components.

To reason about \( M \) with respect to a specification \( M_S \), {\scshape
  Kami} introduces a refinement relation \( \sqsubseteq \).
%
A module \( M \) refines a module \( M_S \) (\emph{i.e.} \( M \) is an
implementation of \( M_S \)) if any traces of \( M \) can also be produced by
\( M_S \).
%
A component \( M \) can be composed with another component \( M' \) to form a
larger component \( M + M' \), for instance when the operations exposed by
\( M' \) are used by \( M \).
%
The authors introduced another ``modular'' refinement property, whose simplest
expression could be
%
\[
  M \sqsubseteq N \wedge R \sqsubseteq S \Rightarrow M + R \sqsubseteq N + S
\]
%
This approach is related to compositional minimization, where one component
is reduced to a simpler, more abstract model, to reduce the complexity of the
proofs.
%
They proved the correctness of a realistic multiprocessor system with respect to
a simple ISA semantics and Lamport's sequential consistency (SC) \thomasrk{ref
  lamport} \GH{oui, il faut une ref! :-)} as the memory model.
%
Their proofs consist in a succession of refinement proofs from their
implementation to high-level modules which model their semantics and the SC
memory model.

{\scshape Kami} provides a general-purpose framework for hardware verification.
\GH{Il manque le début de la phrase} is hardware-specific, thus is not suitable to reason about systems which also
include software components.
%
We believe this is a strong argument in favor of compositional reasoning for
hardware architectures. \GH{Cet argument n'est pas très claire. Tu as bien présenté Kami, on comprend bien qu'il correspond à la catégorie "minimization reasoning". Tu dis qu'il est centré sur le hardware seulement, ok.  Mais je ne vois pas en quoi çà permet de conclure que "minimization reasoning" et plus adapté que "compositionnal reasoning" pour ton approche. Pourrais-on adapter Kami pour inclure des composants software? Soit, a priori, tu peux établir qu'une famille (compositionnal  ou minimization reasoning) est plus adaptée que l'autre et dans ce cas il faudrait l'expliquer plus tôt, quand tu présentes les deux familles, et t'appuyer sur cet argument déjà présenté pour critique Kami ici. Soit il faut mieux expliquer.}
%
In comparison, our framework presented in Chapter~\ref{chapter:freespec} is more
high-level \GH{çà veut dire quoi "high level"?}, and focus on compositional reasoning ---in the form of
assume-guarantee contracts--- rather than minimization reasoning.

\paragraph{\texttt{Coq.io}.}
%
The \texttt{Coq.io} framework, developed and released by Guillaume Claret
\emph{et al.}\,\cite{claret2015coqiowww}, have been originally proposed in order
to allow the definition and verification of interactive programs in Coq by the
means of use cases\,\cite{claret2015coqio}.
%
Such programs are defined in a dedicated monad, with side effects (\emph{e.g.}
system calls to read from or write to a file) axiomatized as monadic operations
of this monad.
%
The proofs rely on scenarios which determine how an environment (\emph{e.g.} an
operating system) would react to the program requests.
%
The verification goal is to verify that, under the hypothesis that the
environment is correct with respect to a scenario, then a program with effects
is also correct with respect to an expected trace of side effects operations it
produces.

The approach used by \texttt{Coq.io} paves the road towards a compositional
approach reasoning.
%
A program with effects can be verified, but the verification of the composition
of this program with its environment is out of the scope of the project.
%
Our framework does not suffer the same limitation.

\paragraph{B-Method.}
%
The B-method\,\cite{abrial2005b} is a well-established method of software
development based on the B formal system.
%
B allows for the definition of functional specifications, called abstract
machines, and the refinement of these specifications up to executable code.
%
An abstract machine is characterized by a set of variables, and several
operations which update these variables. Preconditions in form of
predicates on the machine variables can be attached to a given operation to
specify when the operation can be used.

B has already been used in order to reason about systems made of components
which interact \emph{via}
interfaces\,\cite{souquieres2005verifying,chouali2006proving,lanoix:hal-00105041}.
%
In particular, Lanoix \emph{et al.}\,\cite{lanoix:hal-00105041} proposed the
following reasoning:
%
\begin{itemize}
\item Interfaces and requirements over components which expose these interfaces
  are defined in the form of an abstract machine, where the operations
  preconditions models the assumption a user needs to satisfy.
  %
\item A component which exposes this interface is expected to be a refinement (a
  more concrete implementation) of this abstract machine.
  %
\item A model of a component which uses an interface can \emph{include} the
  abstract machine which models this interface and uses its operations. \GH{cette dernière phrase n'est pas très claire}
\end{itemize}
%
Our approach apply a similar process within the Coq proof assistant, but with a
clearer separation between the operations exposed by an interface and the
requirements over the component which exposes it.
%
This offer use more flexibility \GH{que veux "use more flexibility"? Est-ce que "Our approach offers more flexibility" n'est pas plus approprié?} to prove that a given component correctly uses
(satisfy its assumption) or exposes (enforce its guarantee) interface.
%
We believe this is a valuable property considering that we want to prove the
same hardware architecture correct \GH{correctness} with respect to several \ac{hse} mechanisms.

\paragraph{Compositional Security.}

The projects detailed above focus on verifying functional specifications, but
the use of component-based modeling has also been used to verify security properties of a given
system.

Heyman \emph{et al.} have proposed a component-based modelling technique for
Alloy\,\cite{jackson2012alloy} \GH{c'est quoi Alloy?}. In their approach, components are primarily defined as
semantics for a set of operations\,\cite{heyman2012securemodel}; a component is
connected to another when it leverages its operations. \GH{Ce n'est pas très claire. Difficile de comprendre sans connaitre le papier}
%
Alloy leverages a model finder to verify a composition of these components
against known security patterns, and to assume or verify facts about operations
semantics.
%
However, it lacks an extraction mechanism, which makes it harder to validate the
model.
%
On the contrary, our formalism and framework is compatible with the extraction
mechanism of Coq, meaning a component model can be extracted in an {\scshape
  OCaml} program. \GH{Mouais, en même temps, tu n'utilises pas cette fonctionnalité dans ton approche, donc je ne trouve pas que c'est un argument "fort", bien qu'on puisse le noter également. Tu n'as pas d'autres critères de comparaison plus en phase avec ce que tu as fait?}

Finally, Garg \emph{et al.} have presented in 2010 a formal framework for
compositional reasoning where components are defined in terms of programs
written in a dedicated functional language with algebraic
effects\,\cite{garg2010compositional}.
%
Probably the main difference between our two approaches is that they rely on a
dedicated programming language, while our programs with effects and effect
handlers are regular {\scshape Gallina} terms.
%
As a consequence, we can use the full interactive proof development environment
of Coq in order to write and validate our proofs.

\subsection{Conclusion}
\label{subsec:sota:compconclu}

Our formal definition of \ac{hse} mechanism assumes there exists a formal model
of the hardware architecture.
%
The development of our proof of concept, implemented in
Coq\,\cite{letan2016speccertcode}, convinced us that such a model cannot be
monolithic.
%
Otherwise, it would make the proof burden hard to bear.
%
Compositional verification is thus a very important domain of research for the
verification of large, realistic models.

With FreeSpec\,\cite{letan2018freespeccode}, we aim to provide a generic
compositional reasoning framework for Coq.
%
As detailed in Chapter~\ref{chapter:freespec}, FreeSpec leverages programs with
effects and effect handlers to model component-based system, and introduces
so-called abstract specification in order to enable a verification methodology
inspired by the assume-guarantee paradigm.
%
In doing so, FreeSpec is at the intersection of several research domains.
%
Our work is in the continuity of \texttt{Coq.io}\,\cite{claret2015coqio}, but
our abstract specifications are more generic and expressive than their
scenarios.
%
We have shown how programs with effects and effects handlers can be used to
modularly verify a complex system made of interconnected components, \emph{via}
the notion of interface as the rendezvous point.
%
The principle of our approach is similar to what {\scshape Kami}
achieves\,\cite{choi2017kami}, but is not hardware specific.
%
In addition, our abstract specifications allow for compositional verification,
while {\scshape Kami} focuses on refinement proofs.
%
To the best of our knowledge, the closest related research is the work of Garg
\emph{et al.}\,\cite{garg2010compositional}, with the difference than we
leverage the Coq proof assistant to verify our models. \GH{Il faudrait insister sur le fait que Garg ne fait pas de vérification, ce qui est implicite dans ta phrase. On pourrait penser qu'il ont simplement utilisé un autre outil que Coq}

\section{Conclusion}
\label{sec:sota:conclusion}

\GH{Il faudrait faire ici une conclusion rapide qui résume les deux problèmes auxquels tu t'es attelé et fasse la transition avec tes deux parties suivantes. Rapide, concis, claire ;-)}
