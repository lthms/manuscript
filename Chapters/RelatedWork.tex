%!TEX root = ../main.tex
\chapter{State of the Art of Formal Verification}
\label{chapter:relatedwork}

\endquote{``\emph{We build our computers the way we build our cities: over time,
    without a plan, on top of ruins.}''

  \hfill\footnotesize --- Ellen Ullman}

\vspace{1cm}\noindent
%
Formal verification consists in proving the correctness of a system ---the
\emph{Implementation}--- with respect to certain properties.
%
To that end, a verifier
%
\begin{inparaenum}[(1)]
\item defines a formal description of the system ---the \emph{Specification}---,
  %
\item exhibits a proof that a formal description of the system satisfies a
  statement (defined in an arbitrary logic) which encodes the property with
  respect to which the correctness shall be proven, and
  %
\item exhibits a proof of correspondence between the implementation and the
  specification.
\end{inparaenum}
%
In this context, the terms ``implementation'' and ``specification'' refer to a
subjective relation between two layers of abstraction: the specification is more
abstract than its implementation, and formal verification proofs can be
organized in an arbitrary number of abstraction layers
%
The definition of a specification shall ease the construction of the proof of
correctness, while the correspondence proof allows for extending the properties
of the specification to the implementation.
%
The instantiation of the terms ``formal description'', ``correspondence proof'',
``properties'' or ``correctness proof'' may considerably vary from one system to
another.
%
Similarly, the nature of the proofs and their construction greatly depend on the
tools used by the verifier.
%
For our part, we want to construct correctness proofs of a hardware architecture
specification, with respect to security properties, and using the Coq theorem
prover (as explained in Chapter~\ref{chap:introduction}).
%
The rest of this Chapter is organized with this objective in mind

First, we describe popular formalisms used to define formal descriptions of
hardware specifications (Section~\ref{sec:sota:formalisms}).
%
Then, we focus on the encoding of security properties as logic statements
(Section~\ref{sec:sota:security}).
%
Finally, we give an overview of related works
(Section~\ref{sec:sota:relatedwork}).
% and we conclude this Chapter by positioning our contributions in that respect
% (Section~\ref{...}).

\section{Transition Systems}
\label{sec:sota:formalisms}

\subsection{Definition}

The formal verification of discrete systems, such as computing systems, commonly
rely on some sort of \emph{transition systems} to describe the behavior of the
target.
%
More precisely, the system is characterized by a set of \emph{states} and by a
set of \emph{atomic} state-transformation, called \emph{transitions}.
%
Transitions occur when the system interacts with its environment (\emph{e.g.} a
hardware circuit receives a clock signal, a hardware controller receives a
message from a bus, an operating system handles a syscall).
%
Additionally, \emph{labeled} transition systems distinguish between classes of
transitions \emph{via} the use of labels (\emph{e.g.} one label per syscall).

To the best of our knowledge, the more straightforward definition of a labeled
transition system, as used by Vijayaraghavan \emph{et al.} in their work on
modular verification of multiprocessor hardware
designs\,\cite{vijayaraghavan2015modular}, is a tuple
\( \langle S, L, R \rangle \), such that \( S \) is a set of states, \( L \) is
a set of labels, and \( R \subseteq S \times L \times S \) is the transition
relation.

\begin{example}[Airlock System]
  Figure~\ref{fig:sota:airlock-lts} illustrates an instantiation of this
  definition for a simple airlock system.
  %
  An airlock system is a device made of two doors, and an intermediary chamber.
  %
  To get across a airlock system, a user requests the opening of the first door,
  enters the chamber, waits for the system to close the first door and open the
  second door, and exits the chamber.

  \begin{itemize}
  \item A door of the system can be either \( \mathtt{open} \) or
    \( \mathtt{close} \).
    %
    The set of states of the airlock system reflects the combinatronics of the
    doors states.
  \item A transition is characterized by the opening (\( \mathtt{Open}_i\), with
    \( i \in \{1, 2\} \)) and closing (\( \mathtt{Close}_i \), with
    \( i \in \{1, 2\} \)) of a door of the system.
    %
  \item The system does not allow the simultaneous opening of both doors, as
    stated by the definition of \( R \) which does not contains a transition
    which leads to the state \( (\mathtt{open}, \mathtt{open}) \).
  \end{itemize}
\end{example}

\begin{figure}
  \begin{center}
    % the mathematical definition
    \begin{minipage}[c]{0.55\linewidth}
      \[
        \begin{array}{rcl}
          S & \triangleq & \{ \mathtt{open}, \mathtt{close} \}^2 \\
          L & \triangleq & \{ \mathtt{Open}_1, \mathtt{Close}_1, \mathtt{Open}_2,
                           \mathtt{Close}_2 \} \\
          R & \triangleq & \{ (\mathtt{close}, \mathtt{close}), \mathtt{Open_1},
                           (\mathtt{open}, \mathtt{close}), \\
            & & \ (\mathtt{close}, \mathtt{close}), \mathtt{Open_2},
                (\mathtt{close}, \mathtt{open}), \\
            & & \ (\mathtt{open}, \mathtt{close}), \mathtt{Close_1},
                (\mathtt{close}, \mathtt{close}), \\
            & & \ (\mathtt{close}, \mathtt{open}), \mathtt{Close_2},
                (\mathtt{close}, \mathtt{close}) \}
        \end{array}
      \]
    \end{minipage}
    \hfill
    % a tikzpicture to illustrate the resulting automata
    \begin{minipage}[c]{0.40\linewidth}
      \begin{center}
        \begin{tikzpicture}
          \node [draw, circle split, text width=30pt, text badly centered] (cc)
          {\( \mathtt{close} \) \nodepart{lower} \( \mathtt{close} \)};%
          \node [right=of cc] (x) {};%
          \node [draw, circle split, above=of x, text width=30pt, text badly
          centered] (oc) {\( \mathtt{open} \) \nodepart{lower}
            \( \mathtt{close} \)};%
          \node [draw, circle split, below=of x, text width=30pt, text badly
          centered] (co) {\( \mathtt{close} \) \nodepart{lower}
            \( \mathtt{open} \)};%
          \node [draw, circle split, right=of x, text width=30pt, text badly
          centered] (oo) {\( \mathtt{open} \) \nodepart{lower}
            \( \mathtt{open} \)};%

          \draw [-latex] (cc) edge [bend left] node [xshift=-5pt, left]
          {\( \mathtt{Open}_1 \)} (oc);%
          \draw [-latex] (oc) edge [bend left] node [xshift=5pt, right]
          {\( \mathtt{Close}_1 \)} (cc);%

          \draw [-latex] (cc) edge [bend left] node [xshift=5pt, right]
          {\( \mathtt{Open}_2 \)} (co);%
          \draw [-latex] (co) edge [bend left] node [xshift=-5pt, left]
          {\( \mathtt{Close}_2 \)} (cc);%

        \end{tikzpicture}
      \end{center}
    \end{minipage}

    \caption{An simple airlock system modeled as a labeled transition system}
    \label{fig:sota:airlock-lts}
  \end{center}
\end{figure}

There are many modeling structures one can use to characterize transition
systems, with each variant better suited to tackle a particular class of
systems.
%
For instance, the Kripke structure\,\cite{kripke1971semantical} is a notorious
variation of (labeled) transition systems used in model
checking\,\cite{clarke1999model}, while Petri net\,\cite{peterson1981petri},
process algebra\,\cite{bergstra1984process} or interface
automata\,\cite{de2001interface} are better suited to model concurrent systems.

\subsection{Introduction to Formal Methods}

Theorem prover rely on formal systems in which formulas (also called
propositions) of a formal language represent statements which can either be true
or false.
%
Each formal system (\emph{e.g.} higher-order logic\,\cite{leivant1994hol})
relies on a set of axioms, that are formulas known to be true, and inference
rules which allows for deriving new formulas.

\paragraph{Propositions and Inference Rules.}
%
The statement that a proposition \( P \) is true is commonly denoted by
\( \vdash P \).
%
A proposition \( P \) may also be true on the condition that propositions
\( Q_0, Q_1, ... Q_n \) is also true.
%
This statement is denoted by \( Q_0, Q_1, ... Q_n \vdash P \).
%
A statement is proven true when it is part of the base of axioms or we use
inference rules to derive already proven statements.
%
By doing so, we construct a \emph{proof}.
%
For example, a notorious inference rule is the \emph{Modus ponens}, which states
that if a proposition \( P \) is true, and the proposition \( P \Rightarrow Q \)
is also true, then the proposition \( Q \) is true, that is
%
\[
  P\text{, }(P \Rightarrow Q) \vdash Q
\]
%
Using the \emph{Modus ponens}, it becomes possible to construct a proof of
\( \vdash Q \) from a proof of \( \vdash P \) and a proof of
\( \vdash P \Rightarrow Q \).
%
Figure~\ref{fig:sota:inference} gives a l list of common inference rules.
%
Conditional statements, once proven, become new inference rules to be used to
construct proofs.

Formally constructing a proof can quickly become cumbersome as propositions
become more complex.
%
They can be described in the form of carefully worded sentences.
%
Another popular approach is to write them as so-called proof trees.
%
Each node of the tree is a proof obligation.
%
The children of a given proof obligation or proofs which allows for concluding
about the node goal, by using an inference rule of the system.
%
By convention, a node goal and its children are separated by a line labeled with
the name of the inference rule.
%
The leafs of the trees are the statement known to be true, either because they
are part the system axioms or because they have already been proven before.
%
Therefore, a proof which only consists in applying the \emph{Modus ponen} can be
represented as follows:
%
\begin{prooftree}
  \AxiomC{\( P \)} \AxiomC{\( P \Rightarrow Q \)} \RightLabel{\small {\scshape
      Modus Ponens}} \BinaryInfC{\( Q \)}
\end{prooftree}

\begin{figure}
  \begin{center}
    \begin{tabular}{ll}
      {\scshape Modus ponens} & \( P \Rightarrow Q\text{, }P \vdash Q \) \\
      {\scshape Modus tollens} &
                                 \( P \Rightarrow Q\text{, }\neg Q \vdash \neg P \) \\
      {\scshape Conjunction:} & \( P\text{, }Q \vdash P \wedge Q \) \\
      {\scshape Addition:} & \( P \vdash P \vee Q \)
    \end{tabular}
  \end{center}

  \caption{Examples of common inference rules}
  \label{fig:sota:inference}
\end{figure}

Constructing a proof and verifying its correctness quickly becomes challenging.
%
Theorem provers such as Coq\,\cite{coq} or Isabelle/HOL\,\cite{nipkow2002isabelle} provide
facilities to write proofs, and verify these proofs (supposedly in a more
reliable way than humans).
%
Therefore, the quality of a theorem prover is measured by its capacity to reject
ill-formed proofs.
%
To avoid this pitfall, modern theorem provers are built as ``certified'' layers
around a certification as small and simple as possible.
%
The idea is that, as long as the kernel does not contain a bug, advanced
features implemented inside a certified layer cannot introduce inconsistency in
the proof-checking process.
%
This greatly diminishes the risk to have inconsistencies in the proof checker,
although this happened in the
past\,\cite{claret2015falso,griffioen1998comparison}.
%
Another common approach is to rely on an algorithm whose correctness has been
formally established to handle a well-defined class of problem.
%
This allows for automating the verification process.
%
Abstract interpretation\,\cite{cousot1977absint} and model
checking\,\cite{clarke2018modelc} are two notorious instances of this approach.

\paragraph{Formal Systems.}
%
Choosing a formal language is a key part of the verification process of a
system.
%
It decides the expressiveness of the statements that can be proven, and the
tools verifiers can leverage to construct their proofs.

The most common formal system is the first-order logic\,\cite{smullyan2012fol},
characterized by:
%
\begin{itemize}
\item \emph{Terms}, which represents objects.
\item \emph{Logical operators}, such as conjunction \( \wedge \), disjunction
  \( \vee \), implication \( \Rightarrow \), negation \( \neg \).
\item \emph{Predicates}, that is parameterized formulas that can be true or
  false with respect to the applied terms.
\item \emph{Quantifiers}, such as \( \forall \) (all values) or \( \exists \)
  (there exists a value).
\end{itemize}

First-order logic quantifiers can only be applied on sets of terms (\emph{e.g.}
natural numbers, booleans, states of a airlock system).
%
Higher-order logic\,\cite{leivant1994hol} does not suffer the same limitation,
so it becomes possible to express statements such as \emph{for all sets with a
  total order \( < \), for all pair of values \( \alpha, \beta \), then either
  \( \alpha < \beta \) or \( \beta < \alpha \) or \( \alpha = \beta \)}.
%
Therefore, higher order logics are more expressive than first-order logic, but
they come with a cost in terms of automation.
%
On the one hand, \emph{Interactive} theorem provers (\emph{e.g.}  Coq,
Isabelle/HOL, or more recently Lean\,\cite{de2015lean} are based on higher-order
logic.
%
\emph{Automated} theorem provers (\emph{e.g.}
Vampire\,\cite{riazanov2002vampire}, Z3\,\cite{de2008z3}) are based on
first-order logic.

Finally, modal logic\,\cite{chagrov1997modal} is a formal system which extends
first-order logic with modal operators.
%
Temporal logics form the most popular family of modal logics, such as Temporal
Linear Logic (LTL)\,\cite{sistla1985ltl}.
%
They allow for reasoning about propositions over time.
%
Examples of LTL modular operators are \( \square P \) (\( P \) is always true),
\( \Diamond P \) (\( P \) will eventually become true), \( \bigcirc P \)
(\( P \) will be true after the next transition of the system).
%
Another popular temporal logic is Computation Logic Tree
(CTL)\,\cite{clarke1981ctl}, which considers trees of possible futures (by
opposition to a \emph{linear} future).
%
CTL modal operator includes \( \mathbf{A} P \) (\( P \) is true for all possible
futures) and \( \mathbf{E} P \) (there exists at least one path where \( P \)
becomes true).
%
Temporal logic formulas are commonly verified thanks to model checkers,
\emph{e.g.}  NuSMV\,\cite{cimatti2002nusmv}, SPIN\,\cite{holzmann1997spin} or
TLA+\,\cite{lamport2002tla}.
%
Other approaches can be used to that end ---for instance Gilles Barthe \emph{et
  al.} have encoded \( \square \) and \( \Diamond \) in
Coq\,\cite{barthe2011virtcert1}--- model checkers have the benefit of
automation and counter-example generation.

\subsection{Specifying Security Policies}
\label{sec:sota:security}

The verification a system is \emph{always} relative to certain properties (in
our case, the correct enforcement of a security policy).
%
The definition of a specification of the system to allow for formally reasoning
about its behavior is a key step of the verification process.
%
The formalization of the targeted property is as important, if not more.
%
Indeed, the challenge posed by a potential gap between an implementation and its
specification can be abated by an appropriate correspondence proof.
%
As for the targeted properties, a gap between its characterization using a
particular logic and its semantics should not be understated.
%
For instance, Mathy Vanhoef \emph{et al.} disclosed a critical vulnerability
(KRACK) targeting the WPA2 protocol\,\cite{vanhoef2017key}, despite previous
formal verification results (\emph{e.g.} \cite{he2004analysis}).
%
The reason remains simple: KRACK does not violate the security properties proven
in the formal analysis of the protocol, only these security properties were not
strong enough.

The theory of properties of a transition system is now well understood, with an
intuitive classification of properties, such that:
%
\begin{itemize}
\item \emph{Safety properties}\,\cite{lamport1977proving,lamport1985logical}
  characterize that nothing ``bad'' shall \emph{never} happens.
\item \emph{Liveness properties}\,\cite{lamport1985logical,alpern1985liveness}
  characterize that something ``good'' shall \emph{eventually} happens.
\end{itemize}

We discussed in Subsection~\ref{subsec:usecase:targetedsec} the two classes of
security policies commonly targeted by x86 \ac{hse} mechanisms.
%
An access control policy is a safety property: no unauthorized action by a
subject targeting on object shall never happen.
%
An availability policy is a liveness property: the system shall eventually
satisfy the service

Safety and liveness properties are expressed against the transition systems
\emph{traces}.
%
The most generic definition of a trace of a transition system is a (potentially
infinite) sequence of states generated by successive transitions.
%
Each modeling structure has its own definition of traces, which takes into
account the specificities of the model.
%
For instance, traces labeled transition system will interleave a label between
each state\,\cite{vijayaraghavan2015modular}, to characterize the nature of the
transition which led to the transformation of a state of the sequence with its
successor.
%
Afterwards, we write \( \Sigma(M) \) for the set of traces of a specification
\( M \).

Simplest properties can be defined in terms of sets of
traces\,\cite{schneider2000enforceable,basin2013enforceable}\,\thomasrk{cite
  ``Recognizing Safety and Liveness'' by Alpern}.
%
We assume a specification \( M \) whose set of states is \( S \) and whose
traces only contain states.
%
On the one hand, a safety property \( P \in \powerset(\Sigma(M)) \) is
formalized with an invariant \( \iota \) on trace element (\emph{i.e.} on
\( S \) in the case of the specification \( M \)).
%
\( M \) is correct with respect to \( P \) when
%
\[
  \forall \rho \in \Sigma(M)\text{, } \iota(\rho_0) \wedge \rho_{[1..]} \in P,
\]
%
where \( \rho_0 \) is the first element of the trace, and \( \rho_{[1..]} \) is
the trace obtained by removing the first element of \( \rho \).
%
On the other hand, a liveness property is formalized by a predicate \( \eta \)
on trace element which has to be satisfied at least once.
%
This time, \( M \) is correct with respect to \( P \) when
%
\[
  \rho \in \Sigma(M)\text{, } \eta(\rho_0) \vee \rho_{[1..]} \in P.
\]
%

\begin{example}[Airlock Safety and Liveness Properties]
  A typical \emph{safety} property (nothing `bad'' happens) for an airlock
  system is that at least one door shall be close at any time.
  %
  We formalize this property with the invariant \( \iota \), defined as follows:
  %
  \[
    \iota( d_1, d_2) \triangleq d_1 = \mathtt{close} \vee d_2 = \mathtt{close}
  \]
  %
  The specification of the airlock system is defined with a labeled transition
  system.
  %
  Assuming the airlock device is initialized in a correct state (\emph{e.g.}
  both doors are close), we verify this specification is correct with respect to
  the safety property characterized by \( \iota \) by exhibiting a proof that
  \( \iota \) is an invariant with respect to \( R \), that is
  %
  \[
    \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \iota(d_1, d_2) \Rightarrow
    \iota(d_1', d_2')
  \]
  %
  Such a proof is given in Figure~\ref{fig:sota:proofsafety}.

  In addition, we can also prove that both doors of the airlock will
  \emph{eventually} be close.
  %
  We can characterize this liveness property with the predicate \( \eta \), such
  that
  %
  \[
    \eta(d_1, d_2) \triangleq d_1 = \mathtt{close} \wedge d_2 = \mathtt{close}
  \]
  %
  We verify the specification of the airlock system is correct with respect to
  the liveness property characterized by \( \eta \) by exhibiting a proof that
  for each transition of \( R \), one of the state satisfies \( \eta \), that is
  %
  \[
    \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \eta(d_1, d_2) \vee
    \eta(d_1', d_2')
  \]

\end{example}

\begin{figure}
  \bigcentering%
  {\footnotesize \AxiomC{} \RightLabel{\footnotesize
      \( \vee,\Rightarrow \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{close} = \mathtt{close} \\
        \vee \mathtt{close} = \mathtt{close}) \\
        \Rightarrow (\mathtt{open} = \mathtt{close} \\
        \qquad \vee \mathtt{close} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{close}, \mathtt{close}) \\
        \Rightarrow
        \iota(\mathtt{open}, \mathtt{close})
      \end{array} \)}%
    \AxiomC{}
    \RightLabel{\footnotesize \( \vee,\Rightarrow \){\scshape -Def}}
    \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{close} = \mathtt{close} \\
        \vee \mathtt{close} = \mathtt{close}) \\
        \Rightarrow (\mathtt{close} = \mathtt{close} \\
        \qquad \vee \mathtt{open} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{close}, \mathtt{close}) \\
        \Rightarrow
        \iota(\mathtt{close}, \mathtt{open})
      \end{array} \)}%
    \AxiomC{}
    \RightLabel{\footnotesize \( \vee,\Rightarrow \){\scshape -Def}}
    \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{open} = \mathtt{close} \\
        \vee \mathtt{close} = \mathtt{close}) \\
        \Rightarrow (\mathtt{close} = \mathtt{close} \\
        \qquad \vee \mathtt{close} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{open}, \mathtt{close}) \\
        \Rightarrow
        \iota(\mathtt{close}, \mathtt{close})
      \end{array} \)}%
    \AxiomC{See \( \square \)}
    \RightLabel{\footnotesize \( R \){\scshape -Def}}
    \QuaternaryInfC{\( \forall ((d_1, d_2), l, (d_1', d_2')) \in R, \iota(d_1,
      d_2) \Rightarrow \iota(d_1', d_2') \)}%
    \DisplayProof}

  \vspace{2em}

  {\footnotesize \AxiomC{} \RightLabel{\footnotesize
      \( \vee,\Rightarrow \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        (\mathtt{close} = \mathtt{close} \\
        \vee \mathtt{open} = \mathtt{close}) \\
        \Rightarrow (\mathtt{close} = \mathtt{close} \\
        \qquad \vee \mathtt{close} = \mathtt{close})
      \end{array}
      \)}%
    \RightLabel{\footnotesize \( \iota \){\scshape -Def}} \UnaryInfC{\(
      \begin{array}{l}
        \iota(\mathtt{close}, \mathtt{open}) \\
        \Rightarrow
        \iota(\mathtt{close}, \mathtt{close})
      \end{array} \)}%
    \UnaryInfC{\( \square \)}
    \DisplayProof}

  \caption{Airlock system proof of correctness with respect to a safety
    property}
  \label{fig:sota:proofsafety}
\end{figure}

Not all security policies can be formalized with a predicate on traces.
%
For instance, \emph{noninterference} \thomasrk{ref} is a confidentiality policy
which requires that so-called public inputs handled by a given system always
produce the same output, regardless of concurrent secret inputs.
%
In this context, considering each trace independently does not make sense.
%
To witness a violation of the security policy requires to compare two traces
together.
%
Such properties are called \emph{hyperproperties}\,\cite{marr2002hypertheading},
and are characterized by sets of sets of traces.
%
Verifying a system with respect to a hyperproperty is harder in the general
case, but certain hyperproperties, called \( k \)-safety properties, can be
reduced to an invariant.
%
For instance, we assume \( M \) handles inputs which can be either secret or
public.
%
Let \( \equiv \) be the binary relation, such that two states \( s \) and
\( r \) satisfies this relation (\( s \equiv r \)) when they characterize two
instances of the system which have handled the same public inputs and produced
the same visible behavior.
%
Similarly to Banerjee \emph{et al.} \thomasrk{Stack-based access control for
  secure information flow} or Barthe \emph{et al.}\,\cite{barthe2011virtcert1},
we can prove \( M \) enforces noninterference if for any public input \( l \) by
constructing a proof that
%
\[
  \forall (s, r) \in S \times S, s \equiv r \Rightarrow (s \xrightarrow{l} s'
  \wedge r \xrightarrow{l} r') \Rightarrow s' \equiv r',
\]
where \( s \xrightarrow{l} s' \) is a transition of the system from a state
\( s \) to a state \( s' \) to handle the input \( l \).

%\subsection{Adversary Model}
%
%An \emph{adversary model} (or \emph{threat model}) characterizes what attackers
%can and cannot do inside a system.
%%
%Security guarantees shall always be defined with respect to a certain adversary
%model, to define the limits of the system security enforcement mechanisms.
%%
%That is, attackers which can leverage capabilities outside of the adversary
%model are likely to defeat the security policies.
%%
%Adversary model is a theoretical tool commonly used in the verification of
%cryptographic protocol, with a well-identified hierarchy of archetypes
%(\emph{e.g.} the Dolev–Yao model allows attackers to intercept, modify, generate
%any messages, but require necessary secret to encrypt and decrypt
%messages\,\thomasrk{ref}).

%\begin{itemize}
%\item Combinatronics of system actions (Pip, VirtCert)
%\item Additional rule to model more powerful attacker (Moat, XOM + bus snooping)
%\end{itemize}

\subsection{Related Works}

Formal verification of hardware and software systems is a large and prolific
research field, with important applications in the industry.
%
The interest has grown in the use of formal methods to improve the security of
computer systems\,\cite{chong2016report}.
%
We give an overview of formal verification projects which
%
\begin{inparaenum}[(1)]
\item have a clear focus on security, and
\item target two domains related to \ac{hse} mechanisms, that is hardware
  architectures (XOM\,\cite{lie2003xom}, ARMv8\,\cite{reid2016armv8}), and
  system software components (VirtCert, seL4).
\end{inparaenum}
%
For each project, we detail the modeling structure used to define the
specification of the targeted system, the verified properties and the
verification approach leveraged by the authors.

\paragraph{XOM.}
%
The \ac{xom} microprocessor architecture maintains separate so-called
\emph{compartments} for applications\,\thomasrk{ref xom}.
%
With mainstream microprocessor architectures, the system software is responsible
for both memory allocation and access control.
%
It relies on configurable \ac{cpu} mechanisms, such as a \ac{mmu}, to implement
the latter.
%
On the contrary, a \ac{xom} \ac{cpu} keeps track of each memory location owner,
thanks to a tagging mechanism, and prevents an application to access a memory
location it does not own.

In 2003, David Lie \emph{et al.} have modelled the \ac{xom}
architecture\,\cite{lie2003xom} using the Mur$\varphi$ model
checker\thomasrk{ref murphi}.
%
This model is a transition systems defined in terms of states and rules to
update these states.
%
There are two kinds of rules: the \ac{xom} instructions set, and some additional
capabilities given to the attacker.
%
As for the transitions set, it is defined in terms of pre and postconditions.
%
On the one hand, the precondition is parameterized by the current state and the
labeled event.
%
If the pre-condition is satisfied for a given hardware state and labeled events,
then it means that event can occur in this state.
%
On the other hand, the post condition is parameterized by the initial state, the
labeled event and the resulting state.
%
It determines the consequences of that event, in terms of state update.

The security properties targeted by the \ac{xom} architecture are enforceable
security properties, and the authors rely on Mur$\varphi$ to perform the state
exploration of their model.
%
The main advantage of a model checker, in this context, is to be able to print a
counter-example, that is a trace it has found not to satisfy the targeted
security property, in case of failure.
%
From a security perspective, a counter-example describes an attack path, that is
the execution steps to reproduce in order to defeat the security enforcement.
%
Hence, the authors have been able to show with their model that the \ac{xom}
architecture was subject to several replay attacks, and they leveraged their
model to validate their countermeasures.
%
However, the state explosion problem obliges the authors to simplify their
model, in order to reduce the state combinatory.

\paragraph{ARMv8.}
%
ARM Specification Language

\paragraph{VirtCert.}
%
Between 2011 and 2014, Gilles Barthe \emph{et al.} have worked on an idealized
model of a hypervisor.
%
This model is defined in terms of state, actions and a semantics of actions as
state-trans\-formers.
%
In their context, the state mixes information about both hardware components
(\ac{cpu} execution mode, registers, memory content, etc.) and software
components (list of guests, current active guest, memory mapping for the
hypervisor and the guests, etc.).
%
The actions are the hypercalls exposed by the hypervisor for the guests to use.
%
The semantics of actions as state-transformers, that is the set of possible
transitions for the modelled system, is defined in terms of pre and
postconditions.

First, they have shown that their ideal hypervisor was
%
\begin{inparaenum}[(1)]
\item ensuring strong isolation between guests, and
%
\item eventually processing every request performed by the
  guests\,\cite{barthe2011virtcert1}.
\end{inparaenum}
%
Then, they have incorporated the \ac{cpu} cache to their
model\,\cite{barthe2012virtcert2}.
%
Cache-based attacks, where attackers are able to infer information they should
not have access to by leveraging their knowledge of micro-architectural
implementation specificity, are a very important threat to virtualization
platforms.
%
The authors have shown their ideal hypervisor could prevent such attack, at the
cost of flushing the cache before each context switch.
%
They have taken their approach a step further, by focusing on constant-time
cryptography\,\cite{barthe2014virtcert3}.

The verification scope of VirtCert is large, and cover many security aspects
primordial for virtualization platforms.
%
Moreover, there have been an important specification and formalization effort
required to take into consideration the different security properties.
%
Some of them, like constant-time cryptography implementations, are
hyperpoperties, notably harder to reason with.

\paragraph{seL4.}
%
Certified microkernel.

\paragraph{RockSalt.}
%
Application checker

\paragraph{Moat.}
%
Application checker

\section{Compositional Security}

Traditional transition systems, such as the ones presented in the previous
section, impose to model the complete system all at once.
%
This raises important challenges for complex systems.
%
Model checkers and similar automated tools remain subject to the so-called
\emph{state explosion problem}\,\cite{clarke2012model} despite improvements to
algorithms.
%
State explosion problem imposes modeling compromises, \emph{e.g.}  verification
of cache coherency protocols with a fixed number of cores and limited address
space\thomasrk{ref}.
%
Theorem provers allows for modeling \emph{parameterized} systems, so that it
becomes possible, for example, to construct a proof which holds for an arbitrary
number of similar components\thomasrk{ref}.
%
This approach does not address all the challenges posed by the scale of complete
hardware architectures, built up from smaller ---yet complex--- components.
%
A comprehensive hardware model in terms of hardware components would undoubtedly
make the construction of the proof unbearable for any non-trivial properties,
yet is a requirement to prevent compositional attacks.

Compositional verification is a promising (family of) approach(es) to overcome
the challenges posed by the scale of complex and large systems\thomasrk{ref
  wing}, including hardware architectures.
%
In this approach, the verification work is divided into two steps.
%
First, each component is verified in isolation.
%
Then, the composition of these components in order to ensure it does not create
compositional attacks.
%
This requires to use adapted modeling structures when it comes to defining a
specification (\ref{subsec:sota:compmod}).
%
It also requires dedicated verification approaches, which enable ``divide and
conquer'' strategies to reduce the burden of verifying the system
(\ref{subsec:sota:compverif}).

\subsection{Compositional Modeling Structures}
\label{subsec:sota:compmod}

\paragraph{Input-Output Automata.}
%
I/O automata\,\cite{lynch1988ioautomata} are labeled transition systems which
distinguish between three classes of transitions, modeled with three disjoints
sets of labels:
%
\begin{inparaenum}[(1)]
\item input actions (denoted by \( \mathrm{in}(S) \) for an automaton \( S \)),
  %
\item output actions (denoted by \( \mathrm{out}(S) \)), and
  %
\item internal actions (denoted by \( \mathrm{int}(S) \)).
  %
\end{inparaenum}
%
They together form the signature of a given automaton (denoted by
\( \mathrm{act}(S) \)).
%
Its transition relation \( R(S) \) is a subset of
\( \mathrm{state}(S) \times \mathrm{act}(S) \times state(S) \), where
\( \mathrm{state}(S) \) is the set of states of \( S \).
%
I/O automata are expected to be \emph{input enabled}, that is it cannot delay
the treatment of its inputs.
%
This translates as follows: for every state \( p \) and input actions \( \pi \),
it exists a state \( q \) such that \( (p, \pi, q) \in R(S) \).
%
Composition of I/O automaton is achieved \emph{via} input and output actions.
%
More precisely, when one automaton perform an output action \( pi \) during a
transition, all automata having \( \pi \) as input action perform \( \pi \)
simultaneously.
%
Although by definition, I/O automata are required to be input enabled, in
practice the component they model will correctly behave (for a certain
definition of ``correct'') only if certain requirements are met regarding the
inputs they have to handle.

Interface automata\,\cite{de2001interfaceautomata} are similar to I/O automata,
except they are not require to be input enabled.
%
As a consequence, the definition of an interface automaton captures its
requirements over the rest of the system.
%
Another popular modeling structure is the Moore Machine.
%
Moore Machines play a key role in compositional model
checking\,\cite{mcmillan1989compositional}, because they can be translated into
a regular Kripke structure.

\paragraph{Process algebras.}
%
Another popular approach which enables compositional modeling of complex systems
is process algebra.
%
Process algebra has been developed in order to reason about programs executed in
parallel.
%
It is a formal system to describe interacting systems, together with a semantic
theory for verifying them.
%
In process algebras such as Calculus of Communication
Systems\,\cite{milner1980ccs} or the Communicating Sequential
Processes\,\cite{hoare1978csp}, two concurrent threads can run in parallel, and
synchronization is achieved by sending messages rather than \emph{via} some
shared memory.
%
Compare to I/O or interface automata, process algebras eases the description of
systems interactions.
%
Indeed, the behavior of each process is defined in the form of a program.

\paragraph{Algebraic Effects.}
%
Modeling side-effects in pure programming language, such as Haskell or {\scshape
  Gallina}, is usually achieve thanks to
Monads\,\cite{wadler1990comprehending,jones2005io}, \emph{e.g.} the State Monad
to seamlessly write computations which manipulates a global state, or the List
Monad to abstract non-determinism,
%
However, Monads have a reputation not to compose very
well\,\cite{hyland2006combining}, despite construction such as Monad
Transformers\,\cite{liang1995mtl}.
%
Algebraic effects and handlers are a generic approach overcoming this challenge,
with many different implementations (\emph{e.g.} Eff\,\cite{bauer2015effects},
{\scshape Idris}\,\cite{brady2013idris}, or
Haskell\,\cite{kiselyov2013extensible}).
%
In this context, \emph{effects} are characterized by a set of operations,
\emph{e.g.} \texttt{get} and \texttt{set} for global state manipulation.
%
These operations are expected to produce a value whose type is known by
definition.
%
For instance, \texttt{get} produces a value of the same type as the global
state.

On the one hand, programs with effects are pure computations which compose
effects results together.
%
On the other hand, handlers models the environment which realizes these effects,
computes their results, and manipulates programs control flows.
%
One possible representation of the relation between programs with effects and
effect handlers is by the mean of coroutines\,\cite{kiselyov2013extensible}.
%
When a program with effects requires the result of a given effect, it sends a
request to the handler, and waits for the result.

\subsection{Compositional Verification}
\label{subsec:sota:compverif}

Historically, compositional verification is the answer of model
checking\,\cite{mcmillan1989compositional} and concurrent programs
verification\,\cite{jones1983tentative} communities to the state explosion
problem.
%
It can be divided into to complementary approaches: compositional minimization
and compositional reasoning.

\paragraph{Compositional Minimization.}
%
Components of a larger system are primarily identified by the interface they
expose to their pairs, that is the set of operation they can carry out for the
rest of the system.
%
They also ``hide'' the components they are connected to, and use in order to
handles their input.
%
In this context, two components which expose the same interface can be freely
interchange on the condition that they exhibit an equivalent behavior with
respect to their interface.
%
There are many different formalization of what ``equivalent behavior'' actually
means.
%
For instance, in the context of process algebras, trace equivalence or
bisimulation are two possible definition of equivalent
behavior\,\cite{fokkink2013pa}.

Using a behavior equivalence approach, it becomes possible to reason about one
component by abstracting away the part of the systems it interacts with simpler
specifications.
%
This is referred to as compositional minimization \thomasrk{ref?} in model
checking.
%
The goal is to reduce the complexity of a model, with smaller yet provably
equivalent components.

\paragraph{Compositional Reasoning.}
%
At its simplest, assume-guarantee\,\cite{pnueli1985ag} ---or
rely-guarantee\,\cite{jones1983tentative}--- reasoning is about proving a
component \( C \) guarantees the property \( G \) under the assumptions that an
assumption \( A \) is satisfied, then proving the rest of the system \( S' \)
satisfies \( A \).
%
This allows for concluding about the correctness of the system as a whole, that
is the composition of \( C \) with \( S' \) (denoted by \( C || S' \))
guarantees \( G \).

First assume-guarantee systems have been developed for model checkers, where
assumptions and guarantees were defined with different temporal logic,
\emph{e.g.} LTL and CTL.
%
The main obstacle to the adoption of the assume-guarantee paradigm is the
necessity for the user to provide additional inputs to the checker, in addition
to the model and its properties to verify.
%
The \( L* \) learning algorithm, originally proposed by
Augluin\,\cite{angluin1987lstart}, addresses this issue by automatically
generating the appropriate assumptions.
%
The \( L* \) algorithm has latter been adopted to other modeling structure, for
instance for interface automata\,\cite{emmi2008assume}.

\subsection{Related Works}

\paragraph{Kami.}
%
Interface refinement approach, inspired by process algebra (except, method call
rather than message passing)
%
% Old version, to be amended
In in {\scshape Kami}, a transition of $M$ is denoted
%
\[ p \xrightarrow[a]{i} (v, q) \]
%
where $p \in S$ is the state of the component before the operation $i \in I$ is
called by an other component;
%
$a$ is a sequence of actions performed by the component in order to compute the
result of $i$;
%
$v$ is the result of this call, for the other component to use, and $q$ is the
modified state of the component.
%
Actions, in this context, are either local manipulations of the component's
state or calls of operations of the interface $O$.

A component $M$ can be composed with another component $M'$ to form a larger
component $M + M'$, for instance when the interface exposed by $M'$ is the
interface used by $M$.
%
To reason about $M + M'$, it is possible to define an abstract module $M''$,
verify $M + M''$ with respect to a given property, then prove that $M'$ is
equivalent to $M''$.

\paragraph{\texttt{Coq.io}.}
%
Algebraic Effects, reasoning on program with effects under hypotheses with
respect to outer environment behavior, but no way to verify these hypotheses

\paragraph{Interface-Confined Adversaries.}
%
Logic of Program that overcomes limitation of Coq.io, but to the best of our
knowledge, no implementation.

\section{Conclusion: Where this Thesis Stands}

\subsection{Specifying and Verifying Hardware-based Security Enforcement
  Mechanisms}

Formal verification consists in proving the correctness of a system,
characterized by a mathematical model, with respect to certain properties,
defined as logic formula.
%
By definition, \ac{hse} mechanisms fall between two domains that are hardware
design verification and low-level software components verification.

On the one hand, hardware designs verification often focus on properties
transparent to the executed software components (\emph{e.g.} cache
coherency\,\cite{stern1995cachecoherence}, linearizability of SGX
instructions\,\cite{leslie2015sgx}, hardware-based memory
isolation\,\cite{lie2003xom}).
%
Security gap in interactions of multiple platform components are less subject to
formal verification, due to their increasing
complexity\,\cite{potlapally2011hardwaresecurity}.
%
Yet they are responsible for architectural attacks we want to avoid.
%
On the other hand, low-level software components such as
seL4\,\cite{klein2009sel4} or CertiKOS\,\cite{gu2016certikos} use the features
exposed by these components, and are verified against \emph{ad hoc} hardware
models, whose scope is often limited to necessary hardware features.
%
We steer a middle course between these approaches.
%
We would rather characterize sets of requirements over low-level software
components, such that satisfying these requirements is sufficient to ensure the
hardware architecture enforces a certain property\,\cite{letan2016speccert}.
%
As a first step, we can verify the correctness of these requirements against a
hardware model.
%
The long term goal of this approach is to focus the verification of low-level
software components on proving they satisfy these requirements.
%
As such, our approach relates to previous research works such as
RockSalt\,\cite{morrisett2012rocksalt} (validation of arbitrary programs against
a verified software-based fault isolation\,\cite{wahbe1994sfi} policy) or
Moat\,\cite{sinha2015moat} (verification of SGX
enclave\,\cite{costan2016sgxexplained} programs with respect to
confidentiality).

\subsection{Compositional Verification of Hardware Architecture}

Our formal definition of \ac{hse} mechanism assume there exists a formal model
of the hardware architecture.
%
The proof of concept of our approach we have implemented in the Coq theorem
prover\,\cite{letan2016speccertcode} convinced us that such a model cannot be
monolithic.
%
Otherwise, it would make the proof burden hard to bear.
%
Compositional verification is a very important domain research for the
verification of large, realistic model.
%
However, it is a discipline mostly dominated by automated verification, like
model checking for instance.

With FreeSpec\,\cite{letan2018freespeccode}, we aim to provide a generic
compositional reasoning framework for Coq.
%
FreeSpec leverages programs with effects and effects handler to model
component-based system, and introduces so-called abstract specification in order
to enable compositional reasoning inspired by the assume-guarantee paradigm.
%
In doing so, FreeSpec is at the intersection of several research domains.
%
Our work is in the continuity of \texttt{Coq.io}\,\cite{claret2015coqio}, but
our abstract specifications are more generic and expressive than the scenarios.
%
We have shown how programs with effects and effects handlers can be used to
modularly verify a complex system made of inter-connected components, \emph{via}
the notion of interface as rendez-vous point.
%
The principle of our approach is similar to what {\scshape Kami} achieves, but
is not hardware specific.
%
In addition, our abstract specifications allows for compositional verification,
while {\scshape Kami} focus on refinement proofs.
%
To the best of our knowledge, the closest related research is the work of Deepak
Garg \emph{et al.}\,\cite{garg2010compositional}.
%
Probably the main difference between our two approaches is that they rely on a
dedicated programming language, while our programs with effects and effects
handler are regular {\scshape Gallina} development.
%
As a consequence, we can use the full interactive proof development environment
of Coq in order to write and machine-check our proofs.
